# A quantum algorithm providing exponential speed increase for finding eigenvalues and eigenvectors 1

Daniel S. Abrams Department of Physics, MIT 12-128b Cambridge, MA 02139 (abrams@mit.edu)

Seth Lloyd d’Arbeloff Laboratory for Information Sciences and Technology Department of Mechanical Engineering, MIT 3-160 Cambridge, MA 02139 (slloyd@mit.edu)

We describe a new polynomial time quantum algorithm that uses the quantum fast fourier transform to find eigenvalues and eigenvectors of a Hamiltonian operator, and that can be applied in cases (commonly found in ab initio physics and chemistry problems) for which all known classical algorithms require exponential time. Applications of the algorithm to specific problems are considered, and we find that classically intractable and interesting problems from atomic physics may be solved with between 50 and 100 quantum bits.

Long before Shor’s ground-breaking algorithm[1] - and the resulting surge of interest in quantum computing - Feynman suggested that a quantum computer might be useful for simulating other quantum systems[7]. This suggestion was based upon the observation that quantum systems are described in a Hilbert space whose size grows exponentially with the number of particles. Thus a collection of only 100 spin $1 / 2$ particles, each of which could be specified by only two complex amplitudes were it isolated, requires a total of $2 ^ { 1 0 0 }$ complex amplitudes for its state to be specified completely. This exponential explosion severely limits our ability to perform true “ab initio” (first principles) calculations; since it is obviously not possible to even describe the state of anything but the smallest quantum systems, one must resort to various approximation techniques to calculate properties of interest.

Recent work in quantum computation has revealed various techniques for simulating physics on a quantum computer [8][11][2][4][3][5], and it has been demonstrated that this can in fact be accomplished efficiently, as Feynman supposed. However, while previous work has described a variety of algorithms for initializing a quantum computer into a state corresponding to the state of a physical system, for time evolving this state on the computer, and for measuring properties of the time-evolved state [8][11] [2][4][3], there has been comparatively little work done on algorithms which calculate static properties of a physical system[5]. In particular, of all the questions which one might ask about a quantum system, there is one most frequently asked and for which one would most greatly desire an efficient algorithm: What are the energy eigenvalues and eigenstates? In this letter, we provide a quantum algorithm that can find eigenvalues and eigenvectors of a Hamiltonian operator in cases that occur frequently in problems of physical interest. Moreover, the algorithm requires an amount of time which scales as a polynomial function of the number of particles and the desired accuracy, whereas all known classical algorithms require an exponential amount of time.

The problem to be solved can be precisely stated as follows. Consider the time-evolution operator ${ \widehat { U } } = e ^ { - { \frac { i } { \hbar } } { \widehat { H } } t }$ which corresponds to the Hamiltonian $\hat { H }$ , and an approximate eigenvector $\mathrm { V } _ { a }$ of $\hat { U }$ (and thus of $\hat { H }$ ) that can be generated in quantum polynomial time, i.e., the machine can be placed into a state corresponding to $V _ { a }$ using a polynomial number of quantum logic operations. Call the true eigenvector $V$ and the true eigenvalue $\lambda _ { v }$ . If the state $V _ { a }$ satisfies the property that $| \langle V _ { a } | V \rangle | ^ { 2 }$ is not exponentially small - that is, the approximate eigenvector contains a component of the actual eigenvector that is bounded by a polynomial function of the problem size - then $V$ and $\lambda _ { v }$ can be found in time proportional to $1 / \left| \langle V _ { a } | V \rangle \right| ^ { 2 }$ and $1 / \epsilon$ , where $\epsilon$ is the desired accuracy.

Intuitively, what the algorithm does is to resolve the guess into its nonnegligible components and determine the corresponding eigenvalues. If the operator $\hat { U }$ (and thus its eigenvectors) is of exponentially large dimension - which it typically is - there are no known classical algorithms that can find even the eigenvalues in polynomial time. Although the requirement that there exist an initial statevector $V _ { a }$ with the specified properties may appear to be overly restrictive, it is frequently (if not usually) possible to obtain such a guess for “real” problems using existing classical techniques. For example, in any physical system with discrete energy levels that are not exponentially close together near the ground state (such as an atom), if it is possible to obtain classically any state vector with expected energy merely less than the first excited state (by a non-exponentially small amount), then this state vector must contain a non-negligible component of the ground state and - although it may not remotely resemble the ground state - could be used as the approximate state $\mathrm { V } _ { a }$ to determine the true ground state and ground state energy in polynomial time. Finally, if for some problems it is not possible to obtain classically a guess with the desired properties, it may often be the case that the state vector $V _ { a }$ may be generated using a quantum algorithm, such as quantum simulated annealing.

We will now describe an algorithm which applies to any $\hat { U }$ that can be implemented in quantum polynomial time, whether or not it represents the time evolution operator corresponding to a given Hamiltonian. (It was shown in [8] that the time evolution operator corresponding to any local Hamiltonian can be implemented in polynomial time on a quantum computer.) This first part of the algorithm was described independently by Cleve et. al. in [12] to find eigenvalues (but not eigenvectors) of unitary operators, in that case because the eigenvalues of a particular operator can be used to solve the abelian stabilizer problem. To begin, we consider a quantum computer consisting of m+l+w qubits, where a total of m qubits (to be called the index bits) are used for an FFT, a total of l qubits describe the Hilbert space in which the operator $\hat { U }$ acts, and w extra working qubits are required for temporary storage. Let $\mathrm { M } = 2 ^ { m }$ . The accuracy of the result will grow as $1 / \mathrm { M }$ . Assume that the m index qubits are initially in the state $| 0 >$ and that the l qubits are initially in the state $\mathrm { V } _ { a }$ (hence, the need for $\mathrm { V } _ { a }$ to be generated in quantum polynomial time). That is, the initial state is

$$
| \Psi > = | 0 > | V _ { a } >
$$

where the w work qubits are assumed to be $| 0 >$ unless specified otherwise. We perform a $\pi / 2$ rotation on each of the m index qubits to obtain the state

$$
| \Psi > = \frac { 1 } { \sqrt { M } } \sum _ { j = 0 } ^ { M - 1 } | j \rangle | V _ { a } \rangle
$$

Next, one performs a series of quantum logic operations that transform the computer into the state

$$
| \Psi > = \frac { 1 } { \sqrt { M } } \sum _ { j = 0 } ^ { M - 1 } | j \rangle ( \widehat { U } ) ^ { j } | V _ { a } \rangle
$$

This transformation is accomplished by applying the operation $\hat { U }$ to the second set of l qubits (which are initially in the state $| V _ { a } \rangle$ ) $\mathrm { j }$ times. It can be implemented easily by performing a loop (indexed by i) from 1 to $M$ . Using standard quantum logic operations, set a flag qubit to the value |1 $>$ if and only if $\mathrm { i } \prec \mathrm { j }$ and perform the operation $\hat { U }$ conditioned on the value of this flag. Thus only those components of the above superposition for which i<j are effected. Finally, undo the flag qubit and continue with the next iteration. After M iterations,

the state above is obtained.

At this point, it is helpful to rewrite the state in a slightly different manner. Label the eigenvectors of $\hat { U }$ by the states $\left| \phi _ { k } \right.$ and the corresponding eigenvalues with $\lambda _ { k }$ . We can then write

$$
| V _ { a } \rangle = \sum _ { k } c _ { k } | \phi _ { k } \rangle
$$

in which case the state (3) above can be rewritten as

$$
\begin{array} { c } { { \displaystyle | \Psi \rangle = \frac 1 { \sqrt M } \sum _ { j = 0 } ^ { M - 1 } | j \rangle ( \widehat U ) ^ { j } \sum _ { k } c _ { k } | \phi _ { k } \rangle } } \\ { { = \frac 1 { \sqrt M } \sum _ { k } c _ { k } \sum _ { j = 0 } ^ { M - 1 } | j \rangle ( \lambda _ { k } ) ^ { j } | \phi _ { k } \rangle } } \end{array}
$$

If we write $\lambda _ { k }$ as $e ^ { i \omega _ { k } }$ and exchange the order of the qubits so that the labels $\left| \phi _ { k } \right.$ appear first, the result is seen then most clearly:

$$
\left| \Psi \right. = { \frac { 1 } { \sqrt { M } } } \sum _ { k } c _ { k } \left| \phi _ { k } \right. \sum _ { j = 0 } ^ { M - 1 } e ^ { i \omega _ { k } j } \left| j \right.
$$

It is now self-evident that a quantum FFT performed on the m index qubits will reveal the phases $\omega _ { k }$ and thereby the eigenvalues $\lambda _ { k }$ . The quantum FFT requires only poly(m) operations, whereas the accuracy of the result will scale linearly with M or $2 ^ { m }$ . Each frequency is seen to occur with amplitude $c _ { k } =$ $\langle V _ { a } | \phi _ { k } \rangle$ ; by performing a measurement on the m index qubits, one thus obtains each eigenvalue with probability $\left| c _ { k } \right| ^ { 2 }$ . Only a polynomial number of trials is therefore required to obtain any eigenvalue for which $c _ { k }$ is not exponentially small. If the initial guess $| V _ { a } \rangle$ is close to the desired state (i.e., $| < V _ { a } | V > | ^ { 2 }$ is close to 1), then only a few trials may be necessary.

Moreover, one obtains the eigenvectors as well: once a measurement is made and an eigenvalue $\lambda _ { k }$ is determined, the remaining l qubits “collapse” into the state of the corresponding eigenvector. Of course, the state $\left| \phi _ { k } \right.$ is in some sense “trapped” inside the computer. But since it is impossible to store as classical information the $2 ^ { l }$ phases associated with the state, one cannot possibly hope to do better. However, one is likely to be interested in various properties of the eigenvectors, and these can be determined by making various measurements on the state. For ab initio quantum calculations, easily obtainable properties include those of greatest interest: charge density distributions, correlation functions, momentum distributions, etc. See [11] for a discussion of how relevant physical information can be extracted efficiently from the quantum computer.

We now consider more precisely how to find the eigenvectors and eigenvalues of a “real” Hamiltonian. Generally, one wishes to find energy eigenstates for a Hamiltonian of the form

$$
H = \sum _ { i = 1 } ^ { n } ( T _ { i } + V _ { i } ) + \sum _ { i > j } ^ { n } V _ { i j }
$$

where $n$ is the number of particles, $T _ { i }$ is the kinetic energy, $V _ { i }$ is the external potential, and $V _ { i j }$ is the interaction between the particles. However, there is no reason why these techniques cannot be applied to a different Hamiltonian or to one containing additional terms, as long as the Hamiltonian can be separated into a sum of local interactions (that is, a sum of terms which act upon only k qubits, where $\mathrm { k \Omega }$ is independent of the number of particles n). (In atomic problems, for example, one might include effective interactions such as spin-orbit coupling or nuclear finite size effects). Because the Hamiltonian is Hermitian, we apply the steps described above to the time evolution operator $\widehat { U } ( t ) = e ^ { - i H t }$ , which is unitary and has the same eigenvalues and eigenvectors. This time evolution operator is generated using the technique described in [8]; the key idea is to write

$$
\begin{array} { r c l } { { } } & { { } } & { { H = \displaystyle \sum { H _ { i } } } } \\ { { } } & { { } } & { { } } \\ { { } } & { { } } & { { \widehat { U } ( t ) = e ^ { - i H t } = \displaystyle ( e ^ { - i H _ { 1 } \frac { t } { m } } e ^ { - i H _ { 2 } \frac { t } { m } } . . . e ^ { - i H _ { k } \frac { t } { m } } ) ^ { m } + \displaystyle \sum _ { i > j } [ H _ { i } , H _ { j } ] \frac { t ^ { 2 } } { 2 m } + . . . } } \end{array}
$$

where each $H _ { i }$ acts on only $\mathrm { k }$ qubits at a time. (In the Hamiltonian above, each $H _ { i }$ represents one of the terms $T _ { i }$ , $V _ { i }$ , or $V _ { i j }$ ). Let $U _ { i } = e ^ { - i H _ { i } \frac { t } { m } }$ . Each term $U _ { i }$ can be implemented efficiently, because it acts in a space of only k quantum bits, where $\mathrm { k \Omega }$ is small. For large enough $m$ , the second term on the right (and the higher order terms) approaches zero. It is therefore possible to generate $\hat { U } ( t )$ by acting on the state with each $U _ { i }$ in series, a total of $m$ times. A careful analysis [8] reveals that in order to simulate $\widehat { U } ( t )$ with an accuracy $\epsilon$ , one needs to apply $\mathrm { O } ( t ^ { 2 } / \epsilon )$ quantum logic operations.2

For a specific problem, the form of the matrices $U _ { i }$ depends greatly on the basis set chosen to describe the Hilbert space. Moreover, the choice may strongly impact the size of the basis required to describe the system accurately. In the usual first quantized representation, each particle is described by a series of l qubits representing a single particle wave function. The system as a whole is thus represented with $\mathrm { n ^ { * } l }$ qubits. (It is also possible to use a second quantized representation, which may be more efficient for certain problems; see [11]). For the Hamiltonian above, the matrices $U _ { i }$ can be implemented in a particularly efficient manner by using either position space or momentum space for the single particle basis, and switching between the two via quantum FFTs. However, for most problems, these are not the most effective choices to represent the energy eigenstates. Other sets of basis states are generally more efficient and are frequently employed in conventional classical computations: one possible example might be wavelets; another common choice might be single electron solutions for an effective potential. As long as the single particle basis is of a fixed size (and the reason why we choose a more complicated basis set is for the explicit purpose of keeping it small), then the operators $U _ { i }$ can always be calculated in the chosen basis and implemented using O( $\mathrm { l } ^ { 4 }$ ) operations, where d is the dimension of the single particle basis set [6]. Thus one finds that it is possible to apply these quantum algorithms using the more elaborate choices of basis sets that are commonly employed in conventional ab initio calculations.(Because there exists a fast quantum wavelet transform [9], it may be that a wavelet basis turns out to be particularly useful). On the other hand, there is a trade-off between memory and speed. By using the position or momentum space representation, one needs only $\mathrm { O } ( \mathrm { p o l y } ( \mathrm { k } ) ) = \mathrm { O } ( \mathrm { p o l y } ( \log \mathrm { d } ) )$ operations to perform each $U _ { i }$ ; however a large number of qubits are required to describe the eigenstates accurately. By choosing a more elaborate basis set, one can vastly reduce the required number of qubits, but a much larger number of quantum logic operations O( $\mathrm { k ^ { 4 } }$ ) may be necessary to implement each $U _ { i }$ . Thus one finds that, just as with conventional computations, the choice of basis sets in the quantum computation will depend upon the specific problem at hand and the specific capabilities of the actual computing machine.

Normally, the initial state $V _ { a }$ will be the result of a classical calculation, for example, a Hartree-Fock calculation or configuration interaction calculation. Any ab initio technique which results in a known wave function can be used. (Note that this does not include those techniques which utilize density functional theory, as we require a wavefunction, not simply a charge density distribution). If the input wave function is not already symmetrized or antisymmetrized, we can use the algorithms described in [11] to do so efficiently.

Finally, we consider state-of-the-art ab initio calculations of atomic energy levels in order to compare the quantum algorithm described above with known classical techniques. Problems from atomic physics serve as a particularly good benchmark because extremely accurate experimental data is widely available. The quantum algorithm corresponds most closely to what is known as “complete active configuration interaction” or “full configuration interaction” techniques, because the many-particle basis set includes all possible products of single particle basis vectors. This approach is most valuable in situations where the correlation energy is large and where many “configurations” are of similar energy (this typically occurs when many electrons are in open shells). Unfortunately, it is difficult to state precisely the minimum size problem for which the quantum calculation surpasses the best classical calculations, because a variety of sophisticated techniques are used to avoid the exponential explosion in basis states. That is, the most accurate classical calculations do not employ directly the “full configuration interaction” method. Based on [10], however, we estimate that a calculation of the energy levels of B (5 electrons), using roughly 20 angular wavefunctions and 40 radial wavefunctions per particle - for a total of 800 single particle wave functions and therefore $8 0 0 ^ { 5 } \approx 1 0 ^ { 1 5 }$ full many-body basis states - may provide more accurate results than any classical calculation performed to date. At the very least, such a calculation would reveal scientifically interesting (and classically unobtainable) results with respect to electron correlation energies in B and the relative importance of various orders of excited configurations.

A quantum calculation of the B ground state, using a basis set as described above, can be accomplished with 60 qubits: 10 per particle to represent the state of the atom (for a total of 50 qubits), 6 or 7 qubits for the FFT, and a few additional “scratch” qubits3. Unfortunately, the two particle operators (generated by the coulomb attraction between pairs of electrons) take place in a subspace of dimension $( 2 ^ { 1 0 } ) ^ { 2 }$ ; they therefore are represented by matrices with $2 ^ { 4 0 }$ elements. Implementing such an operator by brute force is likely to remain intractable for the foreseeable future. However, it may be possible to perform the necessary transformation using a quantum algorithm. One possible technique is to change basis sets: by representing the interacting particles in position space, instead of with the orbital basis set, it is easy to calculate the coulomb terms. Thus one can transform each particle into position space separately (requiring a small number of quantum logic operations), perform the time evolution corresponding to the coulomb interaction, and then transform back. Unfortunately, a position space representation will require many more qubits. We estimate that 30 qubits per particle (10 per dimension, for a real space grid of 1024x1024x1024 per particle) will more than suffice. Because these 30 qubits are required only temporarily for the 2 particles whose interaction we are considering at any particular stage in the algorithm, the new efficient algorithm requires a total of $2 \mathrm { ~ x ~ } 3 0$ qubits (for the interacting particles), an additional $3 \mathrm { ~ x ~ } 1 0$ qubits (for the remaining particles), and the same 10 qubits for the FFT and work space. It thus appears that in order to realistically perform an “interesting” calculation using the algorithms described previously, one will need a quantum computer with approximately 100 qubits. Of course, the possibility remains that an efficient algorithm for implementing the coulomb interaction could be invented that does not require additional working space.

In conclusion: we have provided a new quantum algorithm which can be used to find eigenvectors and eigenvalues of a Hamiltonian operator. The algorithm provides an exponential speed increase when compared to the best known classical techniques. Problems from atomic physics may be the best place to perform the first real calculations, both because accurate experimental data is available to verify the resulting calculations, and because the parameters involved appear to be within the foreseeable range of small quantum computers. We estimate that 50 - 100 qubits are sufficient to perform “interesting” calculations that are classically intractable. Finally, we suggest a couple of interesting questions which remain open. First; although we have made estimates regarding numbers of required qubits, it would be interesting to calculate accurately the number of quantum logic gates required to do an “interesting” problem. Second, a detailed analysis of the effects of errors would be worthwhile, as would an analysis of error correcting codes in this context.

D.S.A. acknowledges support from a NDSEG fellowship, and thanks D. Lidar, C. Froese Fisher, and especially W. R. Johnson for helpful discussions. Portions of this research were supported by grant # N00014-95-1-0975 from the Office of Naval Research, and by ARO and DARPA under grant # DAAH04- 96-1-0386 to QUIC, the Quantum Information and Computation initiative, and by a DARPA grant to NMRQC, the Nuclear Magnetic Resonance Quantum Computing initiative.

# References

[1] P. Shor, in Proceedings of the 35th Annual Symposium on Foundations of Computer Science, edited by S. Goldwasser (IEEE Computer Society, Los Alamos, CA, 1994), p.124   
[2] B. Boghosian and W. Taylor, Phys. Rev. E. vol 57 (1998), p. 54   
[3] S. Wiesner, preprint   
[4] C. Zalka, Proc. R. Soc. Lond. A (1998)   
[5] D. Lidar and O. Biham, Phys. Rev. E vol.56 (1997), p.3661   
[6] A. Barenco et. al., Phys. Rev. A 52, 3457 (1995)   
[7] R.P. Feynman, Int. J. Theor. Phys. 21, 467 (1982)   
[8] S. Lloyd, Science 273, 1073 (1996)   
[9] C. Williams, private communication   
[10] W. R. Johnson, private communication   
[11] D.S. Abrams and S. Lloyd, Phys. Rev. Lett. 79, 2586 (1997)   
[12] R. Cleve, A. Ekert, C. Macchiavello, M. Mosca, submitted to Proc. Roy. Soc. Lond. A, preprint at quant-ph/9708016