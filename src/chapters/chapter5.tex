% Chapter 5: Adiabatic Quantum Optimization
% ASSUMES: Chapter 3 defines Hilbert space, qubit, Hamiltonian, eigenvalue,
%   eigenvector, spectral gap, spectral decomposition, unitary, measurement,
%   BQP, Grover's algorithm and its optimality.
% ASSUMES: Chapter 4 defines AQC, adiabatic theorem, spectral gap as
%   computational resource, avoided crossings, local/adaptive schedules,
%   Roland-Cerf construction.

In the circuit model, unstructured optimization is already understood. Given a black-box cost function on $N = 2^n$ bit-strings, Grover's algorithm and its generalizations find a minimizer in $O(\sqrt{N/d_0})$ queries, where $d_0$ is the number of optima \cite{Grover1996, BBHT1998}. The algorithm needs no prior knowledge of the cost function's structure. Amplitude amplification gathers what it needs adaptively, one oracle query at a time. No spectral parameter is computed in advance, no schedule is tuned to a gap profile, and no preprocessing competes with the search cost itself.

Adiabatic quantum computation is polynomially equivalent to the circuit model \cite{aharonov2007adiabatic}, so the same speedup exists in principle. The obstruction is different. The evolution Hamiltonian $H(s)$ interpolates continuously between an initial Hamiltonian $H_0$ and the problem Hamiltonian $H_z$, and the runtime is controlled by the spectral gap of $H(s)$ along the entire path. The location of the avoided crossing, the sharpness of the minimum gap, and the reopening rate all matter. Matching the Grover speedup now requires controlling spectral features that depend on the full degeneracy structure of $H_z$.

The adiabatic version of Grover's algorithm, due to Roland and Cerf \cite{roland2002quantum}, finds a single marked item among $N = 2^n$ by slowly interpolating between a uniform superposition and a problem Hamiltonian that penalizes all unmarked items. The crossing between the two lowest energy levels occurs at $s = 1/2$, its position independent of the Hamiltonian's spectrum. The minimum spectral gap scales as $1/\sqrt{N}$, and a schedule that slows near the crossing achieves the optimal $O(\sqrt{N})$ runtime.

Consider a cost function encoded in an $n$-qubit Hamiltonian diagonal in the computational basis, with $M$ distinct energy levels, arbitrary degeneracies, and a spectral gap that may vary with the number of qubits. The ground states encode solutions to a combinatorial optimization problem. Can the adiabatic approach still match the $\Theta(\sqrt{N})$ lower bound for unstructured search \cite{farhi2008fail}?

The bound applies directly to our setup. Farhi et al.\ proved that when $H_0$ is a rank-one projector onto the uniform superposition, no schedule can find the ground state in time $o(\sqrt{N/d_0})$, regardless of the cost function. Their proof constructs $N$ equivalent Hamiltonians related by Fourier shifts and applies a continuous-time analogue of the BBBV argument \cite{bennett1997strengths}. Partial answers came first. \v{Z}nidari\v{c} and Horvat \cite{horvat2006exponential} showed via analytical and heuristic arguments that the minimum gap scales as $\sqrt{d_0/2^n}$ for 3-SAT instances and identified the crossing position, but did not rigorously bound the runtime. Hen \cite{hen2014continuous} proved a quadratic speedup for a random Hamiltonian whose energy distribution makes the crossing position spectrum-independent, sidestepping the central difficulty.

The answer in full generality is yes, and in our view that is the surprising
part. But it comes with a sharp caveat. The spectrum of the interpolated
Hamiltonian is much richer than in the Grover case. Instead of a two-level
system plus a degenerate bulk, one gets $M$ interacting energy levels in a
symmetric subspace, with higher-state avoided crossings that obscure the lowest
gap. The ground-state crossing position depends nontrivially on the degeneracy
structure of $H_z$. The minimum gap still scales as $\Theta(1/\sqrt{N})$ up to
spectral factors, but it occurs at a position that must be known to exponential
precision for the schedule to be correct.

For a general diagonal problem Hamiltonian, $H(s)$ has a single avoided crossing at position $s^* = A_1/(A_1 + 1)$, where $A_1$ is a spectral parameter determined by the degeneracy structure. The minimum spectral gap at the crossing scales as $\Theta(\sqrt{d_0/(N A_2)})$, and the gap grows linearly on both sides. Chapter 6 proves the gap bounds outside the crossing window, and Chapter 7 derives the optimal runtime. Chapter 8 then shows where the edge comes from. Computing $s^*$ is NP-hard.

\section{From Cost Function to Adiabatic Path}
\label{sec:aqo-problem}

We now formalize the optimization setting and the interpolation path. Consider
an $n$-qubit Hamiltonian $H_z$ that is diagonal in the computational basis.
\begin{equation}
\label{eq:Hz-def}
H_z = \sum_{z \in \{0,1\}^n} E_z \ket{z}\bra{z},
\end{equation}
where $E_z$ is the energy assigned to bit-string $z$. Since $H_z$ acts diagonally, it encodes a classical cost function. The energy $E_z$ is the cost of configuration $z$, and the ground states are the optimal solutions. Without loss of generality, we rescale and shift so that all eigenvalues lie in $[0, 1]$.

Suppose $H_z$ has $M$ distinct energy levels with eigenvalues
\begin{equation}
\label{eq:eigenvalues-ordered}
0 \leq E_0 < E_1 < \cdots < E_{M-1} \leq 1.
\end{equation}
For each level $k$, the set of bit-strings at that energy is
\begin{equation}
\label{eq:Omega-k-def}
\Omega_k = \left\{ z \in \{0,1\}^n : H_z \ket{z} = E_k \ket{z} \right\},
\end{equation}
with degeneracy $d_k = |\Omega_k|$. The degeneracies partition the full Hilbert
space, so $\sum_{k=0}^{M-1} d_k = 2^n = N$. The spectral gap of the problem
Hamiltonian is $\Delta = E_1 - E_0$, the energy difference between the ground
state and the first excited level.

NP-hard optimization problems such as MaxCut and QUBO encode directly as ground states of the 2-local Ising Hamiltonian \cite{barahona1982computational, lucas2014ising}.
\begin{equation}
\label{eq:Ising-Ham}
H_\sigma = \sum_{\langle i,j \rangle} J_{ij} \sigma_z^i \sigma_z^j + \sum_{j=1}^{n} h_j \sigma_z^j,
\end{equation}
where $J_{ij}, h_j \in \{-m, -m+1, \ldots, m\}$ for some constant positive integer $m$. Since each eigenvalue is an integer linear combination of at most $\binom{n}{2} + n$ couplings bounded by $m$, the eigenvalues lie in $\{-L, -L+1, \ldots, L\}$ for $L = O(mn^2)$, giving at most $2L + 1 \in \mathrm{poly}(n)$ distinct energy levels. After normalization to unit operator norm, consecutive eigenvalues differ by at least $1/(2L) \geq 1/\mathrm{poly}(n)$, so the spectral gap satisfies $\Delta \geq 1/\mathrm{poly}(n)$.

Unstructured search also fits this framework. It has $M = 2$ energy levels, a single ground state ($d_0 = 1$) with energy $E_0 = 0$, and $N - 1$ excited states ($d_1 = N - 1$) at energy $E_1 = 1$. The ground state is the ``marked item.'' Classical search requires $\Theta(N)$ queries, while Grover's circuit algorithm requires $\Theta(\sqrt{N})$ \cite{Grover1996, bennett1997strengths}.

The adiabatic Hamiltonian interpolates between a rank-one projector and $H_z$. The initial Hamiltonian is
\begin{equation}
\label{eq:H0-def}
H_0 = -\ket{\psi_0}\bra{\psi_0}, \qquad \ket{\psi_0} = \ket{+}^{\otimes n} = \frac{1}{\sqrt{N}} \sum_{z \in \{0,1\}^n} \ket{z}.
\end{equation}
Every computational basis state receives equal amplitude, so $\ket{\psi_0}$ introduces no bias toward any particular solution.

The adiabatic Hamiltonian is the linear interpolation
\begin{equation}
\label{eq:H(s)-def}
H(s) = -(1 - s)\ket{\psi_0}\bra{\psi_0} + s H_z, \qquad s \in [0, 1].
\end{equation}
At $s = 0$, the ground state is $\ket{\psi_0}$ with energy $-1$, and all other states have energy $0$. At $s = 1$, the Hamiltonian is $H_z$ itself, and its ground states encode the solutions. The adiabatic theorem guarantees that if the schedule $s(t)$ traverses $[0, 1]$ slowly enough, the evolved state remains close to the instantaneous ground state throughout, arriving at the end in a state with high overlap with the ground space of $H_z$.

A rank-one $H_0$ produces exactly one avoided crossing between the two lowest energy levels. That single crossing is the structural reason the spectral analysis in Chapters 5--7 is possible at all. At $s = 0$, the spectrum has a non-degenerate ground state at $-1$ and an $(N-1)$-fold degenerate level at $0$. As $s$ increases, the degeneracy splits according to $H_z$. Because $H_0 = -\ket{\psi_0}\bra{\psi_0}$ has rank one, all coupling between eigenstates of $sH_z$ factors through $\ket{\psi_0}$. The matrix element $\bra{k}H_0\ket{j} = -\sqrt{d_k d_j}/N$ is nonzero for all pairs, yet the perturbation has only one degree of freedom, so eigenvalues repel through a single channel. Generic AQC Hamiltonians may exhibit multiple crossings requiring qualitatively different techniques \cite{albash2018adiabatic, arthurthesis, choi2011different}. Here, there is one.

The standard alternative to the rank-one projector is the transverse-field driver $H_0 = -\sum_{j=1}^n \sigma_x^j$, which is the default in quantum annealing hardware and in much of the AQC literature \cite{albash2018adiabatic}. It couples every pair of computational basis states that differ in a single qubit, producing a dense web of avoided crossings throughout the interpolation. For random instances of NP-complete problems, Altshuler, Krovi, and Roland~\cite{altshuler2010anderson} showed that the resulting spectrum exhibits Anderson localization. One then gets exponentially many avoided crossings with exponentially small gaps, and no known analytical technique yields tight gap bounds in that regime. The rank-one projector avoids this entirely. Because $\ket{\psi_0}\bra{\psi_0}$ has a single non-zero eigenvalue, all coupling between eigenstates of $sH_z$ flows through one channel, producing one crossing that can be analyzed exactly. The tractability of Chapters 5--7 is a direct consequence of this choice. Whether comparable results can be obtained for the transverse-field driver remains open. The Discussion of \cite{braida2024unstructured} identifies this as a central challenge.

In the unstructured case, $H(s) = -(1-s)\ket{\psi_0}\bra{\psi_0} + s(I - \ket{w}\bra{w})$, where $\ket{w}$ is the marked item. Up to a global energy shift of $s$, this is the Roland-Cerf Hamiltonian \cite{roland2002quantum}. The spectrum has $N - 2$ states at energy $s$ (degenerate, orthogonal to both $\ket{\psi_0}$ and $\ket{w}$) and two states whose energies depend on $s$ and undergo an avoided crossing near $s = 1/2$.


\section{Spectral Parameters}
\label{sec:spectral-parameters}

In the Roland-Cerf setting, the crossing position ($s^* = 1/2$), its width, and the minimum gap are all determined by a single quantity, $N$. For a general problem Hamiltonian $H_z$ with $M$ energy levels and arbitrary degeneracies, no single number suffices. The crossing position depends on the full eigenvalue structure of $H_z$, not only on $E_0$ and $E_1$. We therefore need quantities that compress this $M$-dimensional information into parameters that directly control the algorithm, namely the crossing location, the sharpness of the minimum gap, and the reopening rate.

\begin{definition}[Spectral parameters]
\label{def:spectral-parameters}
For the problem Hamiltonian $H_z$ with eigenvalues $E_0 < E_1 < \cdots < E_{M-1}$ and degeneracies $d_k$, define
\begin{equation}
\label{eq:Ap-def}
A_p = \frac{1}{N} \sum_{k=1}^{M-1} \frac{d_k}{(E_k - E_0)^p}, \qquad p \in \mathbb{N}.
\end{equation}
\end{definition}

Each excited level contributes its degeneracy $d_k$ weighted by the inverse $p$-th power of its distance to the ground energy. Larger $p$ gives more weight to near-ground levels. Concretely, $A_1$ uses weight $1/(E_k-E_0)$, while $A_2$ uses $1/(E_k-E_0)^2$. A level at energy $E_0+\varepsilon$ therefore contributes $O(1/\varepsilon)$ to $A_1$ but $O(1/\varepsilon^2)$ to $A_2$. The parameter $A_1$ determines the crossing position, and $A_2$ determines how sharp the crossing is. Normalization by $N=2^n$ makes $A_p$ an average over the full Hilbert space.

When $M = 2$, $d_0 = 1$, $d_1 = N-1$, $E_0 = 0$, and $E_1 = 1$, we get
\begin{equation}
\label{eq:Ap-grover}
A_p = \frac{N - 1}{N} \approx 1 \quad \text{for all } p,
\end{equation}
since $E_1 - E_0 = 1$. The spectral parameters are trivial in this case, which is precisely why the Roland-Cerf analysis is simple.

For a general Ising Hamiltonian with $\Delta \geq 1/\text{poly}(n)$ and $M \in \text{poly}(n)$, the bound $A_1 \leq (1-d_0/N)/\Delta$ gives $A_1 = O(\text{poly}(n))$. The bound $A_2 \geq 1 - d_0/N$ then guarantees $A_2$ stays constant-order whenever $d_0 \ll N$.

$A_1$ determines the crossing position, $s^* = A_1/(A_1 + 1)$. The parameter $A_2$ enters the minimum spectral gap, $g_{\min} = \Theta(\sqrt{d_0/(N A_2)})$. The gap scales as $\sqrt{d_0/N}$, so more ground states strengthen the coupling and widen the crossing. Both parameters appear in the runtime:
\[
T = O\!\left(\frac{\sqrt{A_2}}{A_1(A_1+1)\Delta^2}\sqrt{\frac{N}{d_0}}\right).
\]

Since every eigenvalue gap satisfies $E_k - E_0 \leq 1$ and the total excited degeneracy is $\sum_{k \geq 1} d_k = N - d_0$, we have
\begin{equation}
\label{eq:A2-lower-bound}
A_2 \geq \frac{1}{N} \sum_{k=1}^{M-1} d_k = 1 - \frac{d_0}{N}.
\end{equation}
For $d_0 \ll N$ (few solutions), $A_2 \geq 1 - 1/N$ is close to $1$. We also have
$A_1 \leq (1 - d_0/N)/\Delta$, since $(E_k - E_0)^{-1} \leq \Delta^{-1}$ for all $k \geq 1$.
A lower bound follows by the same comparison: because $E_k - E_0 \geq \Delta$,
termwise comparison gives $A_1 \geq A_2 \Delta$. Since $E_k - E_0 \leq 1$, we
also have $A_1 \leq A_2$. Hence
\[
A_2 \Delta \leq A_1 \leq A_2.
\]

The two-level approximation near the crossing is accurate only when the crossing window $\delta_s = O(\sqrt{d_0 A_2/N})$ is narrow compared to $[0,1]$. Since $\delta_s/s^* = O((1/\Delta)\sqrt{d_0/(A_2 N)})$, this requires the spectral parameters to be polynomially bounded relative to $N$.

\begin{definition}[Spectral condition]
\label{def:spectral-condition}
The problem Hamiltonian $H_z$ satisfies the spectral condition if there exists a constant $c \ll 1$ such that
\begin{equation}
\label{eq:spectral-condition}
\frac{1}{\Delta} \sqrt{\frac{d_0}{A_2 N}} < c.
\end{equation}
\end{definition}

The quantity on the left is, up to constants, the ratio between the crossing-window
width and the problem-Hamiltonian spectral gap $\Delta$. When this ratio is small, the two-level
approximation near the crossing is accurate. Higher levels stay perturbative,
and the window occupies only a small part of $[0,1]$. The appendix
of \cite{braida2024unstructured} shows that $c \approx 0.02$ is sufficient.
When the condition fails, the argument breaks in a specific place. The
eigenvalue equation is still valid, but the quadratic truncation in $\delta$
(Eq.~\eqref{eq:delta-pm-formula}) requires $|\delta| \ll s\Delta$. That fails
when many excited levels crowd near $E_0$. The result is a genuine
multi-crossing regime, exemplified by transverse-field dynamics on random
NP-complete instances \cite{altshuler2010anderson}. The spectral condition
therefore marks the boundary between the single-crossing regime of Chapters 5--7
and a regime that remains analytically intractable \cite{arthurthesis}.

For any $H_z$ with $\Delta > (1/c)\sqrt{d_0/N}$, the condition holds, using $A_2 \geq 1 - d_0/N$. For the Ising Hamiltonian with $\Delta \geq 1/\text{poly}(n)$ and $d_0$ not scaling with $N$, the left side is exponentially small in $n$, so the condition is easily satisfied. With $\Delta = 1$ and $d_0 = 1$ (unstructured search), the left side is $1/\sqrt{N}$, well below any constant $c$ for $N \geq 2$.


\section{Symmetry Reduction}
\label{sec:symmetry-reduction}

The Hilbert space of $H(s)$ has dimension $N = 2^n$, exponentially large in the number of qubits. Direct spectral analysis is intractable. But the problem Hamiltonian $H_z$ has only $M$ distinct energy levels, and the initial state $\ket{\psi_0}$ treats all bit-strings at the same energy identically. This permutation symmetry within each degenerate subspace reduces the eigenvalue problem from $N$ dimensions to $M$.

For each energy level $k$, define the symmetric state
\begin{equation}
\label{eq:symmetric-state}
\ket{k} = \frac{1}{\sqrt{d_k}} \sum_{z \in \Omega_k} \ket{z}, \qquad 0 \leq k \leq M - 1.
\end{equation}
These $M$ states are orthonormal: $\braket{j}{k} = \delta_{jk}$. They span the $M$-dimensional symmetric subspace
\begin{equation}
\label{eq:HS-def}
\mathcal{H}_S = \text{span}\left\{ \ket{k} : 0 \leq k \leq M - 1 \right\}.
\end{equation}

In this basis, the problem Hamiltonian has $M$ non-degenerate eigenvalues.
\begin{equation}
\label{eq:Hz-symmetric}
H_z = \sum_{k=0}^{M-1} E_k \ket{k}\bra{k} \quad \text{on } \mathcal{H}_S,
\end{equation}
and the initial state decomposes as
\begin{equation}
\label{eq:psi0-symmetric}
\ket{\psi_0} = \sum_{k=0}^{M-1} \sqrt{\frac{d_k}{N}} \ket{k}.
\end{equation}
Since $\ket{\psi_0} \in \mathcal{H}_S$ and both $H_z$ and $\ket{\psi_0}\bra{\psi_0}$ map $\mathcal{H}_S$ to itself, the adiabatic Hamiltonian $H(s)$ leaves $\mathcal{H}_S$ invariant. The time evolution starting from $\ket{\psi_0}$ remains in $\mathcal{H}_S$ for all $s$.

The complement $\mathcal{H}_S^\perp$ has dimension $N - M$ and is spanned by states orthogonal to $\ket{\psi_0}$ within each degenerate subspace. For each level $k$, order the bit-strings in $\Omega_k$ as $z_k^{(1)}, \ldots, z_k^{(d_k)}$ and define the Fourier basis
\begin{equation}
\label{eq:fourier-basis}
\ket{k^{(\ell)}} = \frac{1}{\sqrt{d_k}} \sum_{\ell'=1}^{d_k} \exp\left[\frac{i 2\pi \ell \ell'}{d_k}\right] \ket{z_k^{(\ell')}}, \qquad 1 \leq \ell \leq d_k - 1.
\end{equation}
Note that $\ket{k^{(0)}} = \ket{k}$ is the symmetric state already in
$\mathcal{H}_S$. The remaining $d_k - 1$ states for each level $k$ form a basis
for $\mathcal{H}_S^\perp$.
\begin{equation}
\label{eq:HS-perp}
\mathcal{H}_S^\perp = \text{span}\left\{ \ket{k^{(\ell)}} : 0 \leq k \leq M - 1, \; 1 \leq \ell \leq d_k - 1 \right\}.
\end{equation}
Each $\ket{k^{(\ell)}}$ is an eigenstate of $H(s)$ with eigenvalue $s E_k$:
\begin{equation}
H(s) \ket{k^{(\ell)}} = -(1 - s)\ket{\psi_0} \underbrace{\braket{\psi_0}{k^{(\ell)}}}_{=\, 0} + s E_k \ket{k^{(\ell)}} = s E_k \ket{k^{(\ell)}}.
\end{equation}
The inner product vanishes because $\ket{k^{(\ell)}}$ is orthogonal to $\ket{k}=\ket{k^{(0)}}$ by construction, and $\ket{\psi_0}$ is a linear combination of the $\ket{k}$ states. Thus, out of the full $2^n$-dimensional Hilbert space, only $M$ dimensions participate in the adiabatic evolution. The remaining $N-M$ states are spectators. They are exact eigenstates with known eigenvalues $sE_k$ and have zero overlap with the initial state. For Ising Hamiltonians, $M=O(\text{poly}(n))$, so the full dynamics lives in a polynomial-dimensional subspace.

Henceforth, $H(s)$ denotes its restriction to the symmetric subspace $\mathcal{H}_S$:
\begin{equation}
\label{eq:H(s)-restricted}
H(s) = -(1 - s)\ket{\psi_0}\bra{\psi_0} + s \sum_{k=0}^{M-1} E_k \ket{k}\bra{k}.
\end{equation}
This is a rank-one perturbation of the diagonal matrix $sH_z$, the setting of the Golub eigenvalue interlacing results \cite{golub1973modified}.

\begin{lemma}[Eigenvalue equation]
\label{lem:eigenvalue-equation}
Let $H(s)$ be the adiabatic Hamiltonian restricted to $\mathcal{H}_S$ as in Eq.~\eqref{eq:H(s)-restricted}. Then $\lambda(s)$ is an eigenvalue of $H(s)$ if and only if
\begin{equation}
\label{eq:eigenvalue-equation}
\frac{1}{1 - s} = \frac{1}{N} \sum_{k=0}^{M-1} \frac{d_k}{s E_k - \lambda(s)}.
\end{equation}
\end{lemma}

\begin{proof}
Let $\ket{\psi} = \sum_{k=0}^{M-1} \alpha_k \ket{k}$ be an eigenstate of $H(s)$ with eigenvalue $\lambda$, and set $\gamma = \braket{\psi_0}{\psi}$. Acting with $H(s)$ on $\ket{\psi}$ gives
\begin{equation}
H(s)\ket{\psi} = s \sum_{k=0}^{M-1} E_k \alpha_k \ket{k} - (1 - s)\gamma \ket{\psi_0} = \lambda \sum_{k=0}^{M-1} \alpha_k \ket{k}.
\end{equation}
Comparing coefficients of $\ket{k}$ and using $\braket{\psi_0}{k} = \sqrt{d_k/N}$ gives
\begin{equation}
\label{eq:alpha-k-expression}
\alpha_k = \frac{(1 - s)\gamma \sqrt{d_k/N}}{s E_k - \lambda}.
\end{equation}
Since $\gamma = \braket{\psi_0}{\psi} = (1/\sqrt{N}) \sum_{k} \alpha_k \sqrt{d_k}$, substituting Eq.~\eqref{eq:alpha-k-expression} yields
\begin{equation}
1 = \frac{1 - s}{N} \sum_{k=0}^{M-1} \frac{d_k}{s E_k - \lambda},
\end{equation}
which is equivalent to Eq.~\eqref{eq:eigenvalue-equation}. Each step is reversible: given a solution $\lambda$ of Eq.~\eqref{eq:eigenvalue-equation}, the coefficients in Eq.~\eqref{eq:alpha-k-expression} define an eigenstate (after normalization), provided $\gamma \neq 0$. The case $\gamma = 0$ corresponds to $\lambda = s E_k$ for some $k$, which are the eigenvalues in $\mathcal{H}_S^\perp$ already accounted for.
\end{proof}

Viewed as a function of $\lambda$, the right-hand side of Eq.~\eqref{eq:eigenvalue-equation} is a sum of $M$ terms, each decreasing with a vertical asymptote at $\lambda = s E_k$. Between consecutive poles $s E_{k-1}$ and $s E_k$, the function decreases monotonically from $+\infty$ to $-\infty$, producing exactly one root per interval. Below the lowest pole $s E_0$, there is one additional root. The total count is $M$ eigenvalues in $\mathcal{H}_S$, consistent with the dimension.

The two lowest eigenvalues are $\lambda_0(s) < s E_0$ (ground state) and $\lambda_1(s) \in (s E_0, s E_1)$ (first excited state). The spectral gap is $g(s) = \lambda_1(s) - \lambda_0(s) > 0$. However, this ordering information alone does not yield a useful quantitative upper bound on $g(s)$ uniformly over $s \in [0,1]$. Extracting tight bounds requires analyzing the eigenvalue equation in the vicinity of the crossing.

For $M = 2$, Eq.~\eqref{eq:eigenvalue-equation} becomes
\begin{equation}
\frac{1}{1 - s} = \frac{1}{N} \cdot \frac{1}{-\lambda} + \frac{N - 1}{N} \cdot \frac{1}{s - \lambda},
\end{equation}
where we set $E_0 = 0$ and $E_1 = 1$. Clearing denominators produces the quadratic $N\lambda^2 - N(2s - 1)\lambda - s(1 - s) = 0$, whose two roots give the ground and first excited energies:
\begin{equation}
\label{eq:grover-eigenvalues}
\lambda_\pm(s) = \frac{2s - 1}{2} \pm \frac{1}{2}\sqrt{(2s - 1)^2 + \frac{4s(1-s)}{N}}.
\end{equation}
At $s = 0$, the ground energy is $\lambda_- = -1$ and the first excited energy is $\lambda_+ = 0$, consistent with the spectrum of $H(0) = -\ket{\psi_0}\bra{\psi_0}$. The gap $g(s) = \lambda_+(s) - \lambda_-(s)$ simplifies to
\begin{equation}
\label{eq:grover-gap}
g(s) = \sqrt{(2s - 1)^2 + \frac{4s(1-s)}{N}},
\end{equation}
which is minimized at $s = 1/2$ exactly, giving $g_{\min} = 1/\sqrt{N}$. This is the Roland-Cerf gap. The general theory of the next section reproduces this scaling as a special case.


\section{The Avoided Crossing}
\label{sec:avoided-crossing}

The eigenvalue equation (Lemma \ref{lem:eigenvalue-equation}) characterizes the
spectrum of $H(s)$ implicitly. To extract explicit formulas for $s^*$,
$\delta_s$, and $g_{\min}$, we analyze it near the ground-state energy. Near
the crossing, the ground and first excited states behave like a two-level
system, while higher levels enter as a perturbation controlled by the spectral
condition.

The two lowest eigenvalues have the form $\lambda(s) = s E_0 + \delta(s)$, where
$\delta(s)$ is a correction to the trivial energy $s E_0$. Writing the
eigenvalue as a perturbation of the nearest pole isolates the ground-state
contribution and converts the implicit equation into an explicit power series.
This is a standard technique for rank-one updates of diagonal eigenvalue
problems \cite{golub1973modified}. Substituting into
Eq.~\eqref{eq:eigenvalue-equation} gives
\begin{equation}
\label{eq:delta-equation}
-\frac{d_0}{N \delta} + \frac{1}{N} \sum_{k=1}^{M-1} \frac{d_k}{s(E_k - E_0) - \delta} = \frac{1}{1 - s}.
\end{equation}
The first term has a pole at $\delta = 0$. The sum has poles at
$\delta = s(E_k - E_0)$ for $k \geq 1$. When $|\delta| \ll s \Delta$
(guaranteed by the spectral condition), the sum can be expanded in powers of
$\delta/(s(E_k - E_0))$:
\begin{equation}
\frac{1}{N} \sum_{k=1}^{M-1} \frac{d_k}{s(E_k - E_0) - \delta} = \frac{1}{s} \left( A_1 + \frac{\delta}{s} A_2 + \frac{\delta^2}{s^2} A_3 + \cdots \right).
\end{equation}
Truncating at the $A_2$ term and rearranging Eq.~\eqref{eq:delta-equation} gives a quadratic in $\delta$ whose two roots are the corrections $\delta_0^+(s)$ and $\delta_0^-(s)$ for the first excited and ground states, respectively:
\begin{equation}
\label{eq:delta-pm-formula}
\delta_0^\pm(s) = \frac{s(A_1 + 1)}{2 A_2 (1 - s)} \left[ \left(s - s^*\right) \pm \sqrt{\left(s^* - s\right)^2 + \frac{4 A_2 d_0}{N (A_1 + 1)^2}(1 - s)^2} \right],
\end{equation}
Here $\delta_0^+(s) > 0$ corresponds to the first excited state and
$\delta_0^-(s) < 0$ to the ground state. The superscript indicates the sign of
the correction relative to $sE_0$. The crossing position is
\begin{equation}
\label{eq:s-star-def}
s^* = \frac{A_1}{A_1 + 1}.
\end{equation}
The problem Hamiltonian has $M$ eigenvalues and $M$ degeneracies, so in
principle there are $2M$ free spectral parameters. Yet the crossing location
depends on one weighted average, $A_1$. This reduction is what makes a
closed-form schedule possible despite rich spectral structure. For Ising
Hamiltonians with $\Delta \geq 1/\text{poly}(n)$, $A_1$ is polynomially bounded
above. In the hard-search regime $d_0 \ll N$, one also has $A_1=\Omega(1)$, so
$s^*$ stays away from $0$. As $A_1\to\infty$ (many levels close to the ground
state), $s^*\to 1$. For small $A_1$, $s^*$ moves toward $0$.

The crossing position is the balance point in the eigenvalue equation, $A_1/s^* = 1/(1 - s^*)$. The left side is the aggregate pull of the excited spectrum toward $sE_0$, and the right side is the projector contribution. At $s=s^*$, the linear coefficient in the quadratic for $\delta$ (Eq.~\eqref{eq:delta-pm-formula}) vanishes, so the roots $\delta_0^\pm$ are symmetric about zero. The minimum gap is then set by the constant term $d_0/N$, which is why ground-state degeneracy controls the opening size.

How good is the truncation? The actual roots $\delta_\pm(s)$ of the full
equation differ from $\delta_0^\pm(s)$ by a relative error controlled by the
spectral condition. The next result makes this precise. Its proof uses the
intermediate value theorem on the full equation after bounding the remainder
with $A_3$ and the spectral condition. The technique was developed for optimal
spatial search via continuous-time quantum walks
\cite{chakraborty2020optimality}, where the same rank-one perturbation
structure appears with a graph Laplacian replacing the diagonal Hamiltonian. The
adaptation to the AQO setting appears in \cite{braida2024unstructured}.

\begin{lemma}[Validity of approximation]
\label{lem:validity-approximation}
Let $H_z$ satisfy the spectral condition (Definition \ref{def:spectral-condition}) with constant $c \approx 0.02$, and define
\begin{equation}
\label{eq:delta-s-def}
\delta_s = \frac{2}{(A_1 + 1)^2} \sqrt{\frac{d_0 A_2}{N}}.
\end{equation}
Then for any $s \in \mathcal{I}_{s^*} = [s^* - \delta_s, \; s^* + \delta_s]$, there exists a constant $\eta \ll 1$ such that the two lowest eigenvalues of $H(s)$ satisfy
\begin{align}
\delta_+(s) &\in \left( (1 - \eta)\, \delta_0^+(s), \; (1 + \eta)\, \delta_0^+(s) \right), \\
\delta_-(s) &\in \left( (1 + \eta)\, \delta_0^-(s), \; (1 - \eta)\, \delta_0^-(s) \right),
\end{align}
where $\delta_0^\pm(s)$ are given by Eq.~\eqref{eq:delta-pm-formula}.
\end{lemma}

The proof evaluates the full equation~\eqref{eq:delta-equation} at $\delta_0^\pm(1 \pm \eta)$ and shows, using the spectral condition to bound the truncated Taylor remainder, that the full equation changes sign between these points. The intermediate value theorem then guarantees a root in the interval. The spectral condition enters through the bound $|\delta_0^\pm(s)|/(s\Delta) \leq \kappa c < 1$, where $\kappa$ is a constant depending on $c$, ensuring the geometric series in the Taylor expansion converges. The constant $c \approx 0.02$ is sufficient for $\eta \leq 0.1$. The complete calculation appears in the appendix of \cite{braida2024unstructured}.

Since both corrections are approximated to within $1 \pm \eta$, the spectral
gap $g(s) = \delta_+(s) - \delta_-(s)$ is within a factor of $1 \pm 2\eta$ of
$\delta_0^+(s) - \delta_0^-(s)$, which evaluates to
\begin{equation}
\label{eq:gap-formula-window}
g(s) = (1 \pm 2\eta) \cdot \frac{s(A_1 + 1)}{A_2(1 - s)} \sqrt{\left(s^* - s\right)^2 + \frac{4 A_2 d_0}{N(A_1 + 1)^2}(1 - s)^2}.
\end{equation}
At $s = s^*$, the first term under the square root vanishes, leaving only the second:
\begin{equation}
\label{eq:gmin-formula}
g_{\min} = g(s^*) \geq (1 - 2\eta) \cdot \frac{2 A_1}{A_1 + 1} \sqrt{\frac{d_0}{N A_2}}.
\end{equation}
The gap scales as $\sqrt{d_0/N}$ with corrections from spectral structure. The
factor $2A_1/(A_1 + 1)$ captures crossing position. A crossing near the boundary
($s^* \to 0$ or $s^* \to 1$) reduces the gap. The factor $\sqrt{d_0/N}$ is the
Grover-like contribution. More solutions (larger $d_0$) increase the gap and
reduce runtime. The factor $1/\sqrt{A_2}$ encodes spectral structure beyond the
simplest two-level case.

An exact algebraic identity connects $s^*$, $\delta_s$, and the leading-order minimum gap. Writing $\hat{g} = \frac{2A_1}{A_1+1}\sqrt{\frac{d_0}{NA_2}}$ for the leading-order expression, direct substitution gives
\begin{equation}
\label{eq:gmin-deltas-relation}
\frac{s^*(A_1 + 1)^2}{A_2} \cdot \delta_s = \hat{g},
\end{equation}
and by Eq.~\eqref{eq:gmin-formula}, $g_{\min} \geq (1 - 2\eta)\hat{g}$. This relation will be used in Chapter 7 to verify the runtime calculation.

Three regions partition $[0, 1]$ based on the crossing.
\begin{equation}
\label{eq:three-regions}
\mathcal{I}_{s^\leftarrow} = [0, \, s^* - \delta_s), \qquad
\mathcal{I}_{s^*} = [s^* - \delta_s, \, s^* + \delta_s], \qquad
\mathcal{I}_{s^\rightarrow} = (s^* + \delta_s, \, 1].
\end{equation}
\begin{lemma}[Gap within the crossing window]
\label{lem:gap-in-window}
Let $H_z$ satisfy the spectral condition with constant $c$, and define
\begin{equation}
\label{eq:kappa-prime}
\kappa' = \frac{(1 + 2\eta)(1 + 2c)}{(1 - 2\eta)(1 - 2c)} \sqrt{1 + (1 - 2c)^2}.
\end{equation}
Then for any $s \in \mathcal{I}_{s^*}$,
\begin{equation}
\label{eq:gap-window-bounds}
g_{\min} \leq g(s) \leq \kappa' \cdot g_{\min}.
\end{equation}
\end{lemma}

\begin{proof}
The lower bound is immediate from the definition of $g_{\min}$ as the minimum over $\mathcal{I}_{s^*}$. For the upper bound, start from Eq.~\eqref{eq:gap-formula-window} with $|s - s^*| \leq \delta_s$:
\begin{equation}
g(s) \leq \frac{s(A_1 + 1)}{A_2(1 - s)} \sqrt{\delta_s^2 + \frac{4 A_2 d_0}{N(A_1+1)^2}(1 - s)^2}.
\end{equation}
Factoring out $(A_1 + 1) \delta_s (1-s)$ under the square root and using $s/s^* \leq 1 + \delta_s/s^*$:
\begin{equation}
g(s) \leq \frac{s^*(A_1 + 1)^2}{A_2} \delta_s \cdot \frac{s}{s^*} \cdot \sqrt{\frac{1}{(1-s)^2(A_1+1)^2} + 1}.
\end{equation}
The first factor equals $\hat{g}$ by Eq.~\eqref{eq:gmin-deltas-relation}. The spectral condition gives $\delta_s/(1 - s^*) \leq 2c$ and $\delta_s/s^* \leq 2c$. To see the first, compute
\begin{equation}
\frac{\delta_s}{1 - s^*} = \frac{2}{1 + A_1}\sqrt{\frac{d_0 A_2}{N}} = \frac{2 A_2 \Delta}{1 + A_1} \cdot \frac{1}{\Delta}\sqrt{\frac{d_0}{A_2 N}} \leq 2 s^* c \leq 2c,
\end{equation}
where we used $A_2 \Delta/(1 + A_1) \leq A_1/(1+A_1) = s^*$. The bound $\delta_s/s^* \leq 2c$ follows similarly. Substituting into the upper bound:
\begin{equation}
g(s) \leq (1 + 2\eta) \hat{g} \cdot (1 + 2c) \sqrt{1 + (1 - 2c)^2} \leq \kappa' \cdot g_{\min},
\end{equation}
where the factor $(1 + 2\eta)$ comes from the upper approximation in Eq.~\eqref{eq:gap-formula-window}, and the last step uses $\hat{g} \leq g_{\min}/(1 - 2\eta)$.
\end{proof}

Inside $\mathcal{I}_{s^*}$, the gap is $\Theta(g_{\min})$. Outside, it is
strictly larger, as the next section establishes. The avoided crossing is
localized.

Specializing to unstructured search, with $A_1 = A_2 = (N-1)/N$:
\begin{align}
s^* &= \frac{(N-1)/N}{(N-1)/N + 1} = \frac{N - 1}{2N - 1} \approx \frac{1}{2}, \label{eq:grover-s-star} \\
g_{\min} &= \frac{2(N-1)/(2N-1)}{\sqrt{N \cdot (N-1)/N}} = \frac{2(N-1)}{(2N-1)\sqrt{N-1}} \approx \frac{1}{\sqrt{N}}, \label{eq:grover-gmin} \\
\delta_s &= \frac{2N^2}{(2N-1)^2} \sqrt{\frac{N-1}{N^2}} \approx \frac{1}{2\sqrt{N}}. \label{eq:grover-deltas}
\end{align}
The crossing is at $s^* \approx 1/2$, the minimum gap scales as $1/\sqrt{N}$, and the window width scales as $1/\sqrt{N}$. These agree asymptotically with the exact quadratic solution in Eq.~\eqref{eq:grover-gap}, confirming the general theory reproduces the known scaling. The small discrepancy between $s^* = (N-1)/(2N-1)$ and the exact minimum at $s = 1/2$ is a higher-order effect of the two-level truncation, vanishing as $O(1/N)$.


\section{Gap Structure}
\label{sec:gap-structure}

The adiabatic schedule requires the gap everywhere, not just near the crossing. The local adaptive schedule speeds up where the gap is large and slows where it is small, so the runtime depends on the gap profile across the full interval $[0,1]$. Inside $\mathcal{I}_{s^*}$, the gap is $\Theta(g_{\min})$. Outside it, the gap grows linearly. Proving this split requires different techniques on the two sides, and that split drives the structure of Chapter 6.

\begin{lemma}[Gap to the left of the crossing]
\label{lem:gap-left-preview}
For any $s \in \mathcal{I}_{s^\leftarrow} = [0, \, s^* - \delta_s)$, the spectral gap of $H(s)$ satisfies
\begin{equation}
\label{eq:gap-left-bound}
g(s) \geq \frac{A_1(A_1 + 1)}{A_2} (s^* - s).
\end{equation}
\end{lemma}

Why does this hold? One route uses the variational principle. An explicit ansatz
$\ket{\phi}$ gives an upper bound $\lambda_0(s) \leq \bra{\phi} H(s) \ket{\phi}$,
while the eigenvalue equation gives the lower bound
$\lambda_1(s) \geq sE_0$. The ansatz is
\begin{equation}
\label{eq:variational-ansatz}
\ket{\phi} = \frac{1}{\sqrt{A_2 N}} \sum_{k=1}^{M-1} \frac{\sqrt{d_k}}{E_k - E_0} \ket{k}.
\end{equation}
This ansatz concentrates amplitude near the ground energy and yields a tight
upper bound on $\lambda_0(s)$. A second route uses concavity. Because
$\lambda_0(s)=\min_{\ket{\psi}}\bra{\psi}H(s)\ket{\psi}$ is the pointwise minimum
of linear functions in $s$, it is concave. The tangent line at $s^*$ therefore
lies above $\lambda_0(s)$. Combining that tangent bound with
$\lambda_1(s)\ge sE_0$ reproduces Eq.~\eqref{eq:gap-left-bound}. Chapter 6
develops both arguments in detail.

\begin{lemma}[Gap to the right of the crossing]
\label{lem:gap-right-preview}
Assume $A_1 \geq 1/2$ (equivalently $s^* \geq 1/3$). Let $k = 1/4$, $a = 4k^2 \Delta/3$, and
\begin{equation}
\label{eq:s0-def}
s_0 = s^* - \frac{k \, g_{\min}(1 - s^*)}{a - k \, g_{\min}}.
\end{equation}
Then for all $s \geq s^*$, the spectral gap of $H(s)$ satisfies
\begin{equation}
\label{eq:gap-right-bound}
g(s) \geq \frac{\Delta}{30} \cdot \frac{s - s_0}{1 - s_0}.
\end{equation}
\end{lemma}

This bound is linear in $s-s_0$, with slope proportional to $\Delta$. The proof strategy differs from the left side. One places a line $\gamma(s)=sE_0+\beta(s)$ between the two lowest eigenvalues and then uses Sherman-Morrison \cite{sherman_morrison} to control the resolvent norm $\lVert R_{H(s)}(\gamma)\rVert$. This yields $g(s)\ge 2/\lVert R_{H(s)}(\gamma)\rVert$. The constants $k=1/4$ and $a=4k^2\Delta/3$ are chosen so that the auxiliary function $f(s)$ decreases monotonically on $[s^*,1]$, producing the clean slope constant $\Delta/30$.

At the window boundary, both bounds match $g_{\min}$ in order. At
$s = s^* - \delta_s$, the left bound gives
\begin{equation}
g(s^* - \delta_s) \geq \frac{A_1(A_1+1)}{A_2} \cdot \delta_s = \frac{2A_1}{A_1 + 1}\sqrt{\frac{d_0}{N A_2}} = \hat{g},
\end{equation}
which satisfies $\hat{g} = \Theta(g_{\min})$ by Eq.~\eqref{eq:gmin-formula}. At
$s = s^*$ (right boundary start), $\beta(s^*) \geq k\, g_{\min}$, so
$g(s^*) \geq 2k\, g_{\min}/(1 + f(s^*)) = O(g_{\min})$ since
$f(s^*) = \Theta(1)$. The gap profile is therefore continuous across region
boundaries. It dips to $g_{\min}$ at $s^*$ and rises linearly on both sides.

With the gap profile in hand, runtime follows from the optimal local adaptive schedule \cite{vandam2001powerful, roland2002quantum}, where $ds/dt \propto g(s)^2$. Evolution therefore slows quadratically as the gap decreases. The total runtime is
\begin{equation}
\label{eq:runtime-integral-preview}
T \propto \int_0^1 \frac{ds}{g(s)^2},
\end{equation}
split across the three regions. In the left and right regions, linear gap
growth gives $1/g(s)^2 \propto 1/(s-s^*)^2$, so each outer contribution scales
like $1/\delta_s$ at the window boundary. Inside the window, the gap is
approximately constant at $g_{\min}$ and contributes $2\delta_s/g_{\min}^2$.
This window term dominates. The bottleneck is therefore a
$\Theta(1/\sqrt{N})$-wide interval around $s^*$.
\begin{equation}
\frac{\delta_s}{g_{\min}^2} \propto \frac{\sqrt{A_2}}{A_1(A_1+1) \Delta^2} \sqrt{\frac{N}{d_0}},
\end{equation}
yielding the optimal runtime \cite{braida2024unstructured}. For the Ising Hamiltonian with $A_1, A_2 = O(\text{poly}(n))$ and $\Delta \geq 1/\text{poly}(n)$, this gives $T = \widetilde{O}(\sqrt{N/d_0})$, matching the Grover lower bound up to polylogarithmic factors. Chapter 7 carries out this calculation rigorously.


\section{What Remains}
\label{sec:central-questions}

At this point, the structure is in place and the remaining steps are focused. Chapter 6 proves the outer-region gap bounds. Chapter 7 converts those bounds into the optimal runtime. Chapter 8 accounts for the pre-computation cost required to realize that schedule.

Given the complete gap profile, the optimal runtime is
\begin{equation}
\label{eq:runtime-preview}
T = O\left(\frac{1}{\varepsilon} \cdot \frac{\sqrt{A_2}}{A_1(A_1+1) \Delta^2} \cdot \sqrt{\frac{N}{d_0}}\right),
\end{equation}
where $\varepsilon$ is the target error. For Ising Hamiltonians, this is $\widetilde{O}(\sqrt{N/d_0})$, matching the lower bound of Farhi, Goldstone, and Gutmann \cite{farhi2008fail}. Adiabatic quantum optimization achieves the Grover speedup. Chapter 7 derives this rigorously.

The local adaptive schedule requires $s^*$ to precision
$O(\delta_s)=O(2^{-n/2})$, so $A_1$ must be known at comparable precision.
Approximating $A_1$ is already hard much earlier on this scale. At additive
error $1/\text{poly}(n)$, two oracle queries suffice to solve 3-SAT, so the
task is NP-hard. Exact computation of $A_1$, or approximation to
$O(2^{-\text{poly}(n)})$, is $\#$P-hard because polynomial interpolation
recovers all degeneracies $d_k$ from $O(\text{poly}(n))$ exact queries. Chapter
8 proves both statements and quantifies the resulting precision gap.

In the circuit model, Grover's algorithm reaches
$\widetilde{O}(\sqrt{N/d_0})$ without pre-computing any spectral parameter.
Oracle queries gather the needed information during execution. In the adiabatic
framework, by contrast, the schedule is fixed before evolution starts, which
forces NP-hard pre-computation. In our view, this asymmetry is not a proof
artifact. It reflects a genuine model-level difference. The adiabatic speedup is
real, but it is conditional on solving a hard preprocessing problem first
\cite{braida2024unstructured}. Chapter 9 makes this tradeoff explicit through an
uninformed-schedule separation, an interpolation theorem for partial
information, and an adaptive measurement protocol that bypasses classical
hardness.

In the unstructured case, the limitation vanishes: $A_1 = (N-1)/N \approx 1$ is trivially known, so $s^* \approx 1/2$ requires no hard computation. The complexity arises only for problem Hamiltonians with rich spectral structure, where the degeneracies $d_k$ and energy gaps $E_k - E_0$ are not known in advance. The Ising Hamiltonian encoding an NP-hard problem is precisely such a case.
