# Complexity-Theoretic Foundations of Quantum Supremacy Experiments

Scott Aaronson∗ Lijie Chen†

# Abstract

In the near future, there will likely be special-purpose quantum computers with 40-50 high-quality qubits. This paper lays general theoretical foundations for how to use such devices to demonstrate “quantum supremacy”: that is, a clear quantum speedup for some task, motivated by the goal of overturning the Extended Church-Turing Thesis as confidently as possible.

First, we study the hardness of sampling the output distribution of a random quantum circuit, along the lines of a recent proposal by the Quantum AI group at Google. We show that there’s a natural average-case hardness assumption, which has nothing to do with sampling, yet implies that no polynomial-time classical algorithm can pass a statistical test that the quantum sampling procedure’s outputs do pass. Compared to previous work—for example, on BosonSampling and IQP—the central advantage is that we can now talk directly about the observed outputs, rather than about the distribution being sampled.

Second, in an attempt to refute our hardness assumption, we give a new algorithm, inspired by Savitch’s Theorem, for simulating a general quantum circuit with $n$ qubits and depth $d$ in polynomial space and $d ^ { O ( n ) }$ time. We then discuss why this and other known algorithms fail to refute our assumption.

Third, resolving an open problem of Aaronson and Arkhipov, we show that any strong quantum supremacy theorem—of the form “if approximate quantum sampling is classically easy, then the polynomial hierarchy collapses”—must be non-relativizing. This sharply contrasts with the situation for exact sampling.

Fourth, refuting a conjecture by Aaronson and Ambainis, we show that there is a sampling task, namely Fourier Sampling, with a 1 versus linear separation between its quantum and classical query complexities.

Fifth, in search of a “happy medium” between black-box and non-black-box arguments, we study quantum supremacy relative to oracles in $\mathsf { P } / \mathsf { p o l y }$ . Previous work implies that, if one-way functions exist, then quantum supremacy is possible relative to such oracles. We show, conversely, that some computational assumption is needed: if $\mathsf { S a m p B P P } = \mathsf { S a m p B Q P }$ and NP $\subseteq$ BPP, then quantum supremacy is impossible relative to oracles with small circuits.

# 1 Introduction

The Extended Church-Turing Thesis, or ECT, asserts that every physical process can be simulated by a deterministic or probabilistic Turing machine with at most polynomial overhead. Since the 1980s—and certainly since the discovery of Shor’s algorithm [Sho97] in the 1990s—computer scientists have understood that quantum mechanics might refute the ECT in principle. Today, there are actual experiments being planned (e.g., $[ \mathrm { B I S } ^ { + } 1 6 ] $ ) with the goal of severely challenging the ECT in practice. These experiments don’t yet aim to build full, fault-tolerant, universal quantum computers, but “merely” to demonstrate some quantum speedup over the best known or conjectured classical algorithms, for some possibly-contrived task, as confidently as possible. In other words, the goal is to answer the skeptics [Kal11, Lev03] who claim that genuine quantum speedups are either impossible in theory, or at any rate, are hopelessly out of reach technologically. Recently, the term “quantum supremacy” has come into vogue for such experiments,1 although the basic goal goes back several decades, to the beginning of quantum computing itself.

Before going further, we should address some common misunderstandings about quantum supremacy.

The ECT is an asymptotic claim, which of course means that no finite experiment could render a decisive verdict on it, even in principle. But this hardly makes experiments irrelevant. If

(1) a quantum device performed some task (say) $1 0 ^ { 1 5 }$ times faster than a highly optimized simulation written by “adversaries” and running on a classical computing cluster, with the quantum/classical gap appearing to increase exponentially with the instance size across the whole range tested, and   
(2) this observed performance closely matched theoretical results that predicted such an exponential quantum speedup for the task in question, and   
(3) all other consistency checks passed (for example: removing quantum behavior from the experimental device destroyed the observed speedup),

this would obviously “raise the stakes” for anyone who still believed the ECT! Indeed, when some quantum computing researchers have criticized previous claims to have experimentally achieved quantum speedups (see, e.g., [Aar15]), it has typically been on the ground that, in those researchers’ view, the experiments failed to meet one or more of the conditions above.

It’s sometimes claimed that any molecule in Nature or the laboratory, for which chemists find it computationally prohibitive to solve the Schrodinger equation and calculate its ground state, ¨ already provides an example of “quantum supremacy.” The idea, in other words, is that such a molecule constitutes a “useful quantum computer, for the task of simulating itself.”

For us, the central problem with this idea is that in theoretical computer science, we care less about individual instances than about solving problems (i.e., infinite collections of instances) in a more-or-less uniform way. For any one molecule, the difficulty in simulating classically it might reflect genuine asymptotic hardness, but it might also reflect other issues (e.g., a failure to exploit special structure in the molecule, or the same issues of modeling error, constant-factor overheads, and so forth that arise even in simulations of classical physics).

Thus, while it’s possible that complex molecules could form the basis for a convincing quantum supremacy demonstration, we believe more work would need to be done. In particular, one would want a device that could synthesize any molecule in some theoretically infinite class—and one would then want complexitytheoretic evidence that the general problem, of simulating a given molecule from that class, is asymptotically hard for a classical computer. And in such a case, it would seem more natural to call the synthesis machine the “quantum computer,” rather than the molecules themselves!

In summary, we regard quantum supremacy as a central milestone for quantum computing that hasn’t been reached yet, but that might be reached in the near future. This milestone is essentially negative in character: it has no obvious signature of the sort familiar to experimental physics, since it simply amounts to the nonexistence of an efficient classical algorithm to simulate a given quantum process. For that reason, the tools of theoretical computer science will be essential to understand when quantum supremacy has or hasn’t been achieved. So in our view, even if it were uninteresting as TCS, there would still be an urgent need for TCS to contribute to the discussion about which quantum supremacy experiments to do, how to verify their results, and what should count as convincing evidence that classical simulation is hard. Happily, it turns out that there is a great deal here of intrinsic TCS interest as well.

# 1.1 Supremacy from Sampling

In recent years, a realization has crystallized that, if our goal is to demonstrate quantum supremacy (rather than doing anything directly useful), then there are good reasons to shift our attention from decision and function problems to sampling problems: that is, problems where the goal is to sample an $n$ -bit string, either exactly or approximately, from a desired probability distribution.

A first reason for this is that demonstrating quantum supremacy via a sampling problem doesn’t appear to require the full strength of a universal quantum computer. Indeed, there are now at least a half-dozen proposals [AA13, BJS10, FH16, TD04, MFF14, JVdN14, ABKM16] for special-purpose devices that could efficiently solve sampling problems believed to be classically intractable, without being able to solve every problem in the class BQP, or for that matter even every problem in P. Besides their intrinsic physical and mathematical interest, these intermediate models might be easier to realize than a universal quantum computer. In particular, because of their simplicity, they might let us avoid the need for the full machinery of quantum fault-tolerance [ABO97]: something that adds a theoretically polylogarithmic but enormous-inpractice overhead to quantum computation. Thus, many researchers now expect that the first convincing demonstration of quantum supremacy will come via this route.

A second reason to focus on sampling problems is more theoretical: in the present state of complexity theory, we can arguably be more confident that certain quantum sampling problems really are classically hard, than we are that factoring (for example) is classically hard, or even that ${ \mathsf { B P P } } \neq { \mathsf { B Q P } }$ . Already in 2002, Terhal and DiVincenzo [TD04] noticed that, while constant-depth quantum circuits can’t solve any classically intractable decision problems,2 they nevertheless have a curious power: namely, they can sample probability distributions that can’t be sampled in classical polynomial time, unless ${ \mathsf { B Q P } } \subseteq { \mathsf { A M } }$ , which would be a surprising inclusion of complexity classes. Then, in 2004, Aaronson showed that $\mathsf { P o s t B Q P = }$ PP, where PostBQP means BQP with the ability to postselect on exponentially-unlikely measurement outcomes. This had the immediate corollary that, if there’s an efficient classical algorithm to sample the output distribution of an arbitrary quantum circuit—or for that matter, any distribution whose probabilities are multiplicatively close to the correct ones—then

$$
{ \mathsf { P P } } = { \mathsf { P o s t B Q P } } = { \mathsf { P o s t B P P } } \subseteq { \mathsf { B P P } } ^ { \mathsf { N P } } .
$$

By Toda’s Theorem [Tod91], this implies that the polynomial hierarchy collapses to the third level.

Related to that, in 2009, Aaronson [Aar10] showed that, while it was (and remains) a notorious open problem to construct an oracle relative to which BQP $\nless$ PH, one can construct oracular sampling and relation problems that are solvable in quantum polynomial time, but that are provably not solvable in randomized polynomial time augmented with a PH oracle.

Then, partly inspired by that oracle separation, Aaronson and Arkhipov [AA13] proposed BosonSampling: a model that uses identical photons traveling through a network of beamsplitters and phaseshifters to solve classically hard sampling problems. Aaronson and Arkhipov proved that a polynomial-time exact classical simulation of BosonSampling would collapse PH. They also gave a plausible conjecture implying that even an approximate simulation would have the same consequence. Around the same time, Bremner, Jozsa, and Shepherd [BJS10] independently proposed the Commuting Hamiltonians or IQP (“Instantaneous Quantum Polynomial-Time”) model, and showed that it had the same property, that exact classical simulation would collapse PH. Later, Bremner, Montanaro, and Shepherd [BMS15, BMS16] showed that, just like for BosonSampling, there are plausible conjectures under which even a fast classical approximate simulation of the IQP model would collapse PH.

Since then, other models have been proposed with similar behavior. To take a few examples: Farhi and Harrow [FH16] showed that the so-called Quantum Approximate Optimization Algorithm, or QAOA, can sample distributions that are classically intractable unless PH collapses. Morimae, Fujii, and Fitzsimons [MFF14] showed the same for the so-called One Clean Qubit or DQC1 model, while Jozsa and Van den Nest [JVdN14] showed it for stabilizer circuits with magic initial states and nonadaptive measurements, and Aaronson et al. [ABKM16] showed it for a model based on integrable particle scattering in $1 + 1$ dimensions. In retrospect, the constant-depth quantum circuits considered by Terhal and DiVincenzo [TD04] also have the property that fast exact classical simulation would collapse PH.

Within the last four years, quantum supremacy via sampling has made the leap from complexity theory to a serious experimental prospect. For example, there have by now been many small-scale demonstrations of BosonSampling in linear-optical systems, with the current record being a 6-photon experiment by Carolan et al. $[ \mathrm { C H S ^ { + } } 1 5 ]$ . To scale up to (say) 30 or 40 photons—as would be needed to make a classical simulation of the experiment suitably difficult—seems to require more reliable single-photon sources than exist today. But some experts (e.g., [Rud16, PGHAG15]) are optimistic that optical multiplexing, superconducting resonators, or other technologies currently under development will lead to such photon sources. In the meantime, as we mentioned earlier, Boixo et al. $[ \mathrm { B } \mathrm { I S } ^ { + } 1 6 ]$ have publicly detailed a plan, currently underway at Google, to perform a quantum supremacy experiment involving random circuits applied to a 2D array of 40-50 coupled superconducting qubits. So far, the group at Google has demonstrated the preparation and measurement of entangled states on a linear array of 9 superconducting qubits $[ \mathrm { K B F ^ { + } } 1 5 ]$ .

# 1.2 Theoretical Challenges

Despite the exciting recent progress in both theory and experiment, some huge conceptual problems have remained about sampling-based quantum supremacy. These problems are not specific to any one quantum supremacy proposal (such as BosonSampling, IQP, or random quantum circuits), but apply with minor variations to all of them.

Verification of Quantum Supremacy Experiments. From the beginning, there was the problem of how to verify the results of a sampling-based quantum supremacy experiment. In contrast to (say) factoring and discrete log, for sampling tasks such as BosonSampling, it seems unlikely that there’s any NP witness certifying the quantum experiment’s output, let alone an NP witness that’s also the experimental output itself. Rather, for the sampling tasks, not only simulation but even verification might need classical exponential time. Yet, while no one has yet discovered a general way around this,3 it’s far from the fatal problem that some have imagined. The reason is simply that experiments can and will target a “sweet spot,” of (say) 40-50 qubits, for which classical simulation and verification of the results is difficult but not impossible.

Still, the existing verification methods have a second drawback. Namely, once we’ve fixed a specific verification test for sampling from a probability distribution $\mathcal { D }$ , we ought to consider, not merely all classical algorithms that sample exactly or approximately from $\mathcal { D }$ , but all classical algorithms that output anything that passes the verification test. To put it differently, we ought to talk not about the sampling problem itself, but about an associated relation problem: that is, a problem where the goal is to produce any output that satisfies a given condition.

As it happens, in 2011, Aaronson [Aar14] proved an extremely general connection between sampling problems and relation problems. Namely, given any approximate sampling problem $S$ , he showed how to define a relation problem $R _ { S }$ such that, for every “reasonable” model of computation (classical, quantum, etc.), $R _ { S }$ is efficiently solvable in that model if and only if $S$ is. This had the corollary that

$$
{ \mathsf { S a m p B P P } } = { \mathsf { S a m p B Q P } } \iff { \mathsf { F B P P } } = { \mathsf { F B Q P } } ,
$$

where SampBPP and SampBQP are the classes of approximate sampling problems solvable in polynomial time by randomized and quantum algorithms respectively, and FBPP and FBQP are the corresponding classes of relation problems. Unfortunately, Aaronson’s construction of $R _ { S }$ involved Kolmogorov complexity: basically, one asks for an $m$ -tuple of strings, $\langle x _ { 1 } , \dots , x _ { m } \rangle$ , such that

$$
K \left( x _ { 1 } , \ldots , x _ { m } \right) \geq \log _ { 2 } \frac { 1 } { p _ { 1 } \cdot \cdot \cdot p _ { m } } - O \left( 1 \right) ,
$$

where $p _ { i }$ is the desired probability of outputting $x _ { i }$ in the sampling problem. And of course, verifying such a condition is extraordinarily difficult, even more so than calculating the probabilities $p _ { 1 } , \ldots , p _ { m }$ .4 For this reason, it’s strongly preferable to have a condition that talks only about the largeness of the $p _ { i }$ ’s, and not about the algorithmic randomness of the $x _ { i }$ ’s. But then hardness for the sampling problem no longer necessarily implies hardness for the relation problem, so a new argument is needed.

Supremacy Theorems for Approximate Sampling. A second difficulty is that any quantum sampling device is subject to noise and decoherence. Ultimately, of course, we’d like hardness results for quantum sampling that apply even in the presence of experimentally realistic errors. Very recently, Bremner, Montanaro, and Shepherd [BMS16] and Fujii [Fuj16] have taken some promising initial steps in that direction. But even if we care only about the smallest “experimentally reasonable” error—namely, an error that corrupts the output distribution $\mathcal { D }$ to some other distribution $\mathcal { D } ^ { \prime }$ that’s $\varepsilon$ -close to $\mathcal { D }$ in variation distance— Aaronson and Arkhipov [AA13] found that we already engage substantial new open problems in complexity theory, if we want evidence for classical hardness. So for example, their hardness argument for approximate BosonSampling depended on the conjecture that there’s no ${ \mathsf { B P P } } ^ { \mathsf { N P } }$ algorithm to estimate the permanent of an i.i.d. Gaussian matrix $A \sim N ( 0 , 1 ) _ { \mathbb { C } } ^ { n \times n }$ , with high probability over the choice of $A$ .

Of course, one could try to close that loophole by proving that this Gaussian permanent estimation problem is $\# \mathsf { P }$ -hard, which is indeed a major challenge that Aaronson and Arkhipov left open. But this situation also raises more general questions. For example, is there an implication of the form “if $\mathsf { S a m p B P P } = \mathsf { S a m p B Q P }$ , then PH collapses,” where again SampBPP and SampBQP are the approximate sampling versions of BPP and BQP respectively? Are there oracles relative to which such an implication does not hold?

Quantum Supremacy Relative to Oracles. A third problem goes to perhaps the core issue of complexity theory (both quantum and classical): namely, we don’t at present have a proof of $\mathsf { P } \neq \mathsf { P S P A C E }$ , much less of ${ \mathsf { B P P } } \neq { \mathsf { B Q P } }$ or $\mathsf { S a m p B P P \ne S a m p B Q P }$ , less still of the hardness of specific problems like factoring or estimating Gaussian permanents. So what reason do we have to believe that any of these problems are hard? Part of the evidence has always come from oracle results, which we often can prove unconditionally.

Particularly in quantum complexity theory, oracle separations can already be highly nontrivial, and give us a deep intuition for why all the “standard” algorithmic approaches fail for some problem.

On the other hand, we also know, from results like ${ | \mathsf { P } = \mathsf { P S P A C E } }$ [Sha92], that oracle separations can badly mislead us about what happens in the unrelativized world. Generally speaking, we might say, relying on an oracle separation is more dangerous, the less the oracle function resembles what would actually be available in an explicit problem.5

In the case of sampling-based quantum supremacy, we’ve known strong oracle separations since early in the subject. Indeed, in 2009, Aaronson [Aar10] showed that Fourier Sampling—a quantumly easy sampling problem that involves only a random oracle—requires classical exponential time, and for that matter, sits outside the entire polynomial hierarchy. But of course, in real life random oracles are unavailable. So a question arises: can we say anything about the classical hardness of Fourier Sampling with a pseudorandom oracle? More broadly, what hardness results can we prove for quantum sampling, relative to oracles that are efficiently computable? Here, we imagine that an algorithm doesn’t have access to a succinct representation of the oracle function $f$ , but it does know that a succinct representation exists (i.e., that $f \in \mathsf { P } / \mathsf { p o l y } )$ . Under that assumption, is there any hope of proving an unconditional separation between quantum and classical sampling? If not, then can we at least prove quantum supremacy under weaker (or more “generic”) assumptions than would be needed in the purely computational setting?

# 1.3 Our Contributions

In this paper, we address all three of the above challenges. Our results might look wide-ranging, but they’re held together by a single thread: namely, the quest to understand the classical hardness of quantum approximate sampling problems, and especially the meta-question of under which computational assumptions such hardness can be proven. We’ll be interested in both “positive” results, of the form “quantum sampling problem $X$ is classically hard under assumption $Y$ ,” and “negative” results, of the form “proving the classical hardness of $X$ requires assumption $Y$ .” Also, we’ll be less concerned with specific proposals such as BosonSampling, than simply with the general task of approximately sampling the output distribution of a given quantum circuit $C$ . Fortuitously, though, our focus on quantum circuit sampling will make some of our results an excellent fit to currently planned experiments—most notably, those at Google $[ \mathrm { B } \mathrm { I S } ^ { + } 1 6 ]$ , which will involve random quantum circuits on a 2D square lattice of 40 to 50 superconducting qubits. Even though we won’t address the details of those or other experiments, our results (together with other recent work $[ \mathrm { B } \mathrm { I S } ^ { + } 1 6$ , BMS16]) can help to inform the experiments—for example, by showing how the circuit depth, the verification test applied to the outputs, and other design choices affect the strength of the computational assumptions that are necessary and sufficient to conclude that quantum supremacy has been achieved.

We have five main results.

The Hardness of Quantum Circuit Sampling. Our first result, in Section 3, is about the hardness of sampling the output distribution of a random quantum circuit, along the general lines of the planned Google experiment. Specifically, we propose a simple verification test to apply to the outputs of a random quantum circuit. We then analyze the classical hardness of generating any outputs that pass that test.

More concretely, we study the following basic problem:

Problem 1 (HOG, or Heavy Output Generation). Given as input a random quantum circuit $C$ (drawn from some suitable ensemble), generate output strings $x _ { 1 } , \ldots , x _ { k }$ , at least a $2 / 3$ fraction of which have greater than the median probability in $C$ ’s output distribution.

HOG is a relation problem, for which we can verify a claimed solution in classical exponential time, by calculating the ideal probabilities $p _ { x _ { 1 } } , \ldots , p _ { x _ { k } }$ for each $x _ { i }$ to be generated by $C$ , and then checking whether enough of the $p _ { x _ { i } }$ ’s are greater than the median value (which we can estimate analytically to extremely high confidence). Furthermore, HOG is easy to solve on a quantum computer, with overwhelming success probability, by the obvious strategy of just running $C$ over and over and collecting $k$ of its outputs.6

It certainly seems plausible that HOG is exponentially hard for a classical computer. But we ask: under what assumption could that hardness be proven? To address that question, we propose a new hardness assumption:

Assumption 1 (QUATH, or the QUAntum THreshold assumption). There is no polynomial-time classical algorithm that takes as input a description of a random quantum circuit $C$ , and that guesses whether $| \langle 0 ^ { n } | \bar { C } | 0 ^ { n } \rangle | ^ { 2 }$ is greater or less than the median of all $2 ^ { n }$ of the $\vert \langle 0 ^ { n } \vert C \vert x \rangle \vert ^ { 2 }$ values, with success probability at least ${ \frac { 1 } { 2 } } + \Omega \left( { \frac { 1 } { 2 ^ { n } } } \right)$ over the choice of $C$ .

Our first result says that if QUATH is true, then HOG is hard. While this might seem nearly tautological, the important point here is that QUATH makes no reference to sampling or relation problems. Thus, we can now shift our focus from sampling algorithms to algorithms that simply estimate amplitudes, with a minuscule advantage over random guessing.

New Algorithms to Simulate Quantum Circuits. But given what a tiny advantage $\Omega \left( 2 ^ { - n } \right)$ is, why would anyone even conjecture that QUATH might be true? This brings us to our second result, in Section 4, which is motivated by the attempt to refute QUATH. We ask: what are the best classical algorithms to simulate an arbitrary quantum circuit? For special quantum circuits (e.g., those with mostly Clifford gates and a few $\mathrm { T }$ gates [BG16]), there’s been exciting recent progress on improved exponential-time simulation algorithms, but for arbitrary quantum circuits, one might think there isn’t much to say. Nevertheless, we do find something basic to say that, to our knowledge, had been overlooked earlier.

For a quantum circuit with $n$ qubits and $m$ gates, there are two obvious simulation algorithms. The first, which we could call the “Schrodinger” algorithm, stores the entire state vector in memory, using ¨ $\sim m 2 ^ { n }$ time and $\sim 2 ^ { n }$ space. The second, which we could call the “Feynman” algorithm, calculates an amplitude as a sum of terms, using $\sim 4 ^ { m }$ time and $\sim m + n$ space, as in the proof of ${ \mathsf { B Q P \subseteq P ^ { \# } P } }$ [BV97].

Now typically $m \gg n$ , and the difference between $m$ and $n$ could matter enormously in practice. For example, in the planned Google setup, $n$ will be roughly 40 or 50, while $m$ will ideally be in the thousands. Thus, $2 ^ { n }$ time is reasonable whereas $4 ^ { m }$ time is not. So a question arises:

• When $m \gg n$ , is there a classical algorithm to simulate an $n$ -qubit, $m$ -gate quantum circuit using both poly $( m , n )$ space and much less than $\exp \left( m \right)$ time—ideally, more like $\exp \left( n \right)$ ?

We show an affirmative answer. In particular, inspired by the proof of Savitch’s Theorem [Sav70], we give a recursive, sum-of-products algorithm that uses poly $( m , n )$ space and $m ^ { O ( n ) }$ time—or better yet, $\hat { d } ^ { O ( n ) }$ time, where $d$ is the circuit depth. We also show how to improve the running time further for quantum circuits subject to nearest-neighbor constraints, such as the superconducting systems currently under development. Finally, we show the existence of a “smooth tradeoff” between our algorithm and the $2 ^ { n }$ -memory Schrodinger algorithm. Namely, starting with the Schr ¨ odinger algorithm, for every desired ¨ halving of the memory usage, one can multiply the running time by an additional factor of $\sim d$ .

We hope our algorithm finds some applications in quantum simulation. In the meantime, though, the key point for this paper is that neither the Feynman algorithm, nor the Schrodinger algorithm, nor our new ¨ recursive algorithm come close to refuting QUATH. The Feynman algorithm fails to refute QUATH because it yields only a $1 / \exp \left( m \right)$ advantage over random guessing, rather than a $1 / 2 ^ { n }$ advantage. The Schrodinger ¨ and recursive algorithms have much closer to the “correct” $2 ^ { n }$ running time, but they also fail to refute QUATH because they don’t calculate amplitudes as straightforward sums, so don’t lead to polynomial-time guessing algorithms at all. Thus, in asking whether we can falsify QUATH, in some sense we’re asking how far we can go in combining the advantages of all these algorithms. This might, in turn, connect to longstanding open problems about the optimality of Savitch’s Theorem itself (e.g., L versus NL).

Interestingly, our analysis of quantum circuit simulation algorithms explains why this paper’s hardness argument for quantum circuit sampling, based on QUATH, would not have worked for quantum supremacy proposals such as BosonSampling or IQP. It works only for the more general problem of quantum circuit sampling. The reason is that for the latter, unlike for BosonSampling or IQP, there exists a parameter $m \gg n$ (namely, the number of gates) that controls the advantage that a polynomial-time classical algorithm can achieve over random guessing, even while $n$ controls the number of possible outputs. Our analysis also underscores the importance of taking $m \gg n$ in experiments meant to show quantum supremacy, and it provides some guidance to experimenters about the crucial question of what circuit depth they need for a convincing quantum supremacy demonstration.

Note that, the greater the required depth, the more protected against decoherence the qubits need to be. But the tradeoff is that the depth must be high enough that simulation algorithms that exploit limited entanglement, such as those based on tensor networks, are ruled out. Beyond that requirement, our $d ^ { O ( n ) }$ simulation algorithm gives some information about how much additional hardness one can purchase for a given increase in depth.

Strong Quantum Supremacy Theorems Must Be Non-Relativizing. Next, in Section 5, we switch our attention to a meta-question. Namely, what sorts of complexity-theoretic evidence we could possibly hope to offer for $\mathsf { S a m p B P P } \ne \mathsf { S a m p B Q P }$ : in other words, for quantum computers being able to solve approximate sampling problems that are hard classically? By Aaronson’s sampling/searching equivalence theorem [Aar14], any such evidence would also be evidence for $\mathsf { F B P P } \neq \mathsf { F B Q P }$ (where FBPP and FBQP are the corresponding classes of relation problems), and vice versa.

Of course, an unconditional proof of these separations is out of the question right now, since it would imply $\mathsf { P } \neq \mathsf { P S P A C E }$ . Perhaps the next best thing would be to show that, if $\mathsf { S a m p B P P } = \mathsf { S a m p B Q P }$ , then the polynomial hierarchy collapses. This latter is not out of the question: as we said earlier, we already know, by a simple relativizing argument, that an equivalence between quantum and classical exact sampling implies the collapse $\mathsf { P } ^ { \# \mathsf { P } } = \mathsf { P } \mathsf { H } = \mathsf { B } \mathsf { P } \mathsf { P } ^ { \mathsf { N P } }$ . Furthermore, in their work on BosonSampling, Aaronson and Arkhipov [AA13] formulated a $\# \mathsf { P }$ -hardness conjecture—namely, their so-called Permanent of Gaussians Conjecture, or PGC—that if true, would imply a generalization of that collapse to the physically relevant case of approximate sampling. More explicitly, Aaronson and Arkhipov showed that if the PGC holds, then

$$
{ \mathsf { S a m p B P P } } = { \mathsf { S a m p B Q P } } \Longrightarrow { \mathsf { P } } ^ { \# \mathsf { P } } = { \mathsf { B P P } } ^ { \mathsf { N P } } .
$$

They went on to propose a program for proving the PGC, by exploiting the random self-reducibility of the permanent. On the other hand, Aaronson and Arkhipov also explained in detail why new ideas would be needed to complete that program, and the challenge remains open.

Subsequently, Bremner, Montanaro, and Shepherd [BMS15, BMS16] gave analogous $\# \mathsf { P }$ -hardness conjectures that, if true, would also imply the implication (1), by going through the IQP model rather than through BosonSampling.

Meanwhile, nearly two decades ago, Fortnow and Rogers [FR99] exhibited an oracle relative to which ${ \mathsf { P } } = { \mathsf { B Q P } }$ and yet the polynomial hierarchy is infinite. In other words, they showed that any proof of the implication

$$
\mathsf { P } = \mathsf { B Q P } \Longrightarrow \mathsf { P H } \mathsf { c o l l a p s e s }
$$

would have to be non-relativizing. Unfortunately, their construction was extremely specific to languages (i.e., total Boolean functions), and didn’t even rule out the possibility that the implication

#

could be proven in a relativizing way. Thus, Aaronson and Arkhipov [AA13, see Section 10] raised the question of which quantum supremacy theorems hold relative to all oracles.

In Section 5, we fill in the final piece needed to resolve their question, by constructing an oracle $A$ relative to which SampBPP $=$ SampBQP and yet PH is infinite. In other words, we show that any strong supremacy theorem for quantum sampling, along the lines of what Aaronson and Arkhipov [AA13] and Bremner, Montanaro, and Shepherd [BMS15, BMS16] were seeking, must use non-relativizing techniques. In that respect, the situation with approximate sampling is extremely different from that with exact sampling.

Perhaps it’s no surprise that one would need non-relativizing techniques to prove a strong quantum supremacy theorem. In fact, Aaronson and Arkhipov [AA13] were originally led to study BosonSampling precisely because of the connection between bosons and the permanent function, and the hope that one could therefore exploit the famous non-relativizing properties of the permanent to prove hardness. All the same, this is the first time we have explicit confirmation that non-relativizing techniques will be needed.

Maximal Quantum Supremacy for Black-Box Sampling and Relation Problems. In Section 6, we turn our attention to the black-box model, and specifically to the question: what are the largest possible separations between randomized and quantum query complexities for any approximate sampling or relation problem? Here we settle another open question. In 2015, Aaronson and Ambainis [AA15] studied Fourier Sampling, in which we’re given access to a Boolean function $f : \{ 0 , 1 \} ^ { n }  \{ 0 , 1 \}$ , and the goal is to sample a string $z$ with probability ${ \widehat { f } } \left( z \right) ^ { 2 }$ , where $\widehat { f }$ is the Boolean Fourier transform of $f$ , normalized so that $\sum _ { z } \widehat { f } \left( z \right) ^ { 2 } = 1$ . This problem is trivially solvable by a quantum algorithm with only 1 query to $f$ . By contrast, Aaronson and Ambainis showed that there exists a constant $\varepsilon > 0$ such that any classical algorithm that solves Fourier Sampling, to accuracy $\varepsilon$ in variation distance, requires $\Omega \left( 2 ^ { n } / n \right)$ queries to $f$ . They conjectured that this lower bound was tight.

Here we refute that conjecture, by proving a $\Omega \left( 2 ^ { n } \right)$ lower bound on the randomized query complexity of Fourier Sampling, as long as ε is sufficiently small (say, $\frac { 1 } { 4 0 0 0 0 } )$ This implies that, for approximate sampling problems, the gap between quantum and randomized query complexities can be as large as imaginable: namely, 1 versus linear $( ! )$ .7 This sharply contrasts with the case of partial Boolean functions, for which Aaronson and Ambainis [AA15] showed that any $N$ -bit problem solvable with $k$ quantum queries is also solvable with $O \left( N ^ { 1 - 1 / 2 k } \right)$ randomized queries, and hence a constant versus linear separation is impossible. Thus, our result helps once again to underscore the advantage of sampling problems over decision problems for quantum supremacy experiments. Given the extremely close connection between Fourier Sampling and the IQP model [BJS10], our result also provides some evidence that classically simulating an $n$ -qubit IQP circuit, to within constant error in variation distance, is about as hard as can be: it might literally require $\Omega \left( 2 ^ { n } \right)$ time.

Aaronson and Ambainis [AA15] didn’t directly address the natural relational version of Fourier Sampling, which Aaronson [Aar10] had called Fourier Fishing in 2009. In Fourier Fishing, the goal is to output any string $z$ such that $\widehat { f } \left( z \right) ^ { 2 } \geq 1$ , with nontrivial success probability. Unfortunately, the best lower bound on the randomized query complexity of Fourier Fishing that follows from [Aar10] has the form $2 ^ { n ^ { \Omega ( 1 ) } }$ . As a further contribution, in Section 6 we give a lower bound of $\Omega \left( 2 ^ { n } / n \right)$ on the randomized query complexity of Fourier Fishing, which both simplifies and subsumes the $\Omega \left( 2 ^ { n } / n \right)$ lower bound for Fourier Sampling by Aaronson and Ambainis [AA15] (which, of course, we also improve to $\Omega ( 2 ^ { n } )$ in this paper).

Quantum Supremacy Relative to Efficiently-Computable Oracles. In Section 7, we ask a new question: when proving quantum supremacy theorems, can we “interpolate” between the black-box setting of Sections 5 and 6, and the non-black-box setting of Sections 3 and 4? In particular, what happens if we consider quantum sampling algorithms that can access an oracle, but we impose a constraint that the oracle has to be “physically realistic”? One natural requirement here is that the oracle function $f$ be computable in the class $\mathsf { P } / \mathsf { p o l y }$ :8 in other words, that there are polynomial-size circuits for $f$ , which we imagine that our sampling algorithms (both quantum and classical) can call as subroutines. If the sampling algorithms also had access to explicit descriptions of the circuits, then we’d be back in the computational setting, where we already know that there’s no hope at present of proving quantum supremacy unconditionally. But what if our sampling algorithms know only that small circuits for $f$ exist, without knowing what they are? Could quantum supremacy be proven unconditionally then?

We give a satisfying answer to this question. First, by adapting constructions due to Zhandry [Zha12] and (independently) Servedio and Gortler [SG04], we show that if one-way functions exist, then there are oracles $A \in \mathsf { P } / \mathsf { p o l y }$ such that $\mathsf { B P P } ^ { A } \neq \mathsf { B Q P } ^ { A }$ , and indeed even ${ \mathsf { B Q P } } ^ { A } \not \subset { \mathsf { S Z K } } ^ { A }$ . (Here and later, the one-way functions only need to be hard to invert classically, not quantumly.)

Note that, in the unrelativized world, there seems to be no hope at present of proving ${ \mathsf { B P P } } \neq { \mathsf { B Q P } }$ under any hypothesis nearly as weak as the existence of one-way functions. Instead one has to assume the one-wayness of extremely specific functions, for example those based on factoring or discrete log.

Second, and more relevant to near-term experiments, we show that if there exist one-way functions that take at least subexponential time to invert, then there are Boolean functions $f \in \mathsf { P } / \mathsf { p o l y }$ such that approximate Fourier Sampling on those $f$ ’s requires classical exponential time. In other words: within our “physically realistic oracle” model, there are feasible-looking quantum supremacy experiments, along the lines of the IQP proposal [BJS10], such that a very standard and minimal cryptographic assumption is enough to prove the hardness of simulating those experiments classically.

Third, we show that the above two results are essentially optimal, by proving a converse result: that even in our $\mathsf { P } / \mathsf { p o l y }$ oracle model, some computational assumption is still needed to prove quantum supremacy. The precise statement is this: if $\mathsf { S a m p B P P } = \mathsf { S a m p B Q P }$ and ${ \mathsf { N P \subseteq B P P } }$ , then $\mathsf { S a m p B P P } ^ { A } = \mathsf { S a m p B Q P } ^ { A }$ for all $A \in \mathsf { P } / \mathsf { p o l y }$ . Or equivalently: if we want to separate quantum from classical approximate sampling relative to efficiently computable oracles, then we need to assume something about the unrelativized world: either $\mathsf { S a m p B P P \ne S a m p B Q P }$ (in which case we wouldn’t even need an oracle), or else NP $\nless$ BPP (which is closely related to the assumption we do make, namely that one-way functions exist).

So to summarize, we’ve uncovered a “smooth tradeoff” between the model of computation and the hypothesis needed for quantum supremacy. Relative to some oracle (and even a random oracle), we can prove SampBPP $\neq$ SampBQP unconditionally. Relative to some efficiently computable oracle, we can prove $\mathsf { S a m p B P P } \ne \mathsf { S a m p B Q P }$ , but only under a weak computational assumption, like the existence of one-way functions. Finally, with no oracle, we can currently prove $\mathsf { S a m p B P P } \ne \mathsf { S a m p B Q P }$ only under special assumptions, such as factoring being hard, or the permanents of Gaussian matrices being hard to approximate in ${ \mathsf { B P P } } ^ { \mathsf { N P } }$ , or our QUATH assumption. Perhaps eventually, we’ll be able to prove $\mathsf { S a m p B P P \ne }$ SampBQP under the sole assumption that PH is infinite, which would be a huge step forward—but at any rate we’ll need some separation of classical complexity classes.9

One last remark: the idea of comparing complexity classes relative to P/poly oracles seems quite natural even apart from its applications to quantum supremacy. So in Appendix A, we take an initial stab at exploring the implications of that idea for other central questions in complexity theory. In particular, we prove the surprising result there that $\mathsf { P } ^ { A } \sp { } = \mathsf { B } \mathsf { P } \mathsf { P } ^ { A }$ for all oracles $A \in \mathsf { P / p o l y }$ , if and only if the derandomization hypothesis of Impagliazzo and Wigderson [IW97] holds (i.e., there exists a function in E with $2 ^ { \Omega ( n ) }$ circuit complexity). In our view, this helps to clarify Impagliazzo and Wigderson’s theorem itself, by showing precisely in what way their circuit lower bound hypothesis is stronger than the desired conclusion $\mathsf { P } = \mathsf { B P P }$ . We also show that, if there are quantumly-secure one-way functions, then there exists an oracle $A \in \mathsf { P } / \mathsf { p o l y }$ such that ${ \mathsf { S } } Z { \mathsf { K } } ^ { A } \subset { \mathsf { B } } { \mathsf { Q } } { \mathsf { P } } ^ { A }$ .

# 1.4 Techniques

In our view, the central contributions of this work lie in the creation of new questions, models, and hardness assumptions (such as QUATH and quantum supremacy relative to P/poly oracles), as well as in basic observations that somehow weren’t made before (such as the sum-products algorithm for simulating quantum circuits)—all of it motivated by the goal of using complexity theory to inform ongoing efforts in experimental physics to test the Extended Church-Turing Thesis. While some of our proofs are quite involved, by and large the proof techniques are ones that will be familiar to complexity theorists. Even so, it seems appropriate to say a few words about techniques here.

To prove, in Section 3, that “if QUATH is true, then HOG is hard,” we give a fairly straightforward reduction: namely, we assume the existence of a polynomial-time classical algorithm to find high-probability outputs of a given quantum circuit $C$ . We then use that algorithm (together with a random self-reduction trick) to guess the magnitude of a particular transition amplitude, such as $\langle 0 ^ { n } | C | 0 ^ { n } \rangle$ , with probability slightly better than chance, which is enough to refute QUATH.

One technical step is to show that, with $\Omega ( 1 )$ probability, the distribution over $n$ -bit strings sampled by a random quantum circuit $C$ is far from the uniform distribution. But not only can this be done, we show that it can be done by examining only the very last gate of $C$ , and ignoring all other gates! A challenge that we leave open is to improve this, to show that the distribution sampled by $C$ is far from uniform, not merely with $\Omega ( 1 )$ probability, but with $1 - 1 / \exp ( n )$ probability. In Appendix E, we present numerical evidence for this conjecture, and indeed for a stronger conjecture, that the probabilities appearing in the output distribution of a random quantum circuit behave like independent, exponentially-distributed random variables. (We note that Brandao, Harrow and Horodecki [BHH16] recently proved a closely-related result, which unfortunately is not quite strong enough for our purposes.)

In Section 4, to give our polynomial-space, $d ^ { O ( n ) }$ -time classical algorithm for simulating an $n$ -qubit, depth- $d$ quantum circuit $C$ , we use a simple recursive strategy, reminiscent of Savitch’s Theorem. Namely, we slice the circuit into two layers, $C _ { 1 }$ and $C _ { 2 }$ , of depth $d / 2$ each, and then express a transition amplitude $\langle x | C | z \rangle$ of interest to us as

$$
\langle x | C | z \rangle = \sum _ { y \in \{ 0 , 1 \} ^ { n } } \langle x | C _ { 1 } | y \rangle \langle y | C _ { 2 } | z \rangle .
$$

We then compute each $\langle x | C _ { 1 } | y \rangle$ and $\langle y \vert C _ { 2 } \vert z \rangle$ by recursively slicing $C _ { 1 }$ and $C _ { 2 }$ into layers of depth $d / 4$ each, and so on. What takes more work is to obtain a further improvement if $C$ has only nearest-neighbor interactions on a grid graph—for that, we use a more sophisticated divide-and-conquer approach—and also to interpolate our recursive algorithm with the $2 ^ { n }$ -space Schrodinger simulation, in order to make the best ¨ possible use of whatever memory is available.

Our construction, in Section 5, of an oracle relative to which $\mathsf { S a m p B P P } = \mathsf { S a m p B Q P }$ and yet PH is infinite involves significant technical difficulty. As a first step, we can use a PSPACE oracle to collapse SampBPP with SampBQP, and then use one of many known oracles (or, by the recent breakthrough of Rossman, Servedio, and Tan [RST15], even a random oracle) to make PH infinite. The problem is that, if we do this in any na¨ıve way, then the oracle that makes PH infinite will also re-separate SampBPP and

SampBQP, for example because of the approximate Fourier Sampling problem. Thus, we need to hide the oracle that makes PH infinite, in such a way that a PH algorithm can still find the oracle (and hence, PH is still infinite), but a SampBQP algorithm can’t find it with any non-negligible probability—crucially, not even if the SampBQP algorithm’s input $x$ provides a clue about the oracle’s location. Once one realizes that these are the challenges, one then has about seven pages of work to ensure that SampBPP and SampBQP remain equal, relative to the oracle that one has constructed. Incidentally, we know that this equivalence can’t possibly hold for exact sampling, so something must force small errors to arise when the SampBPP algorithm simulates the SampBQP one. That something is basically the tiny probability that the quantum algorithm will succeed at finding the hidden oracle, which however can be upper-bounded using quantummechanical linearity.

In Section 6, to prove a $\Omega \left( 2 ^ { n } \right)$ lower bound on the classical query complexity of approximate Fourier Sampling, we use the same basic strategy that Aaronson and Ambainis [AA15] used to prove a $\Omega \left( 2 ^ { n } / n \right)$ lower bound, but with a much more careful analysis. Specifically, we observe that any Fourier Sampling algorithm would also yield an algorithm whose probability of accepting, while always small, is extremely sensitive to some specific Fourier coefficient, say ${ \widehat { f } } \left( 0 \cdots { \dot { 0 } } \right)$ . We then lower-bound the randomized query complexity of accepting with the required sensitivity to ${ \widehat { f } } \left( 0 \cdots 0 \right)$ , taking advantage of the fact that $\widehat { f } ( 0 \cdot \cdot \cdot 0 )$ is simply proportional to $\sum _ { x } f \left( x \right)$ , so that all $x$ ’s can be treated symmetrically. Interestingly, we also give a different, much simpler argument that yields a $\Omega \left( 2 ^ { n } / n \right)$ lower bound on the randomized query complexity of Fourier Fishing, which then immediately implies a $\Omega \left( 2 ^ { n } / n \right)$ lower bound for Fourier Sampling as well. However, if we want to improve the bound to $\Omega \left( 2 ^ { n } \right)$ , then the original argument that Aaronson and Ambainis [AA15] used to prove $\Omega \left( 2 ^ { n } / n \right)$ seems to be needed.

In Section 7, to prove that one-way functions imply the existence of an oracle $A \in \mathsf { P } / \mathsf { p o l y }$ such that $\mathsf { P } ^ { A } \neq \mathsf { B } \mathsf { Q } \mathsf { P } ^ { A }$ , we adapt a construction that was independently proposed by Zhandry [Zha12] and by Servedio and Gortler [SG04]. In this construction, we first use known reductions [HILL99, GGM86] to convert a one-way function into a classically-secure pseudorandom permutation, say $\sigma$ . We then define a new function by $g _ { r } ( x ) : = \sigma ( x \mathrm { m o d } r )$ , where $x$ is interpreted as an integer written in binary, and $r$ is a hidden period. Finally, we argue that either Shor’s algorithm [Sho97] leads to a quantum advantage over classical algorithms in finding the period of $g _ { r }$ , or else $g _ { r }$ was not pseudorandom, contrary to assumption. To show that subexponentially-secure one-way functions imply the existence of an oracle $A \in \mathsf { P } / \mathsf { p o l y }$ relative to which Fourier Sampling is classically hard, we use similar reasoning. The main difference is that now, to construct a distinguisher against a pseudorandom function $f$ , we need classical exponential time just to verify the outputs of a claimed polynomial-time classical algorithm for Fourier Sampling $f$ —and that’s why we need to assume 2nΩ(1) security.

Finally, to prove that $\mathsf { S a m p B P P } = \mathsf { S a m p B Q P }$ and ${ \mathsf { N P \subseteq B P P } }$ imply $\mathsf { S a m p B P P } ^ { A } = \mathsf { S a m p B Q P } ^ { A }$ for all $A \in \mathsf { P } / \mathsf { p o l y }$ , we design a step-by-step classical simulation of a quantum algorithm, call it $Q$ , that queries an oracle $A \in \mathsf { P } / \mathsf { p o l y }$ . We use the assumption $\mathsf { S a m p B P P } = \mathsf { S a m p B Q P }$ to sample from the probability distribution over queries to $A$ that $Q$ makes at any given time step. Then we use the assumption ${ \mathsf { N P \subseteq B P P } }$ to guess a function $f \in \mathsf { P } / \mathsf { p o l y }$ that’s consistent with $n ^ { O ( 1 ) }$ sampled classical queries to $A$ . Because of the limited number of functions in $\mathsf { P } / \mathsf { p o l y }$ , standard sample complexity bounds for PAC-learning imply that any such $f$ that we guess will probably agree with the “true” oracle $A$ on most inputs. Quantum-mechanical linearity then implies that the rare disagreements between $f$ and $A$ will have at most a small effect on the future behavior of $Q$ .

# 2 Preliminaries

For a positive integer $n$ , we use $[ n ]$ to denote the integers from 1 to $n$ . Logarithms are base 2.

# 2.1 Quantum Circuits

We now introduce some notations for quantum circuits, which will be used throughout this paper.

In a quantum circuit, without loss of generality, we assume all gates are unitary and acting on exactly two qubits each10.

Given a quantum circuit $C$ , slightly abusing notation, we also use $C$ to denote the unitary operator induced by $C$ . Suppose there are $n$ qubits and $m$ gates in $C$ ; then we index the qubits from 1 to $n$ . We also index gates from 1 to $m$ in chronological order for convenience.

For each subset $S \subseteq [ n ]$ of the qubits, let $\mathcal { H } _ { S }$ be the Hilbert space corresponding to the qubits in $S$ , and $I _ { S }$ be the identity operator on $\mathcal { H } _ { S }$ . Then the unitary operator $U _ { i }$ for the $i$ -th gate can be written as $U _ { i } : = O _ { i } \otimes I _ { [ n ] \backslash \{ a _ { i } , b _ { i } \} }$ , in which $O _ { i }$ is a unitary operator on $\mathcal { H } _ { \{ a _ { i } , b _ { i } \} }$ (the Hilbert space spanned by the qubits $a _ { i }$ and $b _ { i }$ ), and $I _ { [ n ] \backslash \{ a _ { i } , b _ { i } \} }$ is the identity operator on the other qubits.

We say that a quantum circuit has depth $d$ , if its gates can be partitioned into $d$ layers (in chronological order), such that the gates in each layer act on disjoint pairs of qubits. Suppose the $i$ -th layer consists of the gates in $[ L _ { i } , R _ { i } ]$ . We define $C _ { [ r  l ] } = U _ { R _ { r } } \cdot U _ { R _ { r } - 1 } \ldots U _ { L _ { l } + 1 } \cdot U _ { L _ { l } }$ , that is, the sub-circuit between the $l$ -th layer and the $r$ -th layer.

# Base Graphs and Grids

In Sections 3 and 4, we will sometimes assume locality of a given quantum circuit. To formalize this notion, we define the base graph of a quantum circuit.

Definition 2.1. Given a quantum circuit $C$ on n qubits, its base graph $G _ { C } = ( V , E )$ is an undirected graph defined by $V = [ n ]$ , and

$$
E = \{ ( a , b ) \mid t h e r e \ i s \ a \ q u a n t u m \ g a t e \ t h a t \ a c t s \ o n \ q u b i t s \ a \ a n d \ b . \} .
$$

We will consider a specific kind of base graph, the grids.

Definition 2.2. The grid $G$ of size $H \times W$ is a graph with vertices $V = \{ ( x , y ) \mid x \in [ H ] , y \in [ W ] \}$ and edges $E = \{ ( a , b ) \mid \left| a - b \right| _ { 1 } = 1 , a \in V , b \in V \}$ , and we say that grid $G$ has $H$ rows and $W$ columns.

# 2.2 Complexity Classes for Sampling Problems

# Definitions for SampBPP and SampBQP

We adopt the following definition for sampling problems from [Aar14].

Definition 2.3 (Sampling Problems, SampBPP, and SampBQP). A sampling problem $S$ is a collection of probability distributions $\left( \mathcal { D } _ { x } \right) _ { x \in \{ 0 , 1 \} ^ { * } }$ , one for each input string $x \in \{ 0 , 1 \} ^ { n }$ , where $\mathcal { D } _ { x }$ is a distribution over $\{ 0 , 1 \} ^ { p ( n ) }$ , for some fixed polynomial $p$ . Then SampBPP is the class of sampling problems $S =$ $\left( \mathcal { D } _ { x } \right) _ { x \in \{ 0 , 1 \} ^ { * } }$ for which there exists a probabilistic polynomial-time algorithm $B$ that, given $\left. x , 0 ^ { 1 / \varepsilon } \right.$ as input, samples from a probability distribution ${ \mathcal { C } } _ { x }$ such that $\| \mathcal { C } _ { x } - \mathcal { D } _ { x } \| \leq \varepsilon$ . SampBQP is defined the same way, except that $B$ is a quantum algorithm rather than a classical one.

Oracle versions of these classes can also be defined in the natural way.

# A Canonical Form of SampBQP Oracle Algorithms

To ease our discussion about $\mathsf { S a m p B Q P } ^ { \mathcal { O } }$ , we describe a canonical form of SampBQP oracle algorithms. Any other reasonable definitions of SampBQP oracle algorithms (like with quantum oracle Turing machines) can be transformed into this form easily.

Without loss of generality, we can assume a SampBQP oracle algorithm $M$ with oracle access to $\mathcal { O } _ { 1 } , \mathcal { O } _ { 2 } , \ldots , \mathcal { O } _ { k }$ $k$ is a universal constant) acts in three stages, as follows.

1. Given an input $\langle x , 0 ^ { 1 / \varepsilon } \rangle$ , $M$ first uses a classical routine (which does not use the oracles) to output a quantum circuit $C$ with $p ( n , 1 / \varepsilon )$ qubits and $p ( n , 1 / \varepsilon )$ gates in polynomial time, where $p$ is a fixed polynomial. Note that $C$ can use the $\mathcal { O } _ { 1 } , \mathcal { O } _ { 2 } , \ldots , \mathcal { O } _ { k }$ gates in addition to a universal set of quantum gates.   
2. Then $M$ runs the outputted quantum circuit with the initial state $| 0 \rangle ^ { \otimes p ( n , 1 / \varepsilon ) }$ , and measures all the qubits to get an outcome z in {0, 1}p(n,1/ε).   
3. Finally, $M$ uses another classical routine $A ^ { \mathsf { o u t p u t } }$ (which does not use the oracles) on the input $z$ , to output its final sample $A ^ { \mathsf { o u t p u t } } ( z ) \in \{ 0 , 1 \} ^ { * }$ .

Clearly, $M$ solves different sampling problems (or does not solve any sampling problem at all) given different oracles $\mathcal { O } _ { 1 } , \mathcal { O } _ { 2 } , \ldots , \mathcal { O } _ { k }$ . Therefore, we use $M ^ { \mathcal { O } _ { 1 } , \mathcal { O } _ { 2 } , \dots , \mathcal { O } _ { k } }$ to indicate the particular algorithm when the oracles are $\mathcal { O } _ { 1 } , \mathcal { O } _ { 2 } , \ldots , \mathcal { O } _ { k }$ .

# 2.3 Distinguishing Two Pure Quantum States

We also need a standard result for distinguishing two pure quantum states.

Theorem 2.4 (Helstrom’s decoder for two pure states). The maximum success probability for distinguishing two pure quantum states $\left| \varphi _ { 0 } \right.$ and $\left| \varphi _ { 1 } \right.$ given with prior probabilities $\pi _ { 0 }$ and $\pi _ { 1 }$ , is given by

$$
p _ { s u c c } = \frac { 1 + \sqrt { 1 - 4 \pi _ { 0 } \pi _ { 1 } F } } { 2 } ,
$$

where $F : = | \langle \varphi _ { 0 } | \varphi _ { 1 } \rangle | ^ { 2 }$ is the fidelity between the two states.

We’ll also need that for two similar quantum states, the distributions induced by measuring them are close.

Corollary 2.5. Let $\left| \varphi _ { 0 } \right.$ and $\left| \varphi _ { 1 } \right.$ be two pure quantum state such that $| | \varphi _ { 0 } \rangle - | \varphi _ { 1 } \rangle | \leq \varepsilon$ . For a quantum state $\varphi$ , define $\mathcal { D } ( \boldsymbol { \varphi } )$ be the distribution on $\{ 0 , 1 \} ^ { * }$ induced by some quantum sampling procedure, we have

$$
\| D ( \varphi _ { 0 } ) - D ( \varphi _ { 1 } ) \| \leq \sqrt { 2 \varepsilon } .
$$

Proof. Fix prior probabilities π0 = π1 = 12 .

Note that we have a distinguisher of $\left| \varphi _ { 0 } \right.$ and $\left| \varphi _ { 1 } \right.$ with success probability $\frac { 1 + \| \mathcal { D } ( \varphi _ { 0 } ) - \mathcal { D } ( \varphi _ { 1 } ) \| } { 2 }$ by invoking that quantum sampling procedure.

By the assumption, $| \langle \varphi _ { 0 } | | \varphi _ { 1 } \rangle | = | \langle \varphi _ { 0 } | \cdot ( | \varphi _ { 0 } \rangle + ( | \varphi _ { 1 } \rangle - | \varphi _ { 0 } \rangle ) | \geq 1 - \varepsilon$ , hence $F = | \langle \varphi _ { 0 } | \varphi _ { 1 } \rangle | ^ { 2 } \geq ( 1 - \varepsilon ) ^ { 2 }$ So we have

$$
\begin{array} { c } { \displaystyle \frac { 1 + \| \mathcal { D } ( \varphi _ { 0 } ) - \mathcal { D } ( \varphi _ { 1 } ) \| } { 2 } \leq \frac { 1 + \sqrt { 1 - ( 1 - \varepsilon ) ^ { 2 } } } { 2 } } \\ { \| \mathcal { D } ( \varphi _ { 0 } ) - \mathcal { D } ( \varphi _ { 1 } ) \| _ { 1 } \leq \sqrt { 1 - ( 1 - \varepsilon ) ^ { 2 } } = \sqrt { 2 \varepsilon - \varepsilon ^ { 2 } } \leq \sqrt { 2 \varepsilon } . } \end{array}
$$

# 2.4 A Multiplicative Chernoff Bound

Lemma 2.6. Suppose $X _ { 1 } , X _ { 2 } , \ldots , X _ { n }$ are independent random variables taking values in [0, 1]. Let $X$ denote their sum and let $\mu = \operatorname { \mathbb { E } } [ X ]$ . Then for any $\delta > 1$ , we have

$$
\operatorname* { P r } [ X \geq ( 1 + \delta ) \mu ] \leq e ^ { - { \frac { \delta \mu } { 3 } } } .
$$

Corollary 2.7. For any $0 < \tau$ , suppose $X _ { 1 } , X _ { 2 } , \ldots , X _ { n }$ are independent random variables taking values in $[ 0 , \tau ]$ . Let $X$ denote their sum and let $\mu = \operatorname { \mathbb { E } } [ X ]$ . Then for any $\delta > 1$ , we have

$$
\operatorname* { P r } [ X \geq ( 1 + \delta ) \mu ] \leq e ^ { - { \frac { \delta \mu } { 3 \tau } } } .
$$

Proof. Replace each $X _ { i }$ by $X _ { i } / \tau$ and apply the previous lemma.

# 3 The Hardness of Quantum Circuit Sampling

We now discuss our random quantum circuit proposal for demonstrating quantum supremacy.

# 3.1 Preliminaries

We first introduce some notations. We use $\mathbb { U } ( N )$ to denote the group of $N \times N$ unitary matrices, $\mu _ { \mathsf { H a a r } } ^ { N }$ for the Haar measure on $\mathbb { U } ( N )$ , and $\mu _ { \mathrm { r a n d } } ^ { N }$ for the Haar measure on $N$ -dimensional pure states.

For a pure state $| u \rangle$ on $n$ qubits, we define probList $( | u \rangle )$ to be the list consisting of $2 ^ { n }$ numbers, $| \langle u | x \rangle | ^ { 2 }$ for each $x \in \{ 0 , 1 \} ^ { n }$ .

Given $N$ real numbers $a _ { 1 } , a _ { 2 } , \dotsc , a _ { N }$ , we use uphalf $( a _ { 1 } , a _ { 2 } , \dotsc , a _ { N } )$ to denote the sum of the largest $N / 2$ numbers among them, and we let

$$
\mathsf { a d v } ( | u \rangle ) = \mathsf { u p h a l f } ( \mathsf { p r o b L i s t } ( | u \rangle ) ) .
$$

Finally, we say that an output $z \in \{ 0 , 1 \} ^ { n }$ is heavy for a quantum circuit $C$ , if it is greater than the median of probList $( C | 0 ^ { n }  )$ .

# 3.2 Random quantum circuit on grids

Recall that we assume a quantum circuit consists of only 2-qubit gates. Our random quantum circuit on grids of $n$ qubits and $m$ gates (assuming $m \geq n ,$ ) is generated as follows (though the basic structure of our hardness argument will not be very sensitive to details, and would also work for many other circuit ensembles):

• All the qubits are arranged as a ${ \sqrt { n } } \times { \sqrt { n } }$ grid (see Definition 2.2), and a gate can only act on two adjacent qubits. • For each $t \in [ m ]$ with $t \leq n$ , we pick the $t$ -th qubit and a random neighbor of it.11 • For each $t \in [ m ]$ with $t > n$ , we pick a uniform random pair of adjacent qubits in the grid ${ \sqrt { n } } \times { \sqrt { n } }$ . • Then, in either case, we set the $t$ -th gate to be a unitary drawn from $\mu _ { \mathsf { H a a r } } ^ { 4 }$ acting on these two qubits.

Slightly abusing notation, we use µn,mgrid to denote both the above distribution on quantum circuits and the distribution on $\mathbb { U } ( 2 ^ { n } )$ induced by it.

# Conditional distribution $\nu _ { \mathrm { g r i d } }$

For convenience, for a quantum circuit $C$ , we abbreviate ad $\mathsf { v } ( C | 0 ^ { n } ) )$ as $\mathsf { a d v } ( C )$ . Consider a simple quantum algorithm which measures $C | 0 ^ { n } \rangle$ in the computational basis to get an output $z$ . Then by definition, adv $( C )$ is simply the probability that $z$ is heavy for $C$ .

We want that, when a quantum circuit $C$ is drawn, $\mathsf { a d v } ( C )$ is large (that is, bounded above $1 / 2$ ), and therefore the simple quantum algorithm has a substantial advantage on generating a heavy output, compared with the trivial algorithm of guessing a random string.

nvenience, we also consi r the foll nal distribution $\nu _ { \mathrm { g r i d } } ^ { n , m }$ : it keeps drawing a circuit $C \gets \mu _ { \tt g r i d } ^ { n , m }$ $C$ $\mathsf { a d v } ( C ) \geq 0 . 7$

# Lower bound on adv $( C )$

We need to show that a circuit $C$ drawn from $\nu _ { \mathbf { g r i d } } ^ { n , m }$ has a large probability of having $\mathsf { a d v } ( C ) \geq 0 . 7$ . In order to show that, we give a cute and simple lemma, which states that the expectation of adv $( C )$ is large. Surprisingly, its proof only makes use of the randomness introduced by the very last gate!

Lemma 3.1. For $n \geq 2$ and $m \geq n$

$$
\underset { C  \mu _ { \mathtt { g r i d } } ^ { n , m } } { \mathbb { E } } [ \mathsf { a d v } ( C ) ] \geq \frac { 5 } { 8 } .
$$

In fact, we conjecture that adv $( C )$ is large with an overwhelming probability.

Conjecture 1. For $n \geq 2$ and $m \geq n ^ { 2 }$ , and for all constants $\varepsilon > 0$

$$
\operatorname* { P r } _ { C \gets \mu _ { \mathtt { g r i d } } ^ { n , m } } \left[ \mathsf { a d v } ( C ) < \frac { 1 + \ln 2 } { 2 } - \varepsilon \right] < \exp \left\{ - \Omega ( n ) \right\} .
$$

We give some numerical simulation evidence for Conjecture 1 in Appendix E.

Remark 3.2. Assuming Conjecture $I$ , in practice, one can sample from $\nu _ { \mathrm { g r i d } }$ by simply sampling from $\mu _ { \mathrm { g r i d } }$ , the uniform distribution over circuits—doing so only introduces an error probability of $\exp \{ - \Omega ( n ) \}$ .

# 3.3 The HOG Problem

Now we formally define the task in our quantum algorithm proposal.

Problem 1 (HOG, or Heavy Output Generation). Given a random quantum circuit $C$ from ν n,mgrid for m ≥ n2, generate $k$ binary strings $z _ { 1 } , z _ { 2 } , \ldots , z _ { k }$ in $\{ 0 , 1 \} ^ { n }$ such that at least a $2 / 3$ fraction of $z _ { i }$ ’s are heavy for $C$ .

The following proposition states that there is a simple quantum algorithm which solves the above problem with overwhelming probability.

Proposition 3.3. There is a quantum algorithm that succeeds at HOG with probability $1 - \exp \{ - \Omega ( k ) \}$ .

Proof. The algorithm just simulates the circuit $C$ with initial state $| 0 ^ { n } \rangle$ , then measures in the computational basis $k$ times independently to output $k$ binary strings.

From the definition of $\nu _ { \mathrm { g r i d } }$ , we have $\mathsf { a d v } ( C ) \geq 0 . 7 > 2 / 3$ . So by a Chernoff bound, with probability $1 - \exp \{ \Omega ( k ) \}$ , at least a $2 / 3$ fraction of $z _ { i }$ ’s are heavy for $C$ , in which case the algorithm solves HOG.

# 3.4 Classical Hardness Assuming QUATH

We now state our classical hardness assumption.

Assumption 1 (QUATH, or the Quantum Threshold assumption). There is no polynomial-time classical algorithm that takes as input a random quantum circuit $C \gets \nu _ { \mathsf { g r i d } } ^ { n , m }$ for $m \geq n ^ { 2 }$ and decides whether $0 ^ { n }$ is heavy for $C$ with success probability $1 / 2 + \Omega ( 2 ^ { - n } )$ .

Remark 3.4. Note that $1 / 2$ is the success probability obtained by always outputting either 0 or 1. Therefore, the above assumption means that no efficient algorithm can beat the trivial algorithm even by $\Omega ( 2 ^ { - n } )$ .

Next, we show that QUATH implies that no efficient classical algorithm can solve HOG.

Theorem 3.5. Assuming QUATH, no polynomial-time classical algorithm can solve HOG with probability at least 0.99.

Proof. Suppose by contradiction that there is such a classical polynomial-time algorithm $A$ . Using $A$ , we will construct an algorithm to violate QUATH.

The algorithm is quite simple. Given a quantum circuit C ← νn,mgrid , we first draw a uniform random string $z \in \{ 0 , 1 \} ^ { n }$ . Then for each $i$ such that $z _ { i } = 1$ , we apply a NOT gate on the $i$ -th qubit. Note that this gate can be “absorbed” into the last gate acting on the $i$ -th qubit in $C$ . Hence, we still get a circuit $C ^ { \prime }$ with $m$ gates. Moreover, it is easy to see that $C ^ { \prime }$ is distributed exactly the same as $C$ even if conditioning on a particular $z$ , and we have $\langle 0 ^ { n } | C | 0 ^ { n } \rangle = \langle 0 ^ { n } | C ^ { \prime } | z \rangle$ , which means that $0 ^ { n }$ is heavy for $C$ if and only if $z$ is heavy for $C ^ { \prime }$ .

Next our algorithm runs $A$ on circuit $C ^ { \prime }$ to get $k$ outputs $z _ { 1 } , \ldots , z _ { k }$ , and picks an output $z _ { i ^ { \star } }$ among these $k$ outputs uniformly at random. If $z _ { i ^ { \star } } = z$ , then the algorithm outputs 1; otherwise it outputs a uniform random bit.

Since $A$ solves HOG with probability 0.99, we have that each $z _ { k }$ is heavy for $C ^ { \prime }$ with probability at least $0 . 9 9 \cdot 2 / 3$ .

Now, since $z$ is a uniform random string, the probability that our algorithm decides correctly whether is heavy for $C ^ { \prime }$ is

$$
\begin{array} { l } { \displaystyle \operatorname* { P r } [ z = z _ { i ^ { \star } } ] \cdot 0 . 9 9 \cdot \frac { 2 } { 3 } + \operatorname* { P r } [ z \neq z _ { i ^ { \star } } ] \cdot 1 / 2 = 2 ^ { - n } \cdot 0 . 9 9 \cdot \frac { 2 } { 3 } + ( 1 - 2 ^ { - n } ) \cdot 1 / 2 } \\ { \displaystyle \qquad = \frac { 1 } { 2 } + \Omega ( 2 ^ { - n } ) . } \end{array}
$$

But this contradicts QUATH, so we are done.

# 3.5 Proof for Lemma 3.1

We first need a simple lemma which helps us to lower bound $\mathsf { a d v } ( | u \rangle )$

For a pure quantum state $| u \rangle$ , define

$$
\mathsf { d e v } ( | u \rangle ) = \sum _ { w \in \{ 0 , 1 \} ^ { n } } \Big | | \langle u | w \rangle | ^ { 2 } - 2 ^ { - n } \Big | .
$$

In other words, $\mathsf { d e v } ( | u \rangle )$ measures the non-uniformity of the distribution obtained by measuring $| u \rangle$ in the computational basis.

The next lemma shows that, when $\mathsf { d e v } ( | u \rangle )$ is large, so is $\mathsf { a d v } ( | u \rangle )$ . Therefore, in order to establish Lemma 3.1, it suffices to lower-bound ${ \mathsf { d e v } } ( | u \rangle )$ .

Lemma 3.6. For a pure quantum state $| u \rangle$ , we have

$$
\mathsf { a d v } ( \vert u \rangle ) \geq \frac { 1 } { 2 } + \frac { \mathsf { d e v } ( u ) } { 4 } .
$$

We will also need the following technical lemma.

Lemma 3.7. Let $| u \rangle \gets \mu _ { \mathsf { r a n d } } ^ { 2 }$ . Then

$$
\underset { | u \rangle  \mu _ { \mathrm { r a n d } } ^ { 2 } } { \mathbb { E } } [ | | \langle u | 0 \rangle | ^ { 2 } - | \langle u | 1 \rangle | ^ { 2 } | ] = 0 . 5 .
$$

The proofs of Lemma 3.6 and Lemma 3.7 are based on simple but tedious calculations, so we defer them to Appendix B.

Now we are ready to prove Lemma 3.1.

Proof of Lemma 3.1. Surprisingly, our proof only uses the randomness introduced by the very last gate.   
That is, the claim holds even if there is an adversary who fixes all the gates except for the last one.

We use $I _ { n }$ to denote the $n$ -qubit identity operator.

Let $C \gets \mu _ { \mathsf { g r i d } } ^ { n , m }$ . From Lemma 3.6, it suffices to show that

$$
\underset { C  \mu _ { \mathtt { g r i d } } ^ { n , m } } { \mathbb { E } } [ \mathsf { d e v } ( C | 0 ^ { n } \rangle ) ] \geq \frac { 1 } { 2 } .
$$

Suppose the last gate $U \gets \mu _ { \mathsf { H a a r } } ^ { 4 }$ acts on qubits $a$ and $b$ . Let the unitary corresponding to the circuit before applying the last gate be $V$ , and $| v \rangle = V | 0 ^ { n } \rangle$ . Now, suppose we apply another unitary $U _ { a }$ drawn from $\mu _ { \mathsf { H a a r } } ^ { 2 }$ on the qubit $a$ . It is not hard to see that $U$ and $( U _ { a } \otimes I _ { 1 } ) \cdot U$ are identically distributed. So it suffices to show that

$$
\begin{array} { r } { \underset { U  \mu _ { \mathrm { H a a r } } ^ { 4 } , U _ { a }  \mu _ { \mathrm { H a a r } } ^ { 2 } } { \mathbb { E } } \Big [ \mathsf { a d v } \Big ( ( U _ { a } \otimes I _ { n - 1 } ) ( U \otimes I _ { n - 2 } ) | v \rangle \Big ) \Big ] \geq 0 . 6 . } \end{array}
$$

We are going to show that the above holds even for a fixed $U$ . That is, fix a $U \in \mathbb { U } ( 4 )$ and let $| u \rangle = U \otimes I _ { n - 2 } ) | v \rangle$ . Then we will prove that

$$
\underset { U _ { a }  \mu _ { \mathsf { H a a r } } ^ { 2 } } { \mathbb { E } } [ \mathsf { d e v } \Big ( ( U _ { a } \otimes I _ { n - 1 } ) | v \rangle \Big ) ] \geq \frac { 1 } { 2 } .
$$

Without loss of generality, we can assume that $a$ is the last qubit. Then we write

$$
| u \rangle = \sum _ { w \in \{ 0 , 1 \} ^ { n } } a _ { w } | w \rangle ,
$$

and

$$
| z \rangle = ( U _ { a } \otimes I _ { n - 1 } ) | u \rangle .
$$

Now we partition the $2 ^ { n }$ basis states into $2 ^ { n - 1 }$ buckets, one for each string in $\{ 0 , 1 \} ^ { n - 1 }$ . That is, for each $p \in \{ 0 , 1 \} ^ { n - 1 }$ , there is a bucket that consists of basis states $\{ | p 0 \rangle , | p 1 \rangle \}$ . Note that since $U _ { a }$ acts on the last qubit, only amplitudes of basis states in the same bucket can affect each other.

For a given $p \in \{ 0 , 1 \} ^ { n - 1 }$ , if both $a _ { p 0 }$ and $a _ { p 1 }$ are zero, we simply ignore this bucket. Otherwise, we can define a quantum state

$$
| t _ { p } \rangle = \frac { a _ { p 0 } | 0 \rangle + a _ { p 1 } | 1 \rangle } { \sqrt { | a _ { p 0 } | ^ { 2 } + | a _ { p 1 } | ^ { 2 } } } ,
$$

and

$$
\begin{array} { r } { | z _ { p } \rangle = U _ { a } | t _ { p } \rangle . } \end{array}
$$

Clearly, we have $\langle z | p 0 \rangle = \sqrt { | a _ { p 0 } | ^ { 2 } + | a _ { p 1 } | ^ { 2 } } \cdot \langle z _ { p } | 0 \rangle$ and $\langle z | p 1 \rangle = \sqrt { | a _ { p 0 } | ^ { 2 } + | a _ { p 1 } | ^ { 2 } } \cdot \langle z _ { p } | 1 \rangle$ . Plugging in, we have

$$
\begin{array} { r l } & { \quad \underset { U _ { a }  \mu _ { \mathrm { H a r r } } ^ { 2 } } { \mathbb { E } } [ | \langle z | p 0 \rangle | ^ { 2 } - 2 ^ { - n } | + | \lvert \langle z | p 1 \rangle | ^ { 2 } - 2 ^ { - n } | ] } \\ & { \ge \underset { U _ { a }  \mu _ { \mathrm { H a r r } } ^ { 2 } } { \mathbb { E } } [ | \langle z | p 0 \rangle | ^ { 2 } - \lvert \langle z | p 1 \rangle | ^ { 2 } | ] } \\ & { = ( | a _ { p 0 } | ^ { 2 } + | a _ { p 1 } | ^ { 2 } ) \cdot \underset { U _ { a }  \mu _ { \mathrm { H a r r } } ^ { 2 } } { \mathbb { E } } [ | \langle z _ { p } | 0 \rangle | ^ { 2 } - \lvert \langle z _ { p } | 1 \rangle | ^ { 2 } | ] . } \end{array}
$$

(triangle inequality)

Now, since $\left| t _ { p } \right.$ is a pure state, and $U _ { a }$ is drawn from $\mu _ { \mathsf { H a a r } } ^ { 2 }$ , we see that $| z _ { p } \rangle$ is distributed as a Haarrandom pure state. So from Lemma 3.7, we have

$$
\underset { U _ { a }  \mu _ { \mathsf { H a a r } } ^ { 2 } } { \mathbb { E } } [ | | \langle z _ { p } | 0 \rangle | ^ { 2 } - | \langle z _ { p } | 1 \rangle | ^ { 2 } | ] = 0 . 5 .
$$

Therefore,

$$
\underset { U _ { a }  \mu _ { \mathtt { H a } 2 \nu } } { \mathbb { E } } [ | \langle z | p 0 \rangle | ^ { 2 } - 2 ^ { - n } | + | | \langle z | p 1 \rangle | ^ { 2 } - 2 ^ { - n } | ] \geq \frac { 1 } { 2 } \cdot ( | a _ { p 0 } | ^ { 2 } + | a _ { p 1 } | ^ { 2 } ) .
$$

Summing up for each $p \in \{ 0 , 1 \} ^ { n - 1 }$ , we have

$$
\mathbb { E } _ { a  \mu _ { \mathsf { H a r } } ^ { 2 } } [ { \mathsf { d e v } } ( | z \rangle ) ] \geq { \frac { 1 } { 2 } } ,
$$

which completes the proof.

# 4 New Algorithms to Simulate Quantum Circuits

In this section, we present two algorithms for simulating a quantum circuit with $n$ qubits and $m$ gates: one algorithm for arbitrary circuits, and another for circuits that act locally on grids. What’s new about these algorithms is that they use both polynomial space and close to $\exp ( n )$ time (but despite that, they don’t violate the QUATH assumption from Section 3, for the reason pointed out in Section 1.3). Previously, it was known how to simulate a quantum circuit in polynomial space and $\exp ( m )$ time (as in the proof of ${ \mathsf { B Q P \subseteq P ^ { \# } P } } ,$ ), or in exponential space and $\exp ( n )$ time.

In addition, we provide a time-space trade-off scheme, which enables even faster simulation at the cost of more space usage. See Section 2.1 for the quantum circuit notations that are used throughout this section.

# 4.1 Polynomial-Space Simulation Algorithms for General Quantum Circuits

We first present a simple recursive algorithm for general circuits.

Theorem 4.1. Given a quantum circuit $C$ on n qubits with depth $d ,$ , and two computational basis states $| x \rangle , | y \rangle$ , we can compute $\langle y | C | x \rangle$ in $O ( n \cdot ( 2 d ) ^ { n + 1 } )$ time and $O ( n \log d )$ space.

Proof. In the base case $d = 1$ , the answer can be trivially computed in $O ( n )$ time. When $d > 1$ , we have

$$
\begin{array} { l } { \langle y | C | x \rangle = \langle y | C _ { [ d  d / 2 + 1 ] } \cdot C _ { [ d / 2  1 ] } | x \rangle } \\ { \quad = \langle y | C _ { [ d  d / 2 + 1 ] } ( \displaystyle \sum _ { z \in \{ 0 , 1 \} ^ { n } } | z \rangle \langle z | ) C _ { [ d / 2  1 ] } | x \rangle } \\ { \quad = \displaystyle \sum _ { z \in \{ 0 , 1 \} ^ { n } } \langle y | C _ { [ d  d / 2 + 1 ] } | z \rangle \cdot \langle z | C _ { [ d / 2  1 ] } | x \rangle . } \end{array}
$$

Then, for each $z$ , we calculate $\langle y | C _ { [ d  d / 2 + 1 ] } | z \rangle \cdot \langle z | C _ { [ d / 2  1 ] } | x \rangle$ by recursively calling the algorithm on the two sub-circuits $C _ { [ d  d / 2 + 1 ] }$ and $C _ { [ d / 2  1 ] }$ respectively; and sum them up to calculate (2).

It is easy to see the above algorithm is correct, and its running time can be analyzed as follows: let $F ( d )$ be its running time on a circuit of $d$ layers; then we have $F ( 1 ) = O ( n )$ , and by the above discussion

$$
\begin{array} { r } { \mathsf {  { { \mathbb { F } } } } ( d ) \le 2 ^ { n + 1 } \cdot F ( \lceil d / 2 \rceil ) = O ( n \cdot 2 ^ { ( n + 1 ) \lceil \log d \rceil } ) = O ( n \cdot ( 2 ^ { \lceil \log d \rceil } ) ^ { n + 1 } ) \le O ( n \cdot ( 2 d ) ^ { n + 1 } ) , } \end{array}
$$

which proves our running time bound.

Finally, we can see in each recursion level, we need $O ( n )$ space to save the indices of $| x \rangle$ and $| y \rangle$ , and $O ( 1 )$ space to store an intermediate answer. Since there are at most $O ( \log d )$ recursion levels, the total space is bounded by $O ( n \log d )$ . □

# 4.2 Faster Polynomial Space Simulation Algorithms for Grid Quantum Circuits

When a quantum circuit is spatially local, i.e., its base graph can be embedded on a grid, we can further speed up the simulation with a more sophisticated algorithm.

We first introduce a simple lemma which shows that we can find a small balanced cut in a two-dimensional grid.

Lemma 4.2. Given a grid $G = ( V , E )$ of size $H \times W$ such that $| V | \geq 2$ , we can find a subset $S \subset E$ such that

• $| S | \le { \cal { O } } ( \sqrt { | V | } )$ , and • after $S$ is removed, $G$ becomes a union of two disconnected grids with size smaller than $\frac { 2 } { 3 } \lvert V \rvert$ .

Proof. We can assume $H \geq W$ without loss of generality and simply set $S$ to be the set of all the edges between the $\lfloor H / 2 \rfloor$ -th row and the $\lfloor H / 2 \rfloor + 1$ -th row; then both claims are easy to verify.

We now present a faster algorithm for simulating quantum circuits on grids.

Theorem 4.3. Given a quantum circuit $C$ on $n$ qubits with depth $d ,$ , and two computational basis states $| x \rangle , | y \rangle$ , assuming that $G _ { C }$ can be embedded into a two-dimensional grid with size n (with the embedding explicitly specified), we can compute $\langle y | C | x \rangle$ in $2 ^ { O ( d { \sqrt { n } } ) }$ time and $O ( d \cdot n \log n )$ space.

Proof. For ease of presentation, we slightly generalize the definition of quantum circuits: now each gate can be of the form $O _ { i } \otimes I _ { [ n ] \backslash \{ a _ { i } , b _ { i } \} }$ (a 2-qubit gate) or $O _ { i } \otimes I _ { [ n ] \backslash \{ a _ { i } \} }$ (a 1-qubit gate) or simply $I _ { [ n ] }$ (a 0-qubit gate, which is introduced just for convenience).

The algorithm works by trying to break the current large instance into many small instances which we then solve recursively. But unlike the algorithm in Theorem 4.1, which reduces an instance to many sub-instances with fewer gates, our algorithm here reduces an instance to many sub-instances with fewer qubits.

The base case, $n = 1$ qubit. In this case, all the gates are either 1-qubit or 0-qubit; hence the answer can be calculated straightforwardly in $O ( m )$ time and constant space.

Cutting the grid by a small set. When $n \geq 2$ , by Lemma 4.2, we can find a subset $S$ of edges with $| S | \leq O ( { \sqrt { n } } )$ . After $S$ is removed, the grid becomes a union of two disconnected grids $A$ and $B$ (we use $A , B$ to denote both the grids and the sets of the vertices in the grid for simplicity) with size smaller than $2$ ${ \overline { { 3 } } } ^ { n }$ .

Let

$$
\{ R = i \mid U _ { i } { \mathrm { ~ i s ~ o f ~ t h e ~ f o r m ~ } } O _ { i } \otimes I _ { [ n ] \backslash \{ a _ { i } , b _ { i } \} } \}
$$

that is, the set of the indices of the gates crossing the cut $S$ . Without loss of generality, we can assume that for each $i \in R$ , we have $a _ { i } \in A$ and $b _ { i } \in B$ .

Since in a single layer, there is at most one gate acting on a particular adjacent pair of qubits, we have

$$
| R | \leq O ( d { \sqrt { n } } ) .
$$

Breaking the gates in $R$ . Now, for each $i \in R$ , we decompose $O _ { i }$ (which can be viewed as a matrix in C4×4) into a sum of 16 single-entry matrices Oi,1, Oi,2, . . . , Oi,16.

Write $O _ { i }$ as

$$
O _ { i } = \sum _ { x , y \in \{ 0 , 1 \} ^ { 2 } } \langle y | O _ { i } | x \rangle \cdot | y \rangle \langle x | .
$$

Then we set $O _ { i , j } ~ = ~ \langle y _ { j } | O _ { i } | x _ { j } \rangle \cdot | y _ { j } \rangle \langle x _ { j } |$ for each $j \in$ [16], where $( x _ { j } , y _ { j } )$ is the $j$ -th ordered pair in $\{ 0 , 1 \} ^ { 2 } \times \{ 0 , 1 \} ^ { \tilde { 2 } }$ .

Decomposing the instance. Now, we are going to expand each $U _ { i } = O _ { i } \otimes I _ { [ n ] \backslash \{ a _ { i } , b _ { i } \} }$ as a sum

$$
U _ { i } = \sum _ { j = 1 } ^ { 1 6 } O _ { i , j } \otimes I _ { [ n ] \backslash \{ a _ { i } , b _ { i } \} }
$$

for each $i \in R$ , and therefore decompose the answer $\langle y | C | x \rangle = \langle y | U _ { m } U _ { m - 1 } \cdot \cdot \cdot U _ { 1 } | x \rangle$ into a sum of $1 6 ^ { | R | }$ terms. More concretely, for a mapping $\tau$ from $R$ to [16] and an index $i \in [ m ]$ , we define

$$
U _ { i , \tau } = \left\{ \begin{array} { l l } { O _ { i , \tau ( i ) } \times I _ { [ n ] \backslash \{ a _ { i } , b _ { i } \} } \qquad } & { i \in R . } \\ { U _ { i } \qquad } & { i \notin R . } \end{array} \right.
$$

Let $\tau$ be the set of all mappings from $R$ to [16]. Then we have

$$
\langle y | C | x \rangle = \langle y | U _ { m } U _ { m - 1 } \cdot \cdot \cdot U _ { 1 } | x \rangle = \sum _ { \tau \in { \cal T } } \langle y | U _ { m , \tau } U _ { m - 1 , \tau } \cdot \cdot \cdot U _ { 1 , \tau } | x \rangle .
$$

Dealing with the sub-instance. For each $\tau \in \mathcal { T }$ and an index $i \in [ m ]$ , we are going to show that $U _ { i , \tau }$ can be decomposed as $U _ { i , \tau } ^ { A } \otimes U _ { i , \tau } ^ { B }$ , where $U _ { i , \tau } ^ { A }$ and $U _ { i , \tau } ^ { B }$ are operators on $\mathcal { H } _ { A }$ and $\mathcal { H } _ { B }$ respectively.

When $i \in R$ , by definition, there exist $x , y \in \{ 0 , 1 \} ^ { 2 }$ and $\alpha \in \mathbb { C }$ such that

$$
U _ { i , \tau } = \alpha \cdot | y \rangle \langle x | \otimes I _ { [ n ] \setminus \{ a _ { i } , b _ { i } \} } = \alpha \cdot \left( | y _ { 0 } \rangle \langle x _ { 0 } | \otimes I _ { A \setminus \{ a _ { i } \} } \right) \otimes \left( | y _ { 1 } \rangle \langle x _ { 1 } | \otimes I _ { B \setminus \{ b _ { i } \} } \right) .
$$

Otherwise $i \not \in R$ . In this case, if $O _ { i }$ is of the form $O _ { i } \otimes I _ { [ n ] \backslash \{ a _ { i } , b _ { i } \} }$ , then $a _ { i } , b _ { i }$ must be both in $A$ or in $B$ and the claim trivially holds; and the claim is also obvious when $O _ { i }$ is of the form $O _ { i } \otimes I _ { [ n ] \backslash \{ a _ { i } \} }$ or $I _ { [ n ] }$ .

Moreover, one can easily verify that each $U _ { i , \tau } ^ { A }$ is of the form $O _ { i } ^ { A } \otimes I _ { A \backslash \{ a _ { i } , b _ { i } \} }$ or $O _ { i } ^ { A } \otimes I _ { A \backslash \{ a _ { i } \} }$ or simply $I _ { A }$ , in which $O _ { i } ^ { A }$ is (respectively) a 2-qubit operator on $\mathcal { H } _ { \{ a _ { i } , b _ { i } \} }$ or a 1-qubit operator on ${ \mathcal { H } } _ { \{ a _ { i } \} } { \mathrm { . } }$ ), and the same holds for each $U _ { i , \tau } ^ { B }$ .

Hence, we have

$$
\begin{array} { r l } & { \quad \langle y | U _ { m } U _ { m - 1 } \cdot \cdot \cdot U _ { 1 } | x \rangle } \\ & { = \displaystyle \sum _ { \tau \in { \mathcal { T } } } \langle y | U _ { m , \tau } U _ { m - 1 , \tau } \cdot \cdot \cdot U _ { 1 , \tau } | x \rangle . } \\ & { = \displaystyle \sum _ { \tau \in { \mathcal { T } } } \langle y | \big ( U _ { m , \tau } ^ { A } \otimes U _ { m , \tau } ^ { B } \big ) \big ( U _ { m - 1 , \tau } ^ { A } \otimes U _ { m - 1 , \tau } ^ { B } \big ) \cdot \cdot \cdot \big ( U _ { 1 , \tau } ^ { A } \otimes U _ { 1 , \tau } ^ { B } \big ) | x \rangle . } \\ & { = \displaystyle \sum _ { \tau \in { \mathcal { T } } } \langle y _ { A } | U _ { m , \tau } ^ { A } U _ { m - 1 , \tau } ^ { A } \cdot \cdot \cdot U _ { 1 , \tau } ^ { A } | x _ { A } \rangle \cdot \langle y _ { B } | U _ { m , \tau } ^ { B } U _ { m - 1 , \tau } ^ { B } \cdot \cdot \cdot U _ { 1 , \tau } ^ { B } | x _ { B } \rangle , } \end{array}
$$

where $x _ { A } , x _ { B } \ ( y _ { A } , y _ { B } )$ is the projection of $x \left( y \right)$ on $\mathcal { H } _ { A }$ and $\mathcal { H } _ { B }$

So from the above discussion, we can then calculate $\langle y _ { A } | U _ { m , \tau } ^ { A } U _ { m - 1 , \tau } ^ { A } \cdot \cdot \cdot U _ { 1 , \tau } ^ { A } | x _ { A } \rangle$ with a recursive call with computational basis states $\vert x _ { A } \rangle$ and $\left| y _ { A } \right.$ , grid $A$ , and $m$ m,τgates .

The matrix element $\langle y _ { B } | U _ { m , \tau } ^ { B } U _ { m - 1 , \tau } ^ { B } \cdot \cdot \cdot U _ { 1 , \tau } ^ { B } | x _ { B } \rangle$ can 1,τ 2,τ m,τ  computed similarly. After that we sum up all the terms in (3) to get the answer.

Complexity analysis. Now we are going to bound the running time. Let $F ( n )$ be an upper bound on the running time when the size of the remaining grid is $n$ . Then we have

$$
F ( n ) = \left\{ \begin{array} { l l } { { O ( m ) } } & { { \mathrm { ~ w h e n ~ } n = 1 . } } \\ { { 2 ^ { O ( d \sqrt { n } ) } \cdot \operatorname* { m a x } _ { k \in [ n / 3 , 2 n / 3 ] } F ( k ) } } & { { \mathrm { ~ o t h e r w i s e . ~ } } } \end{array} \right.
$$

The second case is due to the fact that the sizes of sub-instances (i.e., the sizes of $A$ and $B$ ) lie in $[ n / 3 , 2 n / 3 ]$ , and $\mathcal { T } = 1 6 ^ { | R | } = 2 ^ { O ( d \sqrt { n } ) }$ . It is not hard to see that $F ( n )$ is an increasing function, so we have √ $F ( n ) =$ $2 ^ { O ( d \sqrt { n } ) } F ( 2 n / 3 )$ for $n > 1$ , which further simplifies to $F ( n ) = 2 ^ { O ( d { \sqrt { n } } ) }$ .

Finally, we can see that at each recursion level, we need $O ( d \cdot n )$ space to store the circuit, and $O ( 1 )$ space to store the intermediate answer. Since there are at most $\log n$ recursion levels, the space complexity is $O ( d \cdot n \log n )$ .

Interestingly, by using tensor network methods, Markov and Shi [MS08] gave an algorithm for simulating quantum circuits on grids with similar running time to ours. However, the difference is that Markov√ √ √ and Shi’s algorithm requires $2 ^ { O ( d { \sqrt { n } } ) }$ time and $2 ^ { O ( d { \sqrt { n } } ) }$ space, whereas ours requires $2 ^ { O ( d { \sqrt { n } } ) }$ time and only polynomial space.

The algorithm of Theorem 4.3 achieves a speedup over Theorem 4.1 only for small $d$ , but we can combine it with the algorithm in Theorem 4.1 to get a faster algorithm for the whole range of $d$ .

Theorem 4.4. There is a constant c such that, given a quantum circuit $C$ on n qubits with depth $d ,$ , and two computational basis states $| x \rangle , | y \rangle$ , assuming that $G _ { C }$ can be embedded into a two dimensional grid with size $n$ (with the embedding explicitly specified), we can compute $\langle y | C | x \rangle$ in

$$
O ( 2 ^ { n } \cdot \left[ 1 + \left( { \frac { d } { c { \sqrt { n } } } } \right) ^ { n + 1 } \right] )
$$

time and $O ( d \cdot n \log n )$ space.

Proof. By Theorem 4.3, there is a constant $c$ such that we have an √ $O ( 2 ^ { n } )$ time and polynomial space algorithm for calculating $\langle y | C | x \rangle$ when the depth is at most $c \sqrt { n }$ for circuit on grids. So we can use the same algorithm as in Theorem 4.1, except that we revert to the algorithm in Theorem 4.3 when the depth is no√ more than $c \sqrt { n }$ .

We still let $F ( d )$ be the running time on a circuit of $d$ layers. We then have $F ( d ) = O ( 2 ^ { n } )$ when $d \leq c { \sqrt { n } }$ . From the above discussion, we can see that for $d > c { \sqrt { n } }$ ,

$$
F ( d ) \leq 2 ^ { n + 1 } \cdot F ( \lceil \frac { d } { 2 } \rceil ) = O ( 2 ^ { n } \cdot 2 ^ { ( n + 1 ) \lceil \log ( d / c \sqrt { n } ) \rceil } ) = O ( 2 ^ { n } \cdot \left( \frac { d } { c \sqrt { n } } \right) ^ { n + 1 } ) ,
$$

which proves the running time bound. And it is not hard to see that the algorithm’s space usage is dominated by $O ( d \cdot n \log n )$ .

# 4.3 Space-Time Trade-off Schemes

We now show how to optimize the running time for whatever space is available.

Theorem 4.5. Given a quantum circuit $C$ on $n$ qubits with depth $d _ { \ i }$ , two computational basis states $| x \rangle , | y \rangle$ and an integer $k$ , we can compute $\langle y | C | x \rangle$ in

$$
O ( n 2 ^ { n - k } \cdot 2 ^ { ( k + 1 ) \lceil \log d \rceil } ) \le O ( n 2 ^ { n - k } \cdot ( 2 d ) ^ { k + 1 } )
$$

time and $O ( 2 ^ { n - k } \log d )$ space.

Proof. Decomposing the whole Hilbert space $\mathcal { H } _ { [ n ] }$ . We first decompose $\mathcal { H } _ { [ n ] }$ into a direct sum of many subspaces. Let $w _ { i }$ be the $i$ -th string in $\{ 0 , 1 \} ^ { k }$ in lexicographic order. For each $i ~ \in ~ [ 2 ^ { k } ]$ , let $\mathcal { H } _ { i } ~ =$ $\mathsf { S p a n } ( | w _ { i } 0 ^ { n - k } \rangle , . . . | w _ { i } 1 ^ { n - k } \rangle )$ . Then we have

$$
\mathcal { H } _ { [ n ] } = \bigoplus _ { i = 1 } ^ { 2 ^ { k } } \mathcal { H } _ { i } .
$$

Also, let $\mathcal { P } _ { i }$ be the projection from $\mathcal { H } _ { [ n ] }$ to $\mathcal { H } _ { i }$ ; then

$$
I _ { [ n ] } = \sum _ { i = 1 } ^ { 2 ^ { k } } \mathcal { P } _ { i } .
$$

Now we generalize the original problem as follows: given two indices $s , t \in [ 2 ^ { k } ]$ and a pure state $| u \rangle$ in $\mathcal { H } _ { s }$ , we want to compute $\mathcal { P } _ { t } C | u \rangle$ . By choosing $s$ and $t$ such that $\mathcal { H } _ { s }$ contains $| x \rangle$ and $\mathcal { H } _ { t }$ contains $| y \rangle$ , we can easily solve the original problem.

The base case $d = 1$ . When there is only one layer, $\mathcal { P } _ { t } C | u \rangle$ can be calculated straightforwardly in $O ( n \cdot 2 ^ { n - k } )$ time and $O ( 2 ^ { n - k } )$ space.

Recursion. When $d > 1$ , we have

$$
\begin{array} { r l } & { \mathcal { P } _ { t } C | u \rangle = \mathcal { P } _ { t } C _ { [ d  d / 2 + 1 ] } \cdot C _ { [ d / 2  1 ] } | u \rangle } \\ & { \quad \quad = \mathcal { P } _ { t } C _ { [ d  d / 2 + 1 ] } ( \displaystyle \sum _ { z \in [ 2 ^ { k } ] } \mathcal { P } _ { z } ) C _ { [ d / 2  1 ] } | u \rangle } \\ & { \quad \quad = \displaystyle \sum _ { z \in [ 2 ^ { k } ] } \mathcal { P } _ { t } C _ { [ d  d / 2 + 1 ] } \mathcal { P } _ { z } C _ { [ d / 2  1 ] } | u \rangle . } \end{array}
$$

We can then calculate $\mathcal { P } _ { t } C _ { [ d  d / 2 + 1 ] } \mathcal { P } _ { z } C _ { [ d / 2  1 ] } | u \rangle$ for each $z$ as follows: we first use a recursive call to get $| b \rangle = \mathcal { P } _ { z } C _ { [ d / 2  1 ] } | u \rangle$ and a second recursive call to compute $\mathcal { P } _ { t } C _ { [ d  d / 2 + 1 ] } | b \rangle$ (note that $| b \rangle \in \mathcal { H } _ { z }$ ).

Complexity analysis. It is easy to see that the total space usage is $O ( 2 ^ { n - k } \log d )$ , since for each $i$ storing a vector in $\mathcal { H } _ { i }$ takes $O ( 2 ^ { n - k } )$ space, and we only need to record $O ( 1 )$ such vectors at each recursion level. In addition, when $d = 1$ , we need only $O ( 2 ^ { n - k } )$ space.

For the running time bound, let $F ( d )$ denote the running time on a circuit of $d$ layers; then $F ( 1 ) =$ $O ( n 2 ^ { n - k } )$ . From the above discussion, it follows that

$$
F ( d ) \leq 2 ^ { k + 1 } \cdot F ( \lceil d / 2 \rceil ) = O ( n 2 ^ { n - k } \cdot 2 ^ { ( k + 1 ) \lceil \log ( d ) \rceil } ) = O ( n 2 ^ { n - k } \cdot ( 2 d ) ^ { k + 1 } ) .
$$

The above trade-off scheme can be further improved for quantum circuits on grids.

Theorem 4.6. There is a constant c such that, given a quantum circuit $C$ on n qubits with depth d, two computational basis states $| x \rangle , | y \rangle$ and an integer $k$ , assuming that $G _ { C }$ can be embedded into a two dimensional grid with size $n$ , we can compute $\langle y | C | x \rangle$ in

$$
2 ^ { O ( n ) } \cdot \left[ 1 + ( 2 d / c \sqrt { n } ) ^ { k + 1 } \right]
$$

time and

$$
O \left( 2 ^ { n - k } \operatorname* { m a x } ( 1 , \log ( d / { \sqrt { n } } ) ) \right)
$$

space.

Proof. By Theorem 4.3, there is a constant $c$ such that we have an √ $O ( 2 ^ { n } )$ time algorithm for calculating $\langle y | C | x \rangle$ for circuits on grids with depth at most $c \sqrt { n }$ .

Then we use the same algorithm as in Theorem 4.5, with the only modification that when $d \leq c { \sqrt { n } }$ , we calculate $\mathcal { P } _ { t } \cdot C | u \rangle$ by $2 ^ { 2 ( n - \bar { k } ) }$ calls of the algorithm in Theorem 4.3.

With the same analysis as in Theorem 4.5, when $d > c { \sqrt { n } }$ , we can see that the total space usage is $O ( 2 ^ { n - k } \log ( d / c { \sqrt { n } } ) )$ , and the running time is

$$
O ( 2 ^ { n + 2 ( n - k ) + ( k + 1 ) \lceil \log ( d / c \sqrt { n } ) \rceil } ) = O ( 2 ^ { O ( n ) } \cdot ( 2 d / c \sqrt { n } ) ) ^ { k + 1 } ) .
$$

Combining with the algorithm for $d \leq c { \sqrt { n } }$ proves our running time and space bound.

# 5 Strong Quantum Supremacy Theorems Must Be Non-Relativizing

In this section we show that there is an oracle relative to which SampBPP $=$ SampBQP, yet $\mathsf { P H } ^ { \mathcal { O } }$ is infinite.

Recall that an oracle $\mathcal { O }$ is a function $\mathcal { O } : \{ 0 , 1 \} ^ { * } \to \{ 0 , 1 \}$ , and the combination of two oracles $\mathcal { O } _ { 0 } , \mathcal { O } _ { 1 }$ , denoted as $\mathcal { O } _ { 0 } \oplus \mathcal { O } _ { 1 }$ , simply maps $z \in \{ 0 , 1 \} ^ { * }$ to $\mathcal { O } _ { z _ { 1 } } ( z _ { 2 } , z _ { 3 } , . . . , z _ { | z | } )$ (cf. [FFKL03]). We use ${ \mathcal { O } } _ { n }$ to denote the restriction of $\mathcal { O }$ on $\{ 0 , 1 \} ^ { n }$ .

# 5.1 Intuition

We have two simultaneous objectives: (1) we need SampBPP and SampBQP to be equal; and (2) we also need PH to be infinite. So it will be helpful to review some previous results on (1) and (2) separately.

• An oracle $\mathcal { O }$ such that ${ \mathsf { S a m p B P P } } ^ { \mathcal { O } } = { \mathsf { S a m p B Q P } } ^ { \mathcal { O } }$ : in order to make two classes equal, we can use the standard method: adding a much more powerful oracle [BGS75]. That is, we set $\mathcal { O }$ to be a PSPACE-complete language, like TQBF. Then it is easy to see both SampBPPTQBF and SampBQPTQBF become SampPSPACE (i.e., the class of approximate sampling problems solvable in polynomial space).

• An oracle $\mathcal { O }$ such that $\mathsf { P H } ^ { \mathcal { O } }$ is infinite: a line of works by Yao [Yao85], Hastad [Has86], and others ˚ constructed relativized worlds where PH is infinite, and a very recent breakthrough by Rossman, Servedio, and Tan [RST15] even shows that PH is infinite relative to a random oracle with probability 1.

# A Failed Attempt: Direct Combination

The first natural idea is to combine the previous two results straightforwardly by setting the oracle to be TQBF $\oplus \mathcal { O }$ , where $\mathcal { O }$ is a random oracle.

Alas, it is not hard to see that this does not work: while PH is still infinite, a SampBQP algorithm can perform Fourier Sampling (cf. Definition 6.2) on the random oracle bits, and it is known that no SampBPP algorithm can do that [AA15] (see also Theorem 6.8). Hence, in this case SampBQP $\neq$ SampBPP.

# Another Failed Attempt: Hiding a “Secret Random String” in a Secret Location

The failure of the naive approach suggests that we must somehow “hide” the random oracle bits, since if the SampBQP algorithm has access to them, then SampBPP and SampBQP will not be equal. More specifically, we want to hide a “secret random string” among the oracle bits so that:

(1) a PH algorithm can find it, so that PH is still infinite, but   
(2) a SampBQP algorithm cannot find it, so that we can still make SampBPP $=$ SampBQP by attaching a TQBF oracle.

Inspired by the so-called cheat-sheet construction [ABDK15], it is natural to consider a direct hiding scheme. Imagine that the oracle bits are partitioned into two parts: one part is $\log N$ copies of the OR function on $N$ bits, and another part is $N$ binary strings $y _ { 1 } , \ldots , y _ { N }$ , each with length $N$ . Let $t = a _ { 1 } , a _ { 2 } , \ldots , a _ { \log N } \in \{ 0 , 1 \} ^ { \log N }$ be the answer to the copies of OR; we can also interpret $t$ as an integer in $[ N ]$ . Finally, set $y _ { t }$ to be a random input, while other $y _ { i }$ ’s are set to zero.

Intuitively, a PH algorithm can easily evaluate the $\log N$ copies of OR and then get access to the random string; while it is known that OR is hard for a quantum algorithm, so no quantum algorithm should be able to find the location of the random string efficiently.

Unfortunately, there is a fatal issue with the above approach: a SampBQP algorithm is also given an input $x \in \{ 0 , 1 \} ^ { n }$ and it may guess that the input $x$ denotes the location of the random string. That is, on some particular input, the SampBQP algorithm is “lucky” and gets access to the random string, which still makes SampBPP and SampBQP unequal.

# Hiding the “Secret Random String” in a Bunch of OR’s

Therefore, our final construction goes further. Instead of hiding the random string in a secret location amid the oracle bits, we hide it using a bunch of ORs. That is, suppose we want to provide $N$ uniform random bits. Then we provide them each as an OR of $N$ bits. In this way, a PH algorithm is still able to access the random bits, while a quantum algorithm, even if it’s “lucky” with its additional input, still can’t get access to these hidden random bits.

# 5.2 Implementation

# The Distribution $\mathcal { D } _ { \mathcal { O } }$ on Oracles.

We first describe formally how to hide a random string inside a bunch of OR’s by defining a distribution $\mathcal { D } _ { \mathcal { O } }$ on oracles.

For notational convenience, our constructed oracles always map all odd-length binary strings to 0. So we can alternatively describe such an oracle $\mathcal { O }$ by a collection of functions $\{ f _ { n } \} _ { n = 0 } ^ { + \infty }$ , where each $f _ { n }$ is a function from $\{ 0 , 1 \} ^ { 2 n }  \{ 0 , 1 \}$ . That is, $\mathcal { O } _ { 2 n }$ is set to be $f _ { n }$ for each $n$ , while the $\mathcal { O } _ { 2 n + 1 }$ ’s are all constant zero functions.

For each string $p \in \{ 0 , 1 \} ^ { n }$ , we use $B _ { n , p }$ to denote the set of strings in $\{ 0 , 1 \} ^ { 2 n }$ with $p$ as a prefix. Now we first define a distribution $\mathcal { D } _ { n }$ on functions $\{ 0 , 1 \} ^ { 2 n }  \{ 0 , 1 \}$ , from which a sample function $f _ { n }$ is generated as follows: initially, we set $f _ { n } ( x ) = 0$ for all $x \in \{ 0 , 1 \} ^ { 2 n }$ ; then for each $p \in \{ 0 , 1 \} ^ { n }$ , with probability 0.5, we pick an element $e$ in $B _ { n , p }$ at uniformly random and set $f _ { n } ( e ) = 1$ . Observe that by taking the OR of each $B _ { n , p }$ , we get a function $g ( p ) : = \vee _ { x \in B _ { n , p } } f _ { n } ( x )$ , which is a uniform random function from $\{ 0 , 1 \} ^ { n }$ to $\{ 0 , 1 \}$ by construction.

Finally, the $\mathcal { D } _ { n }$ ’s induce a distribution $\mathcal { D } _ { \mathcal { O } }$ on oracles, which generates an oracle $\mathcal { O }$ by drawing $f _ { n } \sim \mathcal { D } _ { n }$ independently for each integer $n$ . That is, we set $\mathcal { O } _ { 2 n }$ to be $f _ { n }$ , and $\mathcal { O } _ { 2 n + 1 }$ to be 0, for each $n$ .

Having defined the distribution $\mathcal { D } _ { \mathcal { O } }$ , we are ready to state our result formally.

Theorem 5.1. For an oracle $\mathcal { O }$ drawn from the distribution $\mathcal { D } _ { \mathcal { O } }$ , the following two statements hold with probability 1:

• $S a m p B P P ^ { T O B F , \mathcal { O } } = S a m p B Q P ^ { T O B F , \mathcal { O } } .$ • $P H ^ { T Q B F , \mathcal { O } }$ is infinite.

From which our desired result follows immediately.

Corollary 5.2. There exists an oracle $\mathcal { O } ^ { \prime } = T Q B F \oplus \mathcal { O }$ such that SampBPPO0 = SampBQPO0 and $P H ^ { \mathcal { O } ^ { \prime } }$ is infinite.

The rest of this section is devoted to the proof of Theorem 5.1.

# 5.3 SampBPPTQBF, $^ { \mathcal { O } } =$ SampBQPTQBF,O with Probability 1.

We first describe an algorithm for simulating SampBQPTQBF,O in SampBPPTQBF,O, thereby proving the first part of Theorem 5.1. In the following, we assume that all oracle algorithms are given access to two oracles, TQBF and $\mathcal { O }$ .

Given a SampBQP oracle algorithm $M$ , our central task is to give a SampBPP oracle algorithm that simulates $M$ closely. Formally:

Lemma 5.3. For any SampBQP oracle algorithm $M$ , there is a SampBPP oracle algorithm $A$ such that: Let $\mathcal { O }$ be an oracle drawn from $\mathcal { D } _ { \mathcal { O } }$ , and let $\mathcal { D } _ { x , \varepsilon } ^ { M }$ and $\mathcal { D } _ { x , \varepsilon } ^ { A }$ be the distributions output by $M ^ { T Q B F , \mathcal { O } }$ and $A ^ { T Q B F , \mathcal { O } }$ respectively on input $\langle x , 0 ^ { 1 / \varepsilon } \rangle$ . Then with probability at least $1 - \exp \{ - ( 2 \cdot | x | + 1 / \varepsilon ) \}$ , we have

$$
\| \mathcal { D } _ { x , \varepsilon } ^ { M } - \mathcal { D } _ { x , \varepsilon } ^ { A } \| \leq \varepsilon .
$$

Before proving Lemma 5.3, we show it implies the first part of Theorem 5.1.

Proof of the first part of Theorem 5.1. Fix a SampBQP oracle algorithm $M$ , and let $\mathcal { O }$ be an oracle drawn from $\mathcal { D } _ { \mathcal { O } }$ . We first show that with probability 1, there is a classical algorithm $A _ { M }$ such that

$$
\begin{array} { r } { \| \mathcal { D } _ { x , \varepsilon } ^ { M } - \mathcal { D } _ { x , \varepsilon } ^ { A _ { M } } \| \leq \varepsilon \mathrm { ~ f o r ~ a l l ~ } x \in \{ 0 , 1 \} ^ { * } \mathrm { ~ a n d ~ } \varepsilon = 2 ^ { - k } \mathrm { ~ f o r ~ s o m e ~ i n t e g e r ~ } k . } \end{array}
$$

Let $A$ be the SampBPP algorithm guaranteed by Lemma 5.3. For an input $x \in \{ 0 , 1 \} ^ { * }$ and an integer k, we call (x, k) a bad pair if kDMx,2− $\| \mathcal { D } _ { x , 2 ^ { - k } } ^ { M } - \mathcal { D } _ { x , 2 ^ { - k } } ^ { A } \| > 2 ^ { - k }$ . By Lemma 5.3, the expected number of bad pairs is upper-bounded by

$$
\sum _ { n = 1 } ^ { + \infty } 2 ^ { n } \cdot \sum _ { k = 1 } ^ { + \infty } \exp ( - ( 2 n + 2 ^ { k } ) ) \leq \sum _ { n = 1 } ^ { + \infty } \sum _ { k = 1 } ^ { + \infty } \exp ( - ( n + k ) ) \leq O ( 1 ) .
$$

This means that with probability 1, there are only finitely many bad pairs, so we can handle them by hardwiring their results into the algorithm $A$ to get the algorithm $A _ { M }$ we want.

Since there are only countably many SampBQP oracle algorithms $M$ , we see with probability 1, for every SampBQP oracle algorithm $M$ , there is a classical algorithm $A _ { M }$ such that (4) holds. We claim that in that case, $\mathsf { S a m p B Q P ^ { T Q B F , O } = S a m p B P P ^ { T Q B F , O } }$ .

Let $\boldsymbol { s }$ be a sampling problem in $\dot { \mathsf { S a m p B Q P } } ^ { \mathsf { T Q B F } , \mathcal { O } }$ . This means that there is a SampBQP oracle algorithm $M$ , such that for all $x \in \{ 0 , 1 \} ^ { * }$ and $\varepsilon$ , we have $\| \mathcal { D } _ { x , \varepsilon } ^ { M } - \mathcal { S } _ { x } \| \leq \varepsilon$ . Let $A _ { M }$ be the corresponding SampBPP algorithm. Now consider the following algorithm $A ^ { \prime }$ : given input $\langle x , 0 ^ { 1 / \varepsilon } \rangle$ , let $k$ be the smallest integer such that $2 ^ { - k } \leq \varepsilon / 2$ ; then run $A _ { M }$ on input $\langle x , 0 ^ { 2 ^ { k } } \rangle$ to get a sample from $\mathcal { D } _ { x , 2 ^ { - k } } ^ { A _ { M } }$

Since

$$
\begin{array} { r l } & { \| \mathcal { D } _ { x , \varepsilon } ^ { A ^ { \prime } } - S _ { x } \| = \| \mathcal { D } _ { x , 2 ^ { - k } } ^ { A _ { M } } - S _ { x } \| } \\ & { \qquad \leq \| \mathcal { D } _ { x , 2 ^ { - k } } ^ { M } - \mathcal { D } _ { x , 2 ^ { - k } } ^ { A _ { M } } \| + \| \mathcal { D } _ { x , 2 ^ { - k } } ^ { M } - S _ { x } \| \leq 2 \cdot 2 ^ { - k } \leq \varepsilon , } \end{array}
$$

this means that $A ^ { \prime }$ solves $\boldsymbol { \mathcal { S } }$ and $\mathcal { S } \in \mathsf { S a m p B P P } ^ { \mathsf { T Q B F } , \mathcal { O } }$ . So SampBQPTQBF, $^ { \mathcal { O } } \subseteq$ SampBPPTQBF,O with probability 1, which completes the proof.

We now prove Lemma 5.3, which is the most technical part of the whole section.

Proof of Lemma 5.3. Recall that from the canonical description in Section 2.2, there exists a fixed polynomial $p$ , such that given input $\langle x , 0 ^ { 1 / \varepsilon } \rangle$ , the machine $M$ first constructs a quantum circuit $C$ with $N =$ $p ( | x | , 1 / \varepsilon )$ qubits and $N$ gates classically ( $C$ can contain TQBF and $\mathcal { O }$ gates). We first set up some notation.

Notation. Recall that $\mathcal { O }$ can be specified by a collection of functions $\{ f _ { n } \} _ { n = 0 } ^ { + \infty }$ , where each $f _ { n }$ maps $\{ 0 , 1 \} ^ { 2 n }$ to $\{ 0 , 1 \}$ . Without loss of generality, we can assume that all the $\mathcal { O }$ gates act on an even number of qubits, and for each $n$ , all the $f _ { n }$ gates act on the first $2 n$ qubits.

For a function $f : \{ 0 , 1 \} ^ { k } \to \{ 0 , 1 \}$ , we use $U _ { f }$ to denote the unitary operator mapping $| i \rangle$ to $( - 1 ) ^ { f ( i ) } | i \rangle$ for $i \in \{ 0 , 1 \} ^ { k }$ .

Suppose there are $_ { T \ O }$ -gates in total, and suppose the $i$ -th $\mathcal { O }$ -gate is an $f _ { n _ { i } }$ gate. Then the unitary operator $U$ applied by the circuit $C$ can be decomposed as

$$
U = U _ { T + 1 } ( U _ { f _ { n _ { T } } } \otimes I _ { N - 2 n _ { T } } ) \cdot \cdot \cdot ( U _ { f _ { n _ { 2 } } } \otimes I _ { N - 2 n _ { 2 } } ) U _ { 2 } ( U _ { f _ { n _ { 1 } } } \otimes I _ { N - 2 n _ { 1 } } ) U _ { 1 } ,
$$

where the $U _ { i }$ ’s are the unitary operators corresponding to the sub-circuits which don’t contain an $\mathcal { O }$ gate.

Our algorithm proceeds by replacing each $\mathcal { O }$ -gate by a much simpler gate, one by one, without affecting the final quantum state too much. It then simulates the final circuit with the help of the TQBF oracle.

Replacing the $t$ -th $\mathcal { O }$ -gate. Suppose we have already replaced the first $t - 1 \mathcal { O }$ -gates. That is, for each $i \in [ t - 1 ]$ , we replaced the $f _ { n _ { i } }$ gate (the $i$ -th $\mathcal { O }$ -gate) with a $g _ { i }$ gate, and now we are going to replace the $t$ -th $\mathcal { O }$ -gate.

Let

$$
| v \rangle = U _ { t } ( U _ { g _ { t - 1 } } \otimes I _ { N - 2 n _ { t - 1 } } ) \cdot \cdot \cdot ( U _ { g _ { 2 } } \otimes I _ { N - 2 n _ { 2 } } ) U _ { 2 } ( U _ { g _ { 1 } } \otimes I _ { N - 2 n _ { 1 } } ) U _ { 1 } | 0 \rangle ^ { \otimes N } ,
$$

which is the quantum state right before the $t { \cdot }$ -th $\mathcal { O }$ gate in the circuit after the replacement.

For brevity, we use $f$ to denote the function $f _ { n _ { t } }$ , and we drop the subscript $t$ of $n _ { t }$ when it is clear from context.

Analysis of incurred error. The $t$ -th $\mathcal { O }$ -gate is an $f$ gate. If we replace it by a $g$ gate, the change to the quantum state is

$$
\| U _ { f } \otimes I _ { N - 2 n } | v \rangle - U _ { g } \otimes I _ { N - 2 n } | v \rangle \| = \| ( U _ { f } - U _ { g } ) \otimes I _ { N - 2 n } | v \rangle \| .
$$

We can analyze the above deviation by bounding its square. Let $H$ be the Hilbert space spanned by the last $N - 2 n$ qubits, and let $\rho = \mathrm { T r } _ { \cal H } [ | v \rangle \langle v | ]$ . Then we have

$$
\begin{array} { r l } & { \quad \| ( ( U _ { f } - U _ { g } ) \otimes I _ { N - 2 n } ) | v \rangle \| ^ { 2 } } \\ & { = \mathrm { T r } \left[ ( U _ { f } - U _ { g } ) ^ { \dagger } ( U _ { f } - U _ { g } ) \otimes I _ { N - 2 n } | v \rangle \langle v | \right] } \\ & { = \mathrm { T r } \left[ ( U _ { f } - U _ { g } ) ^ { \dagger } ( U _ { f } - U _ { g } ) \rho \right] . } \end{array}
$$

Note that

$$
( U _ { f } - U _ { g } ) ^ { \dagger } ( U _ { f } - U _ { g } ) = 4 \sum _ { f ( i ) \neq g ( i ) } | i \rangle \langle i |
$$

from the definition. So we can further simplify the above trace as

$$
\mathrm { T r } \left[ ( U _ { f } - U _ { g } ) ^ { \dagger } ( U _ { f } - U _ { g } ) \rho \right] = 4 \sum _ { f ( i ) \ne g ( i ) } \mathrm { T r } \left[ | i \rangle \langle i | \rho \right] = 4 \sum _ { f ( i ) \ne g ( i ) } \langle i | \rho | i \rangle .
$$

Now, $\rho$ is a (mixed) quantum state on the first $2 n$ bits, and $\langle i \vert \rho \vert i \rangle$ is the probability of seeing $i$ when measuring $\rho$ in the computational basis. So we can define a probability distribution $Q$ on $\{ 0 , 1 \} ^ { 2 n }$ by $Q ( i ) : = \langle i | \rho | i \rangle$ .

Using the distribution $Q$ , the error term (5) can finally be simplified as:

$$
4 \sum _ { i \in \{ 0 , 1 \} ^ { 2 n } } Q ( i ) \cdot [ f ( i ) \neq g ( i ) ] = 4 \cdot \operatorname * { P r } _ { i \sim Q } [ f ( i ) \neq g ( i ) ] ,
$$

where $[ f ( i ) \neq g ( i ) ]$ is the indicator function that takes value 1 when $f ( i ) \neq g ( i )$ and 0 otherwise.

A posterior distribution $\mathcal { D } _ { n } ^ { \mathsf { p o s t } }$ on functions from $\{ 0 , 1 \} ^ { 2 n }  \{ 0 , 1 \}$ . Now, recall that $f = f _ { n }$ is a function drawn from the distribution $\mathcal { D } _ { n }$ . Our goal is to replace $f$ by another simple function $g$ , such that with high probability, the introduced deviation (6) is small.

Note that when replacing the $t$ -th $\mathcal { O }$ gate, we may already have previously queried some contents of $f$ (i.e., it is not thn functions from $f _ { n }$ he circuit). So we need to c. That is, we want a function sider the posterior distribution , such that with high probabilit $\mathcal { D } _ { n } ^ { \mathsf { p o s t } }$ $\{ 0 , 1 \} ^ { 2 n }  \{ 0 , 1 \}$ $g$ $f \sim \mathcal { D } _ { n } ^ { \mathsf { p o s t } }$ , the error term (6) is small.

We use a function $f _ { \mathsf { k n o w n } } : \{ 0 , 1 \} ^ { 2 n } \to \{ 0 , 1 , * \}$ to encode our knowledge: if $f ( i )$ is not queried, then we sfrom $f _ { \mathsf { k n o w n } } ( i ) : = *$ ; otherwise we set ing on the event th $f _ { \mathsf { k n o w n } } ( i ) : = f ( i )$ . Twith $\mathcal { D } _ { n } ^ { \mathsf { p o s t } }$ is simply the distribution obtained $\mathcal { D } _ { n }$ $f$ $f _ { \mathsf { k n o w n } }$

We can now work out the posterior distribution $\mathcal { D } _ { n } ^ { \mathsf { p o s t } }$ from the definition of $\mathcal { D } _ { n }$ and Bayes’ rule.

For $f \sim \mathcal { D } _ { n } ^ { \mathsf { p o s t } }$ , we can see that all the sets $B _ { n , p }$ (recall that $B _ { n , p }$ is the set of all strings in $\{ 0 , 1 \} ^ { 2 n }$ with $p$ as a prefix) are still independent. So we can consider each set separately.

For each $p \in \{ 0 , 1 \} ^ { n }$ , if there is an $x \in B _ { n , p }$ such that $f _ { \mathsf { k n o w n } } ( x ) = 1$ , then by the construction of $\mathcal { D } _ { n }$ all other elements $y \in B _ { n , p }$ must satisfy $f ( y ) = 0$ .

Otherwise, if there is no $x \in B _ { n , p }$ such that $f _ { \mathsf { k n o w n } } ( x ) = 1$ , then we set $Z _ { p } = | \{ f _ { \mathrm { k n o w n } } ( x ) = 0 \mid x \in$ $B _ { n , p } \} |$ and note that $| B _ { n , p } | = 2 ^ { n }$ . By Bayes’ rule, we see that with probability $\frac { 1 } { 2 - Z _ { p } \cdot 2 ^ { - n } }$ p · 2−n , all y ∈ Bn,p satisfy $f ( y ) = 0$ ; and for each $y \in B _ { n , p }$ such that $f _ { \mathsf { k n o w n } } ( y ) = *$ , with probability $\frac { 2 ^ { - n } } { 2 - Z _ { p } \cdot 2 ^ { - n } }$ · 2−n , we have that $y$ is the only element of $B _ { n , p }$ that satisfies $f ( y ) = 1$ .

Construction and Analysis of $g$ . Our construction of $g$ goes as follows: we first set $g ( x ) = f _ { \mathsf { k n o w n } } ( x )$ for all $x$ such that $f _ { \mathsf { k n o w n } } ( x ) \neq *$ . Then for a parameter $\tau$ which will be specified later, we query all $x \in \{ 0 , 1 \} ^ { 2 n }$ with $Q ( x ) \geq \tau$ , and set $g ( x ) = f ( x )$ for them. For all other positions of $g$ , we simply set them to zero. Hence, there are at most $O ( 1 / \tau ) + W$ ones in $g$ , where $W$ denotes the number of ones in fknown.

The following three properties of $g$ are immediate from the construction.

$f ( x ) \neq g ( x ) { \mathrm { ~ i m p l i e s ~ } } Q ( x ) \leq \tau .$ $g ( x ) = 1 { \mathrm { ~ i m p l i e s ~ } } f ( x ) = g ( x ) .$ For each $p \in \{ 0 , 1 \} ^ { n }$ , there is at most one $x \in B _ { n , p }$ with $f ( x ) \neq g ( x )$ .

Upper bounding the deviation (6). Now we are going to show that $\operatorname* { P r } _ { x \sim Q } [ f ( x ) \neq g ( x ) ]$ is very small, with overwhelming probability over the posterior distribution Dpostn .

We first define $2 ^ { n }$ random variables $\{ X _ { p } \} _ { p \in \{ 0 , 1 \} ^ { n } }$ , where $X _ { p } = \sum _ { x \in B _ { n , p } } Q ( x ) \cdot \left[ f ( x ) \neq g ( x ) \right]$ for each $p \in \{ 0 , 1 \} ^ { n }$ . By the construction of $\mathcal { D } _ { n } ^ { \mathsf { p o s t } }$ , we can see that all $X _ { p }$ ’s are independent. Moreover, by properties (7) and (9), there is at most one $x \in B _ { n , p }$ such that $f ( x ) \neq g ( x )$ , and that $x$ must satisfy $Q ( x ) \leq \tau$ . Therefore $X _ { p } \in [ 0 , \tau ]$ for every $p$ .

Let $X = \sum _ { p \in \{ 0 , 1 \} ^ { n } } X _ { p }$ , and $\mu = \operatorname { \mathbb { E } } [ X ]$ . Alternatively, we can write $X$ as

$$
X = \sum _ { x \in \{ 0 , 1 \} ^ { 2 n } } Q ( x ) \cdot [ f ( x ) \neq g ( x ) ] ,
$$

so

$$
\mu = \sum _ { x \in \{ 0 , 1 \} ^ { 2 n } } Q ( x ) \cdot \mathbb { E } [ f ( x ) \neq g ( x ) ] .
$$

We claim that $\mathbb { E } [ f ( x ) \neq g ( x ) ] \leq 2 ^ { - n }$ for all $x \in \{ 0 , 1 \} ^ { 2 n }$ , and consequently $\mu \leq 2 ^ { - n }$ . Fix an $x \in \{ 0 , 1 \} ^ { 2 n }$ , and suppose $x \in B _ { n , p }$ . When $g ( x ) = 1$ , we must have $f ( x ) = g ( x )$ by property (8). When $g ( x ) = 0$ , by the definition of $\mathcal { D } _ { n } ^ { \mathsf { p o s t } }$ , we have $f ( x ) = 1$ with probability at most 2 − Zp · 2−n ≤ 2−n . So $\mathbb { E } [ f ( i ) \neq g ( i ) ] \leq 2 ^ { - n }$ in both cases and the claim is established.

Applying the Chernoff Bound. Set δ = $\delta = \frac { \mu ^ { - 1 } \varepsilon ^ { 4 } } { 3 2 T ^ { 2 } }$ . If $\delta \leq 1$ , then we have

$$
3 2 T ^ { 2 } \varepsilon ^ { - 4 } \geq \mu ^ { - 1 } \geq 2 ^ { n } .
$$

This means that we can simply query all the positions in $f _ { n }$ using $2 ^ { 2 n } = O ( T ^ { 4 } \cdot \varepsilon ^ { - 8 } )$ queries, as this bound is polynomial in $| x |$ and $1 / \varepsilon$ (recall that $T \le N = p ( | x | , 1 / \varepsilon ) )$ .

Hence, we can assume that $\delta > 1$ . So by Corollary 2.7, we have

$$
\operatorname* { P r } \left[ X \ge 2 \delta \mu \right] \le \operatorname* { P r } \left[ X \ge ( 1 + \delta ) \mu \right] \le \exp \left\{ - \frac { \delta \mu } { 3 \tau } \right\} .
$$

Finally, we set $\tau = { \frac { \varepsilon ^ { 4 } } { 9 6 T ^ { 2 } \cdot ( 2 n + \varepsilon ^ { - 1 } + \ln T ) } }$ .

Therefore, with probability

$$
1 - \exp \left\{ - { \frac { \delta \mu } { 3 \tau } } \right\} = 1 - \exp ( - ( 2 n + \varepsilon ^ { - 1 } + \ln T ) ) = 1 - { \frac { \exp ( - ( 2 n + \varepsilon ^ { - 1 } ) } { T } } ,
$$

we have

$$
\| ( U _ { f } - U _ { g } ) \otimes I _ { N - 2 n } | v \rangle \| ^ { 2 } = 4 \cdot X \leq 8 \delta \mu = { \frac { \varepsilon ^ { 4 } } { 4 T ^ { 2 } } } ,
$$

which in turn implies

$$
\| ( U _ { f } - U _ { g } ) \otimes I _ { N - 2 n } | v \rangle \| \leq \frac { \varepsilon ^ { 2 } } { 2 T } .
$$

Moreover, we can verify that $g$ only has $O ( 1 / \tau ) + W = \mathrm { p o l y } ( n , 1 / \varepsilon )$ ones.

Analysis of the final circuit $C ^ { \mathrm { f i n a l } }$ . Suppose that at the end, for each $t \in [ T ]$ , our algorithm has replaced the $t$ -th $\mathcal { O }$ -gate with a $g _ { t }$ gate, where $g _ { t }$ is a function from $\{ 0 , 1 \} ^ { 2 n _ { t } }$ to $\{ 0 , 1 \}$ . Let $C ^ { \mathrm { f i n a l } }$ be the circuit after the replacement.

Let

$$
V = U _ { T + 1 } ( U _ { g _ { T } } \otimes I _ { N - 2 n _ { T } } ) \cdot \cdot \cdot ( U _ { g _ { 2 } } \otimes I _ { N - 2 n _ { 2 } } ) U _ { 2 } ( U _ { g _ { 1 } } \otimes I _ { N - 2 n _ { 1 } } ) U _ { 1 }
$$

be the unitary operator corresponding to $C ^ { \mathrm { f i n a l } }$ . Also, recall that $U$ is the unitary operator corresponding to the original circuit $C$ . We are going to show that $U | 0 \rangle ^ { \otimes N }$ and $V | 0 \rangle ^ { \otimes N }$ , the final quantum states produced by $U$ and $V$ respectively, are very close.

We first define a sequence of intermediate quantum states. Let $| u _ { 1 } \rangle = U _ { 1 } | 0 \rangle ^ { \otimes N }$ . Then for each $t > 1$ we define

$$
| u _ { t } \rangle = U _ { t } ( U _ { f _ { n _ { t - 1 } } } \otimes I _ { N - 2 n _ { t - 1 } } ) | u _ { t - 1 } \rangle .
$$

That is, $\left| u _ { t } \right.$ is the quantum state immediately before applying the $t$ -th $\mathcal { O }$ -gate in the original circuit. Similarly, we let $| v _ { 1 } \rangle = \overline { { U _ { 1 } } } | 0 \rangle ^ { \otimes N }$ , and

$$
| v _ { t } \rangle = U _ { t } ( U _ { g _ { t - 1 } } \otimes I _ { N - 2 n _ { t - 1 } } ) | u _ { t - 1 } \rangle
$$

for each $t > 1$

From the analysis of our algorithm, over $\mathcal { O } \sim \mathcal { D } _ { \mathcal { O } }$ , for each $t \in [ T ]$ , with probability $1 - \exp ( - ( 2 n +$ $\varepsilon ^ { - 1 } ) ) / T$ , we have

$$
\| U _ { f _ { n _ { t } } } \otimes I _ { N - 2 n _ { t } } | v _ { t } \rangle - U _ { g _ { t } } \otimes I _ { N - 2 n _ { t } } | v _ { t } \rangle \| \leq \frac { \varepsilon ^ { 2 } } { 2 T } .
$$

So by a simple union bound, with probability at least $1 - \exp ( - ( 2 n + \varepsilon ^ { - 1 } ) )$ , the above bound holds for all $t \in [ T ]$ . We claim that in this case, for each $t \in [ T + 1 ]$ , we have

$$
\| | v _ { t } \rangle - | u _ { t } \rangle \| \leq ( t - 1 ) \cdot \frac { \varepsilon ^ { 2 } } { 2 T } .
$$

We prove this by induction. Clearly it is true for $t = 1$ . When $t > 1$ , suppose (11) holds for $t - 1$ ; then

$$
\begin{array} { r l } {  { \| | v _ { t }  - | u _ { t }  \| = \| U _ { t } \big ( \mathcal { O } _ { g _ { t - 1 } } \otimes I _ { N - 2 n _ { t - 1 } } \big ) | v _ { t - 1 } \bigr \rangle - U _ { t } \big ( f _ { n _ { t - 1 } } \otimes I _ { N - 2 n _ { t - 1 } } \big ) | u _ { t - 1 } \bigr \rangle } \qquad } & { } \\ & { = \| U _ { g _ { t - 1 } } \otimes I _ { N - 2 n _ { t - 1 } } | v _ { t - 1 } \bigr \rangle - U _ { f _ { n _ { t - 1 } } } \otimes I _ { N - 2 n _ { t - 1 } } | u _ { t - 1 } \bigr \rangle \| } \\ & { \le \| U _ { g _ { t - 1 } } \otimes I _ { N - 2 n _ { t - 1 } } | v _ { t - 1 } \bigr \rangle - U _ { f _ { n _ { t - 1 } } } \otimes I _ { N - 2 n _ { t - 1 } } | v _ { t - 1 }  \| } \\ & { \quad + \| U _ { f _ { n _ { t - 1 } } } \otimes I _ { N - 2 n _ { t - 1 } } | v _ { t - 1 } \bigr \rangle - U _ { f _ { n _ { t - 1 } } } \otimes I _ { N - 2 n _ { t - 1 } } | u _ { t - 1 } \rangle \| } \\ & { \le \displaystyle \frac { \varepsilon ^ { 2 } } { 2 T } + \| | u _ { t - 1 }  - | v _ { t - 1 }  \| \le ( t - 1 ) \cdot \frac { \varepsilon ^ { 2 } } { 2 T } , } \end{array}
$$

where the second line holds by the fact that $U _ { t }$ is unitary, the third line holds by the triangle inequality, and the last line holds by (10) and the induction hypothesis.

Upper-bounding the error. Therefore, with probability at least $1 - \exp ( - ( 2 n + \varepsilon ^ { - 1 } ) )$ , we have

$$
\| | v _ { T + 1 } \rangle - | u _ { T + 1 } \rangle \| = \| U | 0 \rangle ^ { \otimes N } - V | 0 \rangle ^ { \otimes N } \| \leq \frac { \varepsilon ^ { 2 } } { 2 } .
$$

Now, our classical algorithm $A$ then simulates stage 2 and 3 of the SampBQP algorithm $M$ straightforwardly. That is, it first takes a sample $z$ by measuring $\left| v _ { T + 1 } \right.$ in the computational basis, and then outputs $A ^ { \mathsf { o u t p u t } } ( z )$ as its sample, where $A ^ { \mathsf { o u t p u t } }$ is the classical algorithm used by $M$ in stage 3.

From our previous analysis, $A$ queries the oracle only pol $\mathrm { y } ( n , 1 / \varepsilon )$ times. In addition, it is not hard to see that all the computations can be done in PSPACE, and therefore can be implemented in po $\mathrm { l y } ( n , 1 / \varepsilon )$ time with the help of the TQBF oracle. So $A$ is a SampBPP algorithm.

By Corollary 2.5, with probability at least $1 - \exp ( - ( 2 n + \varepsilon ^ { - 1 } ) )$ , the distribution $\mathcal { D } _ { x , \varepsilon } ^ { A }$ outputted by $A$ satisfies

$$
\| \mathcal { D } _ { x , \varepsilon } ^ { A } - \mathcal { D } _ { x , \varepsilon } ^ { M } \| \leq \sqrt { 2 \cdot \frac { \varepsilon ^ { 2 } } { 2 } } = \varepsilon ,
$$

and this completes the proof of Lemma 5.3.

# 5.4 $\mathsf { P H } ^ { \mathsf { T Q B F } , \mathcal { O } }$ is Infinite with Probability 1.

For the second part of Theorem 5.1, we resort to the well-known connection between PH and constant-depth circuit lower bounds.

# The Average Case Constant-depth Circuit Lower Bound.

For convenience, we will use the recent breakthrough result by Rossman, Servedio, and Tan [RST15], which shows that PH is infinite relative to a random oracle with probability 1. (Earlier constructions of oracles making PH infinite would also have worked for us, but a random oracle is a particularly nice choice.)

Theorem 5.4. Let $2 \leq d \leq { \frac { c { \sqrt { \log n } } } { \log \log n } }$ , where $c > 0$ is an absolute constant. Let $S i p s e r _ { d }$ be the explicit $n$ -variable read-once monotone depth- $d$ formula described in [RST15]. Then any circuit $C ^ { \prime }$ of depth at most d − 1 and size at most S = 2n 6(d−1) over $\{ 0 , 1 \} ^ { n }$ agrees with $S i p s e r _ { d }$ on at most $( \frac { 1 } { 2 } + n ^ { - \Omega ( 1 / d ) } ) \cdot 2 ^ { n }$ inputs.

Dn as a Distribution on {0, 1}22n .

In order to use the above result to prove the second part of Theorem 5.1, we need to interpret $\mathcal { D } _ { n }$ (originally a distribution over functions mapping $\{ 0 , 1 \} ^ { 2 n }$ to $\{ 0 , 1 \} )$ as a distribution on $\{ 0 , 1 \} ^ { 2 ^ { 2 n } }$ in the following way.

Let $\tau$ be the bijection between $[ 2 ^ { 2 n } ]$ and $\{ 0 , 1 \} ^ { 2 n }$ that maps an integer $i \in [ 2 ^ { 2 n } ]$ to the $i$ -th binary string in $\{ 0 , 1 \} ^ { 2 n }$ in lexicographic order. Then a function $f : \{ 0 , 1 \} ^ { 2 n }  \{ 0 , 1 \}$ is equivalent to a binary string $x ^ { f } \in \{ 0 , 1 \} ^ { 2 ^ { 2 n } }$ , where the $i$ -th bit of $x ^ { f }$ , denoted $x _ { i } ^ { f }$ , equals $f ( \tau ( i ) )$ . Clearly this is a bijection between functions from $\{ 0 , 1 \} ^ { 2 n }$ to $\{ 0 , 1 \}$ and binary strings in $\{ 0 , 1 \} ^ { 2 ^ { 2 n } }$ .

For notational simplicity, when we say a binary string $\bar { x } \in \{ 0 , 1 \} ^ { 2 ^ { 2 n } }$ is drawn from $\mathcal { D } _ { n }$ , it means $x$ generated by first drawing a sample function $f \sim \mathcal { D } _ { n }$ and then setting $x = x ^ { f }$ .

Note that for $p \in \{ 0 , 1 \} ^ { n }$ , if $p$ is the $i$ -th binary string in $\{ 0 , 1 \} ^ { n }$ , then the set $B _ { n , p }$ corresponds to the bits $x _ { ( i - 1 ) 2 ^ { n } + 1 } , . . . , x _ { i 2 ^ { n } }$ .

# Distributional Constant-Depth Circuit Lower Bound over $\mathcal { D } _ { n }$

Now we are ready to state our distributional circuit lower bound over $\mathcal { D } _ { n }$ formally.

Lemma 5.5. For an integer $n$ , let $N = 2 ^ { n }$ and $S i p s e r _ { d }$ be the $N$ -variable Sipser function as in Theorem 5.4. Consider the Boolean function $( S i p s e r _ { d } \circ 0 { \mathsf { R } } )$ on $\{ 0 , 1 \} ^ { N ^ { 2 } }$ defined as follows: Given inputs $x _ { 1 } , x _ { 2 } , \ldots , x _ { N ^ { 2 } }$ , for each $1 \leq i \leq N$ , set

$$
z _ { i } : = \vee _ { j = ( i - 1 ) N + 1 } ^ { i N } x _ { j } ,
$$

and

$$
( S i p s e r _ { d } \circ O R ) ( x ) : = S i p s e r _ { d } ( z ) .
$$

Then any circuit C0 of depth at most d − 1 and size at most S = 2N 6(d−1) over {0, 1}N2 agrees with $( S i p s e r _ { d } \circ 0 { \mathsf { R } } )$ ) with probability at most $\frac { 1 } { 2 } + N ^ { - \Omega ( 1 / d ) }$ when inputs are drawn from the distribution $\mathcal { D } _ { n }$ .

Before proving Lemma 5.5, we show that it implies the second part of Theorem 5.1 easily.

Proof of the second part of Theorem 5.1. Consider the function $( \mathsf { S i p s e r } _ { d } \circ \mathsf { O R } )$ defined as in Lemma 5.5. It is easy to see that it has a polynomial-size circuit (in fact, a formula) of depth $d + 1$ ; and by Lemma 5.5, every polynomial size circuit of depth $d - 1$ has at most ${ \frac { 1 } { 2 } } + o ( 1 )$ correlation with it when the inputs are drawn from the distribution $\mathcal { D } _ { n }$ . So it follows from the standard connection between PH and $\mathsf { A C } _ { \mathrm { 0 } }$ that $\mathsf { P H } ^ { \mathcal { O } }$ is infinite with probability 1 when $\mathcal { O } \sim \mathcal { D } _ { \mathcal { O } }$ . □

Finally, we prove Lemma 5.5.

Proof of Lemma 5.5. By Theorem 5.4, there is a universal constant $c$ , such that any circuit $C$ of depth at most $d - 1$ and size at most $S$ over $\{ 0 , 1 \} ^ { N }$ agrees with $\mathsf { S i p s e r } _ { d }$ on at most $\left( \frac { 1 } { 2 } + \dot { N } ^ { - c / d } \right) \cdot 2 ^ { N }$ inputs.

We are going to show this lemma holds for the same $c$ . Suppose not; then we have a circuit $C$ of depth at most d − 1 and size at most S = 2N 6(d−1) over $\{ 0 , 1 \} ^ { N ^ { 2 } }$ , such that

$$
\operatorname* { P r } _ { x \sim \mathcal { D } _ { n } } [ C ( x ) = ( \bar { \mathsf { S i p s e r } _ { d } \circ \mathsf { O R } } ) ( x ) ] > \frac { 1 } { 2 } + N ^ { - c / d } .
$$

Now, for each $y _ { 1 } , y _ { 2 } , \dotsc , y _ { N } \in [ N ] ^ { N }$ , we define a distribution $\mathcal { D } _ { n } ^ { y _ { 1 } , y _ { 2 } , . . . , y _ { N } }$ on $\{ 0 , 1 \} ^ { N ^ { 2 } }$ as follows. To generate a sample $x \sim \mathcal { D } _ { n } ^ { y _ { 1 } , y _ { 2 } , . . . , y _ { N } }$ , we first set $x = 0 ^ { N ^ { 2 } }$ . Then for each $i \in [ N ]$ , we set $x _ { ( i - 1 ) N + y _ { i } }$ to 1 with probability $1 / 2$ .

By construction, we can see for all $x$ in the support of $\mathcal { D } _ { n } ^ { y _ { 1 } , y _ { 2 } , . . . , y _ { N } }$ ,

$$
( { \mathrm { S i p s e r } _ { d } } \circ { \mathrm { O R } } ) ( x ) = { \mathrm { S i p s e r } _ { d } } ( x _ { y _ { 1 } } , x _ { N + y _ { 2 } } , x _ { 2 N + y _ { 3 } } , \dotsc , x _ { ( N - 1 ) N + y _ { N } } ) .
$$

Moreover, by definition, $\mathcal { D } _ { n }$ is just the average of these distributions:

$$
\mathcal { D } _ { n } = N ^ { - N } \cdot \sum _ { y _ { 1 } , y _ { 2 } , . . . , y _ { N } } \mathcal { D } _ { n } ^ { y _ { 1 } , y _ { 2 } , . . . , y _ { N } } .
$$

By an averaging argument, there exist $y _ { 1 } , y _ { 2 } , \dotsc , y _ { N } \in [ N ] ^ { N }$ such that

$$
\operatorname* { P r } _ { x \sim \mathcal { D } _ { n } ^ { y _ { 1 } , y _ { 2 } , \ldots , y _ { N } } } [ C ( x ) = ( \mathsf { S i p s e r } _ { d } \circ \mathsf { O R } ) ( x ) ] > \frac { 1 } { 2 } + N ^ { - c / d } .
$$

Setting $x _ { ( i - 1 ) N + y _ { i } } = z _ { i }$ for each $i$ , and all other inputs to 0 in the circuit $C$ , we then have a circuit $D$ of size at most $S$ and depth at most $d - 1$ over $\{ 0 , 1 \} ^ { N }$ . And by the construction of $\mathcal { D } _ { n } ^ { y _ { 1 } , y _ { 2 } , . . . , y _ { N } }$ and the definition of the function $( \mathsf { S i p s e r } _ { d } \circ \mathsf { O R } )$ , we see that $D$ agrees with $\mathsf { S i p s e r } _ { d }$ on at least a $\frac { 1 } { 2 } + N ^ { - c / d }$ fraction of inputs. But this is a contradiction.

# 6 Maximal Quantum Supremacy for Black-Box Sampling and Relation Problems

In this section we present our results about Fourier Fishing and Fourier Sampling.

We will establish an $\Omega ( N / \log N )$ lower bound on the classical query complexity of Fourier Fishing, as well as an optimal $\Omega ( N )$ lower bound on the classical query complexity of Fourier Sampling.

# 6.1 Preliminaries

We begin by introducing some useful notations. Throughout this section, given a function $f : \{ 0 , 1 \} ^ { n } $ $\{ - 1 , 1 \}$ , we define the Fourier coefficient

$$
\widehat { f } ( z ) = 2 ^ { - n / 2 } \sum _ { x \in \{ 0 , 1 \} ^ { n } } f ( x ) \cdot ( - 1 ) ^ { x \cdot z }
$$

for each $z \in \{ 0 , 1 \} ^ { n }$ .

We also define

$$
\mathsf { a d v } ( f ) : = 2 ^ { - n } \cdot \sum _ { z \in \{ 0 , 1 \} ^ { n } , | \widehat { f } ( z ) | \geq 1 } \widehat { f } ( z ) ^ { 2 } ,
$$

and set $N = 2 ^ { n }$ .

The following two constants will be used frequently in this section.

$$
\mathsf { S u c c } _ { Q } = \frac { 2 } { \sqrt { 2 \pi } } \int _ { 1 } ^ { + \infty } x ^ { 2 } e ^ { - x ^ { 2 } / 2 } d x \approx 0 . 8 0 1 \mathrm { a n d } \mathsf { S u c c } _ { R } = \frac { 2 } { \sqrt { 2 \pi } } \int _ { 1 } ^ { + \infty } e ^ { - x ^ { 2 } / 2 } d x \approx 0 . 3 1 7 .
$$

Finally, we use $\mathcal { U } _ { n }$ to denote the uniform distribution on functions $f : \{ 0 , 1 \} ^ { n }  \{ - 1 , 1 \}$ .

# An Approximate Formula for the Binomial Coefficients

We also need the following lemma to approximate the binomial coefficients to ease some calculations in our proofs.

Lemma 6.1. ((5.41) in [Spe14]) For value $n$ and $| k - n / 2 | = o ( n ^ { 2 / 3 } ) \quad$ , we have

$$
{ \binom { n } { k } } \approx { \binom { n } { n / 2 } } \cdot e ^ { - { \frac { ( k - n / 2 ) ^ { 2 } } { n / 2 } } }
$$

and

$$
\ln { \binom { n } { k } } = \ln { \binom { n } { n / 2 } } - { \frac { ( k - n / 2 ) ^ { 2 } } { n / 2 } } + o ( 1 ) .
$$

# 6.2 Fourier Fishing and Fourier Sampling

We now formally define the Fourier Fishing and the Fourier Sampling problems.

Definition 6.2. We are given oracle access to a function $f : \{ 0 , 1 \} ^ { n }  \{ - 1 , 1 \}$ . In Fourier Sampling (or Fsampling in short), our task is to sample from a distribution $\mathcal { D }$ over $\{ 0 , 1 \} ^ { n }$ such that $\| \mathcal { D } - \mathcal { D } _ { f } \| \leq \varepsilon$ , where $\mathcal { D } _ { f }$ is the distribution defined by

$$
\operatorname* { P r } _ { \mathcal { D } _ { f } } [ y ] = 2 ^ { - n } { \widehat { f } } ( y ) ^ { 2 } = \left( { \frac { 1 } { 2 ^ { n } } } \sum _ { x \in \{ 0 , 1 \} ^ { n } } f ( x ) ( - 1 ) ^ { x \cdot y } \right) ^ { 2 } .
$$

In Fourier Fishing (or Ffishing in short), we want to find a $z$ such that $| { \widehat { f } } ( z ) | \geq 1$ . We also define a promise version of Fourier Fishing (promise-Ffishing for short), where the function $f$ is promised to satisfy $\mathsf { a d v } ( f ) \geq \mathsf { S u c c } _ { Q } - \frac { 1 } { n } .$ .

# A Simple 1-Query Quantum Algorithm

Next we describe a simple 1-query quantum algorithm for both problems. It consists of a round of Hadamard gates, then a query to $f$ , then another round of Hadamard gates, then a measurement in the computational basis.

The following lemma follows directly from the definitions of Fsampling and Ffishing.

Lemma 6.3. Given oracle access to a function $f ~ : ~ \{ 0 , 1 \} ^ { n } ~  ~ \{ - 1 , 1 \}$ , the above algorithm solves Fsampling exactly (i.e. with $\varepsilon = 0$ ), and Ffishing with probability $\mathsf { a d v } ( f )$ .

We can now explain the meanings of the constants $\mathsf { S u c c } _ { Q }$ and $\mathsf { S u c c } _ { R }$ . When the function $f$ is drawn from $\mathcal { U } _ { n }$ , by a simple calculation, we can see that $\mathsf { S u c c } _ { Q }$ is the success probability for the above simple quantum algorithm on Fourier Fishing, and $\mathsf { S u c c } _ { R }$ is the success probability for an algorithm outputting a uniform random string in $\{ 0 , 1 \} ^ { n }$ .

# 6.3 The $\Omega ( N / \log N )$ Lower Bound for Fourier Fishing

We begin with the $\Omega ( N / \log N )$ randomized lower bound for Fourier Fishing. Formally:

Theorem 6.4. There is no $o ( N / \log N )$ -query randomized algorithm that solves promise-Ffishing with $\mathsf { S u c c } _ { R } + \Omega ( 1 )$ success probability.

To prove Theorem 6.4, we first show that when the function $f$ is drawn from $\mathcal { U } _ { n }$ , no classical algorithm with $o ( N / \log N )$ queries can solve Ffishing with probability $\mathsf { S u c c } _ { R } + \Omega ( 1 )$ ; we then show with high probability, a function $f  U _ { n }$ satisfies the promise of promise-Ffishing. Formally, we have the following two lemmas.

Lemma 6.5. For large enough $n$

$$
\operatorname* { P r } _ { f  \mathcal { U } _ { n } } [ \mathsf { a d v } ( f ) < \mathsf { S u c c } _ { Q } - \frac { 1 } { n } ] < \frac { 1 } { n } .
$$

Lemma 6.6. Over $f  \mathcal { U } _ { n }$ , no randomized algorithm with $o ( N / \log N )$ queries can solve Ffishing with probability

$$
\mathsf { S u c c } _ { R } + \Omega ( 1 ) .
$$

Before proving these two technical lemmas, we show that they together imply Theorem 6.4 easily.

Proof of Theorem 6.4. Suppose by contradiction that there is an $o ( N / \log N )$ query randomized algorithm $A$ which has a $\mathsf { S u c c } _ { R } { + } \Omega ( 1 )$ success probability for promise-Ffishing. From Lemma 6.5, a $1 { - o ( 1 ) }$ fraction of all functions from $\{ 0 , 1 \} ^ { n } \to \{ - 1 , 1 \}$ satisfy the promise of promise-Ffishing. Therefore, when the sample function $f$ is drawn from $\mathcal { U } _ { f }$ , with probability $1 - o ( 1 )$ it satisfies the promise of promise-Ffishing, and consequently $A$ has a $\mathsf { S u c c } _ { R } + \Omega ( 1 )$ success probability of solving Ffishing with that $f$ . This means that $A$ has a success probability of

$$
( 1 - o ( 1 ) ) \cdot ( \mathsf { S u c c } _ { R } + \Omega ( 1 ) ) = \mathsf { S u c c } _ { R } + \Omega ( 1 )
$$

when $f  U _ { n }$ , contradicting Lemma 6.6.

The proof of Lemma 6.5 is based on a tedious calculation so we defer it to Appendix C. Now we prove Lemma 6.6.

Proof of Lemma 6.6. By Yao’s principle, it suffices to consider only deterministic algorithms, and we can assume the algorithm $A$ makes exactly $t = o ( N / \log N )$ queries without loss of generality.

Notations. Suppose that at the end of the algorithm, $A$ has queried the entries in a subset $S \subseteq \{ 0 , 1 \} ^ { n }$ such that $| S | = t$ .

For each $z \in \{ 0 , 1 \} ^ { n }$ , we define

$$
\widehat { f } _ { \mathsf { s e e n } } ( z ) = \frac { 1 } { \sqrt { t } } \sum _ { x \in S } f ( x ) \cdot ( - 1 ) ^ { x \cdot z }
$$

and similarly

$$
{ \widehat { f } } _ { \mathsf { u n s e e n } } f ( z ) = { \frac { 1 } { \sqrt { N - t } } } \sum _ { x \in \{ 0 , 1 \} ^ { n } \setminus S } f ( x ) \cdot ( - 1 ) ^ { x \cdot z } .
$$

From the definitions of ${ \widehat { f } } ( z ) , { \widehat { f } } _ { \mathsf { s e e n } } ( z )$ and $\widehat { f } _ { \mathsf { u n s e e n } } ( z )$ , and note that $N / t = \omega ( \log N ) = \omega ( \ln N )$ , we have

$$
\begin{array} { r l r } & { } & { \widehat { f } ( z ) = \left( \sqrt { t } \cdot \widehat { f } _ { \mathsf { s e e n } } ( z ) + \sqrt { N - t } \cdot \widehat { f } _ { \mathsf { u n s e e n } } ( z ) \right) \Big / \sqrt { N } } \\ & { } & { = \widehat { f } _ { \mathsf { s e e n } } ( z ) / \omega ( \sqrt { \ln N } ) + \widehat { f } _ { \mathsf { u n s e e n } } ( z ) \cdot ( 1 - o ( 1 ) ) . } \end{array}
$$

W.h.p. $\widehat { f } _ { \mathsf { s e e n } } ( z )$ is small for all √ $z \in \{ 0 , 1 \} ^ { n }$ . We first show that, with probability at least $1 - o ( 1 )$ over $f  U _ { n }$ , we have $| \widehat { f } _ { \mathsf { s e e n } } ( z ) | \leq 2 \sqrt { \ln N }$ for all $z \in \{ 0 , 1 \} ^ { n }$ .

Fix a $z \in \{ 0 , 1 \} ^ { n }$ , and note that for the algorithm $A$ , even though which position to query next might depend on the history, the value in that position is a uniform random bit in $\{ - 1 , 1 \}$ . So $\widehat { f } _ { \mathsf { s e e n } } ( z )$ is a sum of $t$ uniform i.i.d. random variables in $\{ - 1 , 1 \}$ .

Therefore, the probability that $| \widehat { f } _ { \mathsf { s e e n } } ( z ) | > 2 \sqrt { \ln N }$ for this fixed $z$ is

$$
\frac { 2 } { \sqrt { 2 \pi } } \int _ { 2 \sqrt { \ln N } } ^ { + \infty } e ^ { - x ^ { 2 } / 2 } d x = o \left( \frac { 1 } { N } \right) .
$$

Then by a simple union bound, with probability $1 - o ( 1 )$ , there is no $z \in \{ 0 , 1 \} ^ { n }$ such that $| \widehat { f } _ { \mathsf { s e e n } } ( z ) | >$ $2 \sqrt { \ln { N } }$ at the end of $t$ queries. We denote the nonexistence of such a $z$ as the event $\mathcal { E } _ { \mathrm { b a d } }$ .

The lower bound. In the following we condition on $\mathcal { E } _ { \mathrm { b a d } }$ . We show in this case, $A$ cannot solve Ffishing with a success probability better than $\mathsf { S u c c } _ { R }$ , thereby proving the lower bound.

From (12), for each $z \in \{ 0 , 1 \} ^ { n }$ , we have

$$
\widehat { f } ( z ) = o ( 1 ) + \widehat { f } _ { \mathsf { u n s e e n } } ( z ) \cdot ( 1 - o ( 1 ) ) .
$$

Therefore, the probability of $| { \widehat { f } } ( z ) | \geq 1$ is bounded by the probability that $| \widehat { f } _ { \mathsf { u n s e e n } } ( z ) | \geq 1 - o ( 1 )$ Since $\widehat { f } _ { \mathsf { u n s e e n } } ( z )$ is independent of all the seen values in $S$ , we have

$$
\begin{array} { l l r } { \operatorname* { P r } \left[ \widehat { f } _ { \mathsf { u n s e e n } } ( z ) \geq 1 - o ( 1 ) \right] = \displaystyle \frac { 2 } { \sqrt { 2 \pi } } \int _ { 1 - o ( 1 ) } ^ { + \infty } e ^ { - x ^ { 2 } / 2 } d x } \\ { \displaystyle = \frac { 2 } { \sqrt { 2 \pi } } \int _ { 1 } ^ { + \infty } e ^ { - x ^ { 2 } / 2 } d x + o ( 1 ) } \\ { \displaystyle = \mathsf { S u c c } _ { R } + o ( 1 ) . } \end{array}
$$

Hence, no matter which $z$ is outputted by $A$ , we have $| { \widehat { f } } ( z ) | \geq 1$ with probability at most $\mathsf { S u c c } _ { R } + o ( 1 )$ . That means that if we condition on $\mathcal { E } _ { \mathrm { b a d } }$ , then $A$ cannot solve Ffishing with probability $\mathsf { S u c c } _ { R } + \Omega ( 1 )$ . As $\mathcal { E } _ { \mathrm { b a d } }$ happens with probability $1 - o ( 1 )$ , this finishes the proof.

# 6.4 The Optimal $\Omega ( N )$ Lower Bound for Fourier Sampling

We first show that in fact, Lemma 6.6 already implies an $\Omega ( N / \log N )$ lower bound for Fourier Sampling, which holds for a quite large $\varepsilon$ .

Theorem 6.7. For any $\varepsilon < \mathsf { S u c c } _ { Q } - \mathsf { S u c c } _ { R } \approx 0 . 4 8 3 ,$ , the randomized query complexity for Fsampling is $\Omega ( N / \log N )$ .

Proof. Note when $f  \mathcal { U } _ { n }$ , an exact algorithm for Fsampling can be used to solve Ffishing with probability $\mathsf { S u c c } _ { Q }$ . Hence, a sampling algorithm for Fsampling with total variance $\leq \varepsilon$ can solve Ffishing with probability at least $\mathsf { S u c c } _ { Q } - \varepsilon$ , when $f  U _ { n }$ .

Then the lower bound follows directly from Lemma 6.6.

Next we prove the optimal $\Omega ( N )$ lower bound for Fourier Sampling.

Theorem 6.8. There is a constant $\varepsilon > 0$ , such that any randomized algorithm solving Fsampling with error at most $\varepsilon$ needs $\Omega ( N )$ queries.

Proof. Reduction to a simpler problem. Sampling problems are hard to approach, so we first reduce to a much simpler problem with Boolean output (“accept” or “reject”).

Let $A$ be a randomized algorithm for Fsampling with total variance $\leq \varepsilon$ . For a function $f : \{ 0 , 1 \} ^ { n } $ $\{ - 1 , 1 \}$ and $y \in \{ 0 , 1 \} ^ { n }$ , we set $p _ { f , y }$ to be the probability that $A$ outputs $y$ with oracle access to $f$ .

By the definition of Fsampling, for all $f$ , we have

$$
{ \frac { 1 } { 2 } } \sum _ { y \in \{ 0 , 1 \} ^ { n } } \left. p _ { f , y } - 2 ^ { - n } { \widehat { f } } ( y ) ^ { 2 } \right. \leq \varepsilon .
$$

By an averaging argument, this implies that there exists a $y ^ { * } \in \{ 0 , 1 \} ^ { n }$ such that

$$
\underset { f  U _ { n } } { \mathbb { E } } [ | p _ { f , y ^ { * } } - 2 ^ { - n } \widehat { f } ( y ^ { * } ) ^ { 2 } | ] \leq \frac { 2 \varepsilon } { N } .
$$

Then by Markov’s inequality, we have

$$
\left| p _ { f , y } - 2 ^ { - n } { \widehat { f } } ( y ^ { * } ) ^ { 2 } \right| \leq { \frac { 4 0 0 \varepsilon } { N } } ,
$$

for at least a $1 9 9 / 2 0 0$ fraction of $f$ ’s. Now we set $\varepsilon = { \frac { 1 } { 4 0 0 } } \cdot { \frac { 1 } { 1 0 0 } } .$

Without loss of generality, we can assume that $y ^ { * } = 0 ^ { n }$ . Let $z _ { i } : = { \frac { 1 + f ( x _ { i } ) } { 2 } }$ (where $x _ { 1 } , x _ { 2 } , \ldots , x _ { N }$ is a lexicographic ordering of inputs), $Z : = ( z _ { 1 } , \dotsc , z _ { N } )$ and $| Z | : = \sum _ { i = 1 } ^ { N } z _ { i }$ . Then we have

$$
2 ^ { - n } { \widehat { f } } ( 0 ^ { n } ) ^ { 2 } = \left( { \frac { 2 | Z | } { N } } - 1 \right) ^ { 2 } .
$$

Now we can simplify the question to one of how many $z _ { i }$ ’s the algorithm $A$ needs to query, in order to output $0 ^ { n }$ (we call it “accept” for convenience) with a probability $p z = p _ { f , 0 ^ { n } }$ that satisfies

$$
\left| p _ { Z } - \left( \frac { 2 | Z | } { N } - 1 \right) ^ { 2 } \right| \le \frac { 4 0 0 \varepsilon } { N } \le \frac { 0 . 0 1 } { N }
$$

with probability at least $1 9 9 / 2 0 0$ over $Z \in \{ 0 , 1 \} ^ { N }$

Analysis of the acceptance probability of $A$ . Without loss of generality, we can assume that $A$ nonadaptively queries $t$ randomly-chosen inputs $z _ { i _ { 1 } } , z _ { i _ { 2 } } , \ldots , z _ { i _ { t } }$ , and then accepts with a probability $q _ { k }$ that depends solely on $k : = z _ { i _ { 1 } } + \cdot \cdot \cdot + z _ { i _ { t } }$ . The reason is that we can change any other algorithm into this restricted form by averaging over all $N$ ! permutations of $Z$ without affecting its correctness.

Let $p _ { w }$ be the probability that $A$ accepts when $| Z | = w$ . Then

$$
p _ { w } = \sum _ { k = 0 } ^ { t } q _ { k } \cdot r _ { k , w } ,
$$

where rk,w := $r _ { k , w } : = \binom { t } { k } \binom { N - t } { w - k } / \binom { N } { w }$ , is the probability that $z _ { i _ { 1 } } + \cdot \cdot \cdot + z _ { i _ { t } } = k$ conditioned on $| Z | = w$ . Construction and Analysis of the sets $U , V , W$ . Now, consider the following three sets:

$$
U : = \left\{ Z : \left| | Z | - { \frac { N } { 2 } } \right| \leq { \frac { \sqrt { N } } { 2 0 } } \right\} ,
$$

$$
\begin{array} { r l } & { V : = \left\{ Z : \left( 1 - \frac { 1 } { 2 0 } \right) \frac { \sqrt { N } } { 2 } \le | Z | - \frac { N } { 2 } \le \frac { \sqrt { N } } { 2 } \right\} , } \\ & { W : = \left\{ Z : \left( 1 - \frac { 1 } { 2 0 } \right) \sqrt { N } \le | Z | - \frac { N } { 2 } \le \sqrt { N } \right\} . } \end{array}
$$

We calculate the probability that a uniform random $Z$ belongs to these three sets. For a sufficiently large $N$ , we have

$$
\operatorname* { P r } _ { Z } [ Z \in U ] \geq \mathrm { e r f } \left( { \frac { \sqrt { 2 } } { 2 0 } } \right) - o ( 1 ) > 0 . 0 7 5 ,
$$

$$
\operatorname* { P r } _ { Z } [ Z \in V ] \geq { \frac { 1 } { 2 } } \cdot \left( \operatorname { e r f } \left( { \frac { \sqrt { 2 } } { 2 } } \right) - \operatorname { e r f } \left( { \frac { \sqrt { 2 } } { 2 } } \cdot { \frac { 1 9 } { 2 0 } } \right) \right) - o ( 1 ) > 0 . 0 1 ,
$$

$$
\operatorname* { P r } _ { Z } [ Z \in W ] \geq { \frac { 1 } { 2 } } \cdot \left( \operatorname { e r f } ( { \sqrt { 2 } } ) - \operatorname { e r f } \left( { \sqrt { 2 } } \cdot { \frac { 1 9 } { 2 0 } } \right) \right) - o ( 1 ) > 0 . 0 0 5 .
$$

Construction and Analysis of $w _ { 0 } , w _ { 1 } , w _ { 2 }$ . Since all $\operatorname* { P r } _ { Z } [ Z \in U ] , \operatorname* { P r } _ { Z } [ Z \in V ] , \operatorname* { P r } _ { Z } [ Z \in W ] > 0 . 0 0 5$ , and recall that for at least a $1 - 0 . 0 0 5$ fraction of $Z$ , we have

$$
\left| p _ { Z } - \left( \frac { 2 | Z | } { N } - 1 \right) ^ { 2 } \right| \le \frac { 4 0 0 \varepsilon } { N } \le \frac { 0 . 0 1 } { N } .
$$

So there must exist $w _ { 0 } \in U , w _ { 1 } \in V , w _ { 2 } \in W$ such that

$$
\left| p _ { w _ { i } } - 4 \cdot \left( \frac { w _ { i } - N / 2 } { N } \right) ^ { 2 } \right| \leq \frac { 0 . 0 1 } { N }
$$

for each $i \in \{ 0 , 1 , 2 \}$ .

To ease our calculation, let $u _ { i } = { \frac { w _ { i } - N / 2 } { \sqrt { N } } }$ , then we have $w _ { i } = N / 2 + u _ { i } \sqrt { N }$ . By the definition of the $u _ { i }$ ’s, we also have $| u _ { 0 } | \leq \frac { 1 } { 2 0 } , u _ { 1 } \in [ 0 . 4 7 5 , 0 . 5 ] , u _ { 2 } \in [ 0 . 9 5 , 1 ] .$

Plugging in $u _ { i }$ ’s, for each $i \in \{ 0 , 1 , 2 \}$ , equation (14) simplifies to

$$
\left| p _ { w _ { i } } - \frac { 4 u _ { i } ^ { 2 } } { N } \right| \leq \frac { 0 . 0 1 } { N } .
$$

We can calculate the ranges of the $p _ { w _ { i } }$ ’s by plugging the ranges of the $u _ { i }$ ’s,

$$
\begin{array} { c } { { p _ { w _ { 0 } } \leq \frac { 0 . 0 2 } { N } , } } \\ { { \ } } \\ { { p _ { w _ { 1 } } \in \left[ \frac { 0 . 9 5 ^ { 2 } - 0 . 0 1 } { N } , \frac { 1 + 0 . 0 1 } { N } \right] \subseteq \left[ \frac { 0 . 8 9 } { N } , \frac { 1 . 0 1 } { N } \right] , } } \\ { { \ } } \\ { { p _ { w _ { 2 } } \in \left[ \frac { 4 \cdot 0 . 9 5 ^ { 2 } - 0 . 0 1 } { N } , \frac { 4 + 0 . 0 1 } { N } \right] \subseteq \left[ \frac { 3 . 6 } { N } , \frac { 4 . 0 1 } { N } \right] . } } \end{array}
$$

We are going to show that the above is impossible when $t = o ( N )$ . That is, one cannot set the $q _ { k }$ ’s in such a way that all $p _ { w _ { i } }$ ’s satisfy the above constraints when $t = o ( N )$ .

It is safe to set $q _ { k }$ to zero when $| k - t / 2 |$ is large. To simplify the matters, we first show that we can set nearly all the $q _ { k }$ ’s to zero. By the Chernoff bound without replacement, for each $w _ { i }$ and large enough $c$ we have

$$
\begin{array} { r l } & { \underset { k ^ { \prime } \mid k ^ { \prime } = \ell ^ { \prime } \mid 2 \mid k ^ { \prime } = \ell ^ { \prime } } { \sum } r _ { k , \ell , \ell } } \\ & { = \operatorname* { P r } \bigg \{ \bigg | z _ { 1 } + \dots + z _ { i } - \frac { t } { 2 } \bigg | \geq c \sqrt { t } : | Z | = w _ { i } = \frac { N } { 2 } + u _ { i } \sqrt { N } \bigg \} } \\ & { \leq \operatorname* { P r } \bigg [ \bigg | z _ { 1 } + \dots + z _ { i } - \bigg ( \frac { t } { 2 } + \frac { u _ { k } t } { \sqrt { N } } \bigg ) \bigg | \geq c \sqrt { t } - \bigg | \bigg ( \frac { t } { 2 } + \frac { u _ { i } t } { \sqrt { N } } \bigg ) - \frac { t } { 2 } \bigg | \cdot | Z | = w _ { i } = \frac { N } { 2 } + } \\ & { \leq \operatorname* { P r } \bigg [ \bigg | z _ { 1 } + \dots + z _ { i } - \bigg ( \frac { t } { 2 } + \frac { u _ { i } t } { \sqrt { N } } \bigg ) \bigg | \geq c \sqrt { t } - | \mathrm { a k } | \sqrt { t } : | Z | = \frac { N } { 2 } + u _ { i } \sqrt { N } \bigg ] } \\ & { \leq \exp \bigg \{ - 2 \frac { ( c \sqrt { t } - | u _ { i } | \sqrt { t } ) ^ { 2 } } { t } \bigg \} } \\ & { = \exp \Big \{ - 2 \frac { ( c \sqrt { t } - | u _ { i } | \sqrt { t } ) ^ { 2 } } { t } \Big \} } \\ & { = \exp \big \{ - 2 ( c - | u _ { i } | ) ^ { 2 } \big \} } \\ & { \leq \exp \big \{ \Omega ( c ^ { 2 } ) \big \} . } \end{array}
$$

Then we can set $c = c _ { 1 } \sqrt { \ln { N } }$ for a sufficiently large constant $c _ { 1 }$ , so that for all $w _ { i }$ ’s,

$$
\sum _ { k : | k - t / 2 | > c \sqrt { t } } r _ { k , w _ { i } } \leq \frac { 1 } { N ^ { 2 } } .
$$

This means that we can simply set all $q _ { k }$ ’s with $| k - t / 2 | > c \sqrt { t } = c _ { 1 } \sqrt { t \ln N }$ to zero, and only consider $k$ such that $| k - t / 2 | \leq c _ { 1 } \sqrt { t \ln N }$ , as this only changes each √ $p _ { w _ { i } }$ by a negligible value. From now on, we call an integer $k$ valid, if $| k - t / 2 | \leq c _ { 1 } \sqrt { t \ln N }$ .

Either $\frac { r _ { k , w _ { 0 } } } { r _ { k , w _ { 1 } } } \geq 0 . 0 5 \mathrm { ~ o r ~ } \frac { r _ { k , w _ { 2 } } } { r _ { k , w _ { 1 } } } \geq 1 0 .$ . Now, we are going to show the most technical part of this proof: for all valid $k$ , we have either

$$
\begin{array} { r } { \frac { r _ { k , w _ { 0 } } } { r _ { k , w _ { 1 } } } \geq 0 . 0 5 \mathrm { o r } \frac { r _ { k , w _ { 2 } } } { r _ { k , w _ { 1 } } } \geq 1 0 . } \end{array}
$$

Suppose for contradiction that there is a valid $k$ that satisfies

$$
\frac { r _ { k , w _ { 0 } } } { r _ { k , w _ { 1 } } } < 0 . 0 5 \mathrm { a n d } \frac { r _ { k , w _ { 2 } } } { r _ { k , w _ { 1 } } } < 1 0 .
$$

Estimation of $r _ { k , w _ { i } }$ ’s. We first use Lemma 6.1 to derive an accurate estimate of $\ln r _ { k , w _ { i } }$ for each $w _ { i }$ . We set $N _ { t } = N - t$ for simplicity. Recall that

$$
r _ { k , w } = { \binom { t } { k } } { \binom { N _ { t } } { w - k } } / { \binom { N } { w } } .
$$

For each $w _ { i }$ , since $| k - t / 2 | \leq c _ { 1 } \sqrt { t \ln N }$ and $t = o ( N )$ , we have

$$
\left| w _ { i } - k - \frac { N _ { t } } { 2 } \right| \leq \left| w _ { i } - \frac { N } { 2 } \right| + \left| k - \frac { t } { 2 } \right| \leq u _ { i } \sqrt { N } + c _ { 1 } \sqrt { t \ln N } = o ( N _ { t } ^ { 2 / 3 } ) ,
$$

and note that $| w _ { i } - N / 2 | = | u _ { i } \sqrt { N } | = o ( N ^ { 2 / 3 } )$ . So we can apply Lemma 6.1 to derive

$$
\begin{array} { l } { \ln r _ { k , w _ { i } } = \ln { \binom { t } { k } } + \ln { \binom { N _ { t } } { w _ { i } - k } } - \ln { \binom { N } { w _ { i } } } } \\ { \qquad = - \displaystyle \frac { ( w _ { i } - k - N _ { t } / 2 ) ^ { 2 } } { N _ { t } / 2 } + \displaystyle \frac { ( w _ { i } - N / 2 ) ^ { 2 } } { N / 2 } + C + \ln { \binom { t } { k } } + o ( 1 ) , } \end{array}
$$

in which $C$ is a constant that does not depend on √ √ $k$ or $w _ { i }$

Let $d = ( k - t / 2 ) / \sqrt { t }$ (so $k = t / 2 + d \sqrt { t } )$ , and recall that $w _ { i } = N / 2 + u _ { i } \sqrt { N }$ for each $w _ { i }$ . We can further simplify the expression as

$$
\begin{array} { l } { { = - { \displaystyle \frac { ( N / 2 + u _ { i } \sqrt { N } - t / 2 - d \sqrt { t } - N _ { t } / 2 ) ^ { 2 } } { N _ { t } / 2 } } + { \displaystyle \frac { ( N / 2 + u _ { i } \sqrt { N } - N / 2 ) ^ { 2 } } { N / 2 } } + C + \ln \binom { t } { k } + \log \sqrt { t } - N _ { t } } } \\ { { = - { \displaystyle \frac { ( u _ { i } \sqrt { N } - d \sqrt { t } ) ^ { 2 } } { N _ { t } / 2 } } + 2 u _ { i } ^ { 2 } + C + \ln \binom { t } { k } + o ( 1 ) . } } \end{array}
$$

Estimation o f rk,wjr . Note that Nt = N − t = (1 − o(1))N . So we can approximate the ratio between two $r _ { k , w _ { i } }$ and $r _ { k , w _ { j } }$ by

$$
\begin{array} { l } { \ln \frac { T _ { k , w _ { j } } } { T _ { k , w _ { i } } } = \ln { r _ { k , w _ { j } } } - \ln { r _ { k , w _ { i } } } } \\ { \displaystyle = - \frac { \left( u _ { j } \sqrt { N } - d \sqrt { i } \right) ^ { 2 } } { N _ { t } / 2 } + 2 u _ { j } ^ { 2 } + \frac { \left( u _ { i } \sqrt { N } - d \sqrt { i } \right) ^ { 2 } } { N _ { t } / 2 } - 2 u _ { i } ^ { 2 } + o ( 1 ) } \\ { \displaystyle = 2 u _ { j } ^ { 2 } - 2 u _ { i } ^ { 2 } + \frac { \left( \left( u _ { i } + u _ { j } \right) \sqrt { N } - 2 d \sqrt { i } \right) \left( u _ { i } - u _ { j } \right) \sqrt { N } } { N _ { t } / 2 } + o ( 1 ) } \\ { \displaystyle = 2 u _ { j } ^ { 2 } - 2 u _ { i } ^ { 2 } + 2 ( u _ { i } ^ { 2 } - u _ { j } ^ { 2 } ) - 4 d \frac { \sqrt { t N } } { N _ { t } } ( u _ { i } - u _ { j } ) + o ( 1 ) } \\ { \displaystyle = - 4 d \frac { \sqrt { t N } } { N _ { t } } ( u _ { i } - u _ { j } ) + o ( 1 ) . } \end{array}
$$

Verifying (16). Finally, to simplify matters further, we set x = −4d tNNt , a nd substitute it in (17) for We have

$k$

$$
\ln \frac { r _ { k , w _ { 0 } } } { r _ { k , w _ { 1 } } } = x ( u _ { 1 } - u _ { 0 } ) + o ( 1 ) < - \ln 2 0 ,
$$

which simplifies to

$$
x < \frac { - \ln { 2 0 } } { u _ { 1 } - u _ { 0 } } + o ( 1 ) \leq \frac { - \ln { 2 0 } } { 0 . 5 0 5 } + o ( 1 ) \leq - 5 . 9 3 + o ( 1 ) .
$$

Similarly, we have

$$
\ln \frac { r _ { k , w _ { 2 } } } { r _ { k , w _ { 1 } } } = x ( u _ { 1 } - u _ { 2 } ) + o ( 1 ) < \ln 1 0
$$

and

$$
x > - \frac { \ln 1 0 } { u _ { 2 } - u _ { 1 } } - o ( 1 ) \geq - \frac { \ln 1 0 } { 0 . 4 5 } - o ( 1 ) \geq - 5 . 1 2 - o ( 1 ) .
$$

contradiction.

The lower bound. So (16) holds for all valid $k$ , which means for all $k$ such that $| k - t / 2 | \leq c _ { 1 } \sqrt { t \ln N }$ , either $\frac { r _ { k , w _ { 0 } } } { \ldots } \geq 0 . 0 5$ or $\frac { r _ { k , w _ { 2 } } } { r _ { k , w _ { 1 } } } \geq 1 0 $ . ${ r _ { k , w _ { 1 } } } ^ { - } \qquad { r _ { k , w _ { 1 } } } ^ { - }$

Let $H$ be the set of all valid integers $k$ . We set

$$
S = \left\{ k \in H : \frac { r _ { k , w _ { 0 } } } { r _ { k , w _ { 1 } } } \geq 0 . 0 5 \right\} \mathrm { ~ a n d ~ } T = H \setminus S .
$$

By (16), for any $k \in T$ , we have $\frac { r _ { k , w _ { 2 } } } { r _ { k , w _ { 1 } } } \geq 1 0$

Since $p _ { w _ { 1 } } = \sum _ { k \in S } q _ { k } \cdot r _ { k , w _ { 1 } } + \sum _ { k \in T } q _ { k } \cdot r _ { k , w _ { 1 } } \geq { \frac { 0 . 8 9 } { N } }$ (recall we have set all $q _ { k }$ ’s to zero for $k \notin H$ ), we 0.445 0.445   
must have either X qk · rk,w1 ≥ N or X qk · rk,w1 ≥ N k∈S k∈T

$\sum _ { k \in S } q _ { k } \cdot r _ { k , w _ { 1 } } \geq \frac { 0 . 4 4 5 } { N }$ N , we have

$$
p _ { w _ { 0 } } \geq \sum _ { k \in S } q _ { k } \cdot r _ { k , w _ { 1 } } \cdot \frac { r _ { k , w _ { 0 } } } { r _ { k , w _ { 1 } } } \geq \frac { 0 . 4 4 5 } { N } \cdot 0 . 0 5 \geq \frac { 0 . 0 2 2 } { N } ,
$$

which contradicts the constraint that $p _ { w _ { 0 } } \leq \frac { 0 . 0 2 } { N }$ . Otherwise, $\sum _ { k \in T } q _ { k } \cdot r _ { k , w _ { 1 } } \geq \frac { 0 . 4 4 5 } { N } .$ ; then

$$
p _ { w _ { 2 } } \geq \sum _ { k \in T } q _ { k } \cdot r _ { k , w _ { 1 } } \cdot \frac { r _ { k , w _ { 2 } } } { r _ { k , w _ { 1 } } } \geq \frac { 0 . 4 4 5 } { N } \cdot 1 0 \geq \frac { 4 . 4 5 } { N } ,
$$

which violates the requirement that $p _ { w _ { 2 } } \leq \frac { 4 . 0 1 } { N }$ .

Since both cases lead to a contradiction, $A$ needs to make $\Omega ( N )$ queries and this completes the proof.

# 7 Quantum Supremacy Relative to Efficiently-Computable Oracles

We now discuss our results about quantum supremacy relative to oracles in P/poly.

Building on work by Zhandry [Zha12] and Servedio and Gortler [SG04], we first show that, if (classical) one-way functions exist, then there exists an oracle $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ such that $\mathsf { B P P } ^ { \mathcal { O } } \neq \mathsf { B Q P } ^ { \mathcal { O } }$ . Then we make a connection to the previous section by showing that, assuming the existence of (classical) subexponentially strong one-way functions, Fourier Fishing and Fourier Sampling are hard even when it is promised that the oracle is in P/poly.

We also study several other complexity questions relative to P/poly oracles: for example, P vs NP, P vs BPP, and BQP vs SZK. Since these questions are not connected directly with quantum supremacy, we will discuss them in Appendix A.

# 7.1 Preliminaries

Recall that an oracle $\mathcal { O } : \{ 0 , 1 \} ^ { * } \to \{ 0 , 1 \}$ is itself a language, so we say that an oracle $\mathcal { O }$ is in P/poly when the corresponding language belongs to $\mathsf { P } / \mathsf { p o o l y }$ , and we use ${ \mathcal { O } } _ { n }$ to denote its restriction to $\{ 0 , 1 \} ^ { n }$ .

Given two sets $\mathcal { X }$ and $\mathcal { V }$ , we define $y ^ { \chi }$ as the set of functions $f : \mathcal { X }  \mathcal { Y }$ . For a set $\mathcal { X }$ , we will sometimes abuse notation and write $\mathcal { X }$ to denote the uniform distribution on $\mathcal { X }$ .

# (Quantum) Pseudorandom Functions and Permutations

We are going to use pseudorandom functions and permutations throughout this section, so we first review their definitions.

Definition 7.1 (PRF and PRP). A pesudorandom function is a function PRF : ${ \mathcal { K } } \times { \mathcal { X } } \to { \mathcal { Y } }$ , where $\kappa$ is the key-space, and $\mathcal { X }$ and $\mathcal { V }$ are the domain and the range. $\kappa , \chi , \upsilon$ are implicitly functions of the security parameter $n$ .12 We write $y = \mathsf { P R F } _ { k } ( x )$ .

Similarly, a pesudorandom permutation is a function $\mathsf { P R P : } \mathcal { K } \times \mathcal { X } \to \mathcal { X }$ , where $\kappa$ is the key-space, and $\mathcal { X }$ is the domain of the permutation. $\kappa$ and $\mathcal { X }$ are implicitly functions of the security parameter $n$ . We write $y = \mathsf { P R P } _ { k } ( x )$ . It is guaranteed that ${ \mathsf { P R P } } _ { k }$ is a permutation on $\mathcal { X }$ for each $k \in \mathcal { K }$ .

For simplicity, we use $\mathsf { P R F } _ { \kappa }$ to denote the distribution on functions $f : \mathcal { X }  \mathcal { V }$ by drawing $k  \kappa$ and set $f : = \mathsf { P R F } _ { k }$ .

We now introduce the definitions of classical and quantum security.

Definition 7.2 (Classical-Security). A pseudorandom function PRF : ${ \mathcal { K } } \times { \mathcal { X } } \to { \mathcal { Y } }$ is (classically) secure if no classical adversary $A$ can distinguish between a truly random function and the function $\mathsf { P R F } _ { k }$ for $a$ random $k$ in polynomial time. That is, for every such $A$ , there exists a negligible function $\varepsilon = \varepsilon ( n )$ such that

$$
\biggl | \operatorname* { P r } _ { k \gets K } [ A ^ { \mathsf { P R F } _ { k } } ( ) = 1 ] - \operatorname* { P r } _ { f \gets y ^ { \chi } } [ A ^ { f } ( ) = 1 ] \biggr | < \varepsilon .
$$

Also, we say that a pseudorandom function PRF is exponentially-secure, if the above holds even for classical adversaries that take $2 ^ { O ( n ) }$ time.

Similarly, a pseudorandom permutation PRP is (classically) secure if no classical adversary $A$ can distinguish between a truly random permutation and the function ${ \mathsf { P R P } } _ { k }$ for a random $k$ in polynomial time.

Sometimes, especially in the context of one-way functions, we will talk about subexponential security. By this we simply mean that there is no adversary running in 2no(1) t ime.

Definition 7.3 (Quantum-Security). A pseudorandom function PRF is quantum-secure if no quantum adversary $A$ making quantum queries can distinguish between a truly random function and the function $\mathsf { P R F } _ { k }$ for a random k in polynomial time.

Also, a pseudorandom permutation PRP is quantum-secure if no quantum adversary $A$ making quantum queries can distinguish between a truly random permutation and the function ${ \mathsf { P R P } } _ { k }$ for a random $k$ in polynomial time.

# On the Existence of PRFs

It is well-known that the existence of one-way functions implies the existence of PRFs and PRPs.

Lemma 7.4 ([HILL99, GGM86, GL89, LR88]). If one-way functions exist, then there exist secure PRFs and PRPs. Similarly, if subexponentially-secure one-way functions exist, then there exist exponentially-secure PRFs.

We remark here that these are all purely classical assumptions, which make no reference to quantum algorithms. Also, the latter assumption is the same one as in the famous natural proofs barrier [RR97].

# 7.2 A Construction from Zhandry [Zha12]

To prove our separations, we will use a construction from Zhandry [Zha12] with some modifications. We first construct a PRP and a PRF, and summarize some of their useful properties.

# Definitions of PRPraw and PRFmod

Assuming one-way functions exist, by Lemma 7.4, let ${ \mathsf { P R P } } ^ { \mathsf { r a w } }$ be a secure pesudorandom permutation with key-space $K ^ { \mathsf { r a w } }$ and domain $\mathcal { X } ^ { \mathsf { r a w } }$ . We interpret $\mathcal { X } ^ { \mathsf { r a w } }$ as $[ N ]$ , where $N = N ( n ) = | \chi ^ { \mathsf { r a w } } |$ .

Then we define another pseudorandom function $\mathsf { P R F } _ { ( k , a ) } ^ { \mathsf { m o d } } ( x ) = \mathsf { P R P } _ { k } ^ { \mathsf { r a w } } ( ( x - 1 )$ mod $a + 1$ ) where:

• The key space of PRFmod is $\mathcal { K } ^ { \sf m o d } = \mathcal { K } ^ { \sf r a w } \times \mathcal { A }$ where $\mathcal { A }$ is the set of primes in $[ \sqrt { N } / 4 , \sqrt { N } / 2 ]$ .

• The domain and image are both $\mathcal { X } ^ { \mathsf { r a w } }$ , that is, $\chi ^ { \mathrm { m o d } } = \chi ^ { \mathrm { r a w } }$ and $\mathcal { y } ^ { \mathrm { m o d } } = \mathcal { X } ^ { \mathrm { r a w } }$ .

Note that we denote the latter one by PRFmod (not PRPmod) because it is no longer a PRP.

Properties of PRPraw and PRFmod

We now summarize several properties of PRPraw and PRFmod, which can be proved along the same lines as [Zha12].

Lemma 7.5 (Implicit in Claim 1 and Claim 2 of [Zha12]). The following statements hold when PRPraw is classical secure.

1. Both PRPraw and PRFmod are classical secure PRFs. Consequently, no classical algorithm A can distinguish them with a non-negligible advantage.

2. Given oracle access to PRFmod(k,a) where $( k , a ) \gets { \mathcal { K } } ^ { \mathsf { m o d } }$ , there is a quantum algorithm that can recover a with probability at least $1 - \varepsilon$ .

3. There is a quantum algorithm that can distinguish PRPraw from PRFmod with advantage $1 - \varepsilon$

Here $\varepsilon = \varepsilon ( n )$ is a negligible function.

For completeness, we prove Lemma 7.5 in Appendix D, by adapting the proofs of Claims 1 and 2 in [Zha12].

# 7.3 BPP vs BQP

Next we discuss whether there is an oracle $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ that separates BPP from BQP. We show that the answer is yes provided that one-way functions exist.

Theorem 7.6. Assuming one-way functions exist, there exists an oracle O ∈ P/poly such that $B P P ^ { \mathcal { O } } \neq$ $B Q P ^ { \mathcal { O } }$ .

Proof. We are going to use ${ \mathsf { P R P } } ^ { \mathsf { r a w } }$ and PRFmod from Section 7.2.

The oracle $\mathcal { O }$ will encode the truth tables of functions $f _ { 1 } , f _ { 2 } , \ldots$ , where each $f _ { n }$ is a function from ${ \mathcal { X } } _ { n } ^ { \mathsf { r a w } }$ to X rawn . For each $n$ , with probability 0.5 we draw $f _ { n }$ from $\mathsf { P R P } _ { K ^ { \mathsf { r a w } } } ^ { \mathsf { r a w } }$ , that is, draw $k \gets \mathcal { K } ^ { \mathsf { r a w } }$ and set $f _ { n } : = \mathsf { P R P } _ { k } ^ { \mathsf { r a w } }$ , and with probability 0.5 we draw $f _ { n }$ from $\mathsf { P R F } _ { K ^ { \mathrm { m o d } } } ^ { \mathsf { m o d } }$ similarly. We set $L$ to be the unary language consisting of all $0 ^ { n }$ for which $f _ { n }$ is drawn from $\mathsf { P R P } _ { K ^ { \mathsf { r a w } } } ^ { \mathsf { r a w } }$ .

By Lemma 7.5, there exists a BQP machine $M ^ { \mathcal { O } }$ that decides $L$ correctly on all but finite many values of $n$ with probability 1. Since we can simply hardwire the values of $n$ on which $M ^ { \mathcal { O } }$ is incorrect, it follows that $L \in \bar { \mathsf { B Q P } } ^ { \mathcal { O } }$ with probability 1.

On the other hand, again by Lemma 7.5, no BPP machine can distinguish $\mathsf { P R P } _ { K ^ { \mathsf { r a w } } } ^ { \mathsf { r a w } }$ and $\mathsf { P R F } _ { K ^ { \mathsf { m o d } } } ^ { \mathsf { m o d } }$ F Kmod with a non-negligible advantage. So let $M$ be a BPP machine, and let $E _ { n } ( M )$ be the event that $M$ decides whether $0 ^ { n } \in L$ correctly. We have

$$
\operatorname* { P r } _ { \mathcal { O } } [ E _ { n } ( M ) ] = \frac { 1 } { 2 } + o ( 1 ) ,
$$

even conditioning on events $E _ { 1 } ( M ) , \dots , E _ { n - 1 } ( M )$ . Therefore, we have $\operatorname* { P r } _ { \mathcal { O } } [ \Lambda _ { i = 1 } ^ { + \infty } E _ { n } ( M ) ] = 0$ , which means that a BPP machine $M$ decides $L$ with probability 0. Since there are countably many BPP machines, it follows that $L \not \in { \mathsf { B P P } } ^ { \mathcal { O } }$ with probability 1. Hence $\mathsf { B P P } ^ { \mathcal { O } } \neq \mathsf { B Q P } ^ { \mathcal { O } }$ with probability 1.

Finally, note that each $f _ { n }$ has a polynomial-size circuit, and consequently $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ .

# 7.4 Fourier Fishing and Fourier Sampling

Finally, we discuss Fourier Fishing and Fourier Sampling. We are going to show that, assuming the existence of subexponentially-secure one-way functions, Fourier Fishing and Fourier Sampling are hard even when it is promised that the oracle belongs to P/poly.

Theorem 7.7. Assuming the existence of subexponentially strong one-way functions, there is no polynomialtime classical algorithm that can solve promise-Ffishing with probability

$$
\mathsf { S u c c } _ { R } + \Omega ( 1 ) ,
$$

even when it is promised that the oracle function belongs to P/poly.

Proof. By Lemma 7.4, we can use our one-way function to construct an exponentially-secure pseudorandom function, PRF : ${ \boldsymbol { \mathcal { K } } } \times { \boldsymbol { \mathcal { X } } } \to \mathcal { V }$ . Without loss of generality, we assume that $| \mathscr { y } | = 2$ and $| { \mathcal { X } } | = 2 ^ { n }$ . Then we interpret $\mathcal { X }$ as the set $\{ 0 , 1 \} ^ { n }$ , and $\mathcal { V }$ as the set $\{ - 1 , 1 \}$ .

A Concentration Inequality. Now, consider the distribution $\mathsf { P R F } _ { \kappa }$ on functions $\{ 0 , 1 \} ^ { n } \to \{ - 1 , 1 \}$ We claim that

$$
\operatorname* { P r } _ { f \longleftarrow \mathsf { P R F } _ { K } } [ \mathsf { a d v } ( f ) > \mathsf { S u c c } _ { Q } - 1 / n ] > 1 - { \frac { 1 } { n } } - o ( 1 ) .
$$

To see this: from Lemma 6.5, we have

$$
\operatorname* { P r } _ { f \gets y ^ { \chi } } [ \mathsf { a d v } ( f ) > \mathsf { S u c c } _ { Q } - 1 / n ] > 1 - \frac 1 n .
$$

Therefore, if (18) does not hold, then we can construct a distinguisher between $\mathsf { P R F } _ { \kappa }$ and truly random functions $\chi ^ { y }$ by calculating adv $( f )$ in $2 ^ { O ( n ) }$ time. But this contradicts the assumption that PRF is exponentially-secure.

A distributional lower bound. Next, we show that for every polynomial-time algorithm $A$ , we have

$$
\operatorname* { P r } _ { f \longleftarrow \mathsf { P R F } _ { K } } [ A ^ { f } { \mathrm { ~ s o l v e s ~ } } \mathsf { F f i s h i n g ~ c o r r e c t l y } ] \leq 5 \mathsf { u c c } _ { R } + o ( 1 ) .
$$

This is because when $f$ is a truly random function, from Lemma 6.6, we have

$$
\operatorname* { P r } _ { f \gets y ^ { \chi } } [ A ^ { f } \ \mathrm { s o l v e } \ \mathsf { F f i s h i n g \ c o r r e c t l y } ] \le \mathsf { S u c c } _ { R } + o ( 1 ) .
$$

So if (19) does not hold, then we can construct a distinguisher between $\mathsf { P R F } _ { \kappa }$ and truly random functions $\chi ^ { y }$ by simulating $A ^ { f }$ to get its output $z$ , and then checking whether $z$ is a correct solution to Ffishing in 2O(n) time. This again contradicts our assumption that PRF is exponentially-secure.

The lower bound. Finally, we prove the theorem. Suppose for contradiction that there is such a polynomial-time algorithm $A$ . Then when $f \gets \mathsf { P R F } _ { \mathcal K }$ , from (18), with probability $1 - 1 / n - o ( 1 )$ , we have that $f$ satisfies the promise of promise-Ffishing. Thus, $A$ solves Ffishing when $f \gets \mathsf { P R F } _ { \mathcal K }$ with probability at least

$$
( 1 - o ( 1 ) ) \cdot ( \mathsf { S u c c } _ { R } + \Omega ( 1 ) ) = \mathsf { S u c c } _ { R } + \Omega ( 1 ) ,
$$

which contradicts (19).

By a similar reduction, we can show that Fourier Sampling is also hard.

Corollary 7.8. Assuming the existence of subexponentially-secure one-way functions, no polynomial-time classical algorithm can solve Fsampling with error

$$
\varepsilon < \mathsf { S u c c } _ { Q } - \mathsf { S u c c } _ { R } \approx 0 . 4 8 3 ,
$$

even if it is promised that the oracle function belongs to P/poly.

Proof. For a function $f$ , an exact algorithm for Fsampling can be used to solve Ffishing with probability $\mathsf { a d v } ( f )$ . Hence, a polynomial-time sampling algorithm $A$ for Fsampling with error at most $\varepsilon$ can solve Ffishing with probability at least $\mathsf { a d v } ( f ) - \varepsilon$ .

Note that by (18), when $f  \mathsf { P R F } _ { \kappa }$ , the algorithm $A$ can solve Ffishing with probability at least

$$
( { \mathsf { S u c c } } _ { Q } - { \frac { 1 } { n } } - \varepsilon ) \cdot ( 1 - o ( 1 ) ) = { \mathsf { S u c c } } _ { Q } - o ( 1 ) - \varepsilon .
$$

Therefore, by (19), we must have $\varepsilon \geq \mathsf { S u c c } _ { Q } - \mathsf { S u c c } _ { R }$ , which completes the proof.

# 8 Complexity Assumptions Are Needed for Quantum Supremacy Relative to Efficiently-Computable Oracles

In Section 7.4, we showed that the existence of subexponentially-secure one-way functions implies that Fourier Sampling and Fourier Fishing are classically hard, even when it is promised that the oracle function belongs to P/poly. We also showed that if one-way functions exist, then there exists an oracle $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ which separates BPP from BQP.

It is therefore natural to ask whether we can prove the same statements unconditionally. In this section, we show that at least some complexity assumptions are needed.

Theorem 8.1. Suppose SampBPP = SampBQP and $N P \subseteq B P P .$ Then for every oracle $\mathcal { O } \in P / p o I y ,$ we have $S a m p B P P ^ { \mathcal { O } } = S a m p B Q P ^ { \mathcal { O } }$ (and consequently $B P P ^ { \mathcal { O } } = B Q P ^ { \mathcal { O } } .$ ).

Much like in the proof of Theorem 5.1, we need to show that under the stated assumptions, every SampBQP algorithm $M$ can be simulated by a SampBPP algorithm $A$ .

Lemma 8.2. Suppose SampBPP = SampBQP and $N P \subseteq B P P .$ . Then for any polynomial $q ( n )$ and any SampBQP oracle algorithm $M$ , there is a SampBPP oracle algorithm $A$ such that:

For every $\mathcal { O } \in \mathsf { S l Z E } ( q ( n ) )$ , 13 let $\mathcal { D } _ { x , \varepsilon } ^ { M }$ and $\mathcal { D } _ { x , \varepsilon } ^ { A }$ be the distributions output by $M ^ { \mathcal { O } }$ and $A ^ { \mathcal { O } }$ respectively on input $\langle x , 0 ^ { 1 / \varepsilon } \rangle$ . Then

$$
\| \mathcal { D } _ { x , \varepsilon } ^ { M } - \mathcal { D } _ { x , \varepsilon } ^ { A } \| \leq \varepsilon .
$$

Before proving Lemma 8.2, we show that it implies Theorem 8.1.

Proof of Theorem 8.1. Let $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ be an oracle. Then there exists a polynomial $q ( n )$ such that $\mathcal { O } \in$ SIZE $( q ( n ) )$ .

Let $\boldsymbol { \mathcal { S } }$ be a sampling problem in SampBQPO. This means that there is a SampBQP oracle algorithm $M$ , such that for all $x \in \{ 0 , 1 \} ^ { * }$ and $\varepsilon$ , we have $\| \mathcal { D } _ { x , \varepsilon } ^ { M } - S _ { x } \| \leq \varepsilon$ . Let $A _ { M }$ be the corresponding SampBPP algorithm whose existence we’ve assumed, and consider the following algorithm $A ^ { \prime }$ : given input $\langle x , 0 ^ { 1 / \varepsilon } \rangle$ , run $A _ { M }$ on input $\langle x , 0 ^ { 2 / \varepsilon } \rangle$ to get a sample from $\mathcal { D } _ { x , \varepsilon / 2 } ^ { A _ { M } }$ .

Then we have

$$
\begin{array} { r l } & { \| \mathcal { D } _ { x , \varepsilon } ^ { A ^ { \prime } } - \mathcal { S } _ { x } \| = \| \mathcal { D } _ { x , \varepsilon / 2 } ^ { A _ { M } } - \mathcal { S } _ { x } \| } \\ & { \qquad \leq \| \mathcal { D } _ { x , \varepsilon / 2 } ^ { M } - \mathcal { D } _ { x , \varepsilon / 2 } ^ { A _ { M } } \| + \| \mathcal { D } _ { x , \varepsilon / 2 } ^ { M } - \mathcal { S } _ { x } \| \leq 2 \cdot \frac { \varepsilon } { 2 } \leq \varepsilon . } \end{array}
$$

This means that $A ^ { \prime }$ solves $\boldsymbol { \mathcal { S } }$ and $\pmb { S } \in \mathsf { S a m p B P P } ^ { \mathcal { O } }$ . Hence SampBQPO ⊆ SampBPPO.

Now we prove Lemma 8.2. The simulation procedure is similar to that in Lemma 5.3: that is, we replace each oracle gate, one by one, by a known function while minimizing the introduced error. The difference is that, instead of the brute-force method as in Lemma 5.3, here we use a more sophisticated PAC learning subroutine to find an “approximator” to replace the oracle gates.

Proof of Lemma 8.2. Let $\mathcal { O } \in \mathsf { S l Z E } ( q ( n ) )$ ; we let $f _ { n } = \mathcal { O } _ { n }$ for simplicity.

Recall that there exists a fixed polynomial $p$ , such that given input $\langle \dot { x } , 0 ^ { 1 / \varepsilon } \rangle$ , the machine $M$ first constructs a quantum circuit $C$ with $N = p ( | x | , 1 / \varepsilon )$ qubits and $N$ gates classically $C$ can contain $\mathcal { O }$ gates). Without loss of generality, we can assume for each $n$ , all $f _ { n }$ gates act only on the first $n$ qubits.

For a function $f ~ : ~ \{ 0 , 1 \} ^ { k } ~  ~ \{ 0 , 1 \}$ , recall that $U _ { f }$ denotes the unitary operator mapping $| i \rangle$ to $( - 1 ) ^ { f ( i ) } | i \rangle$ for $i \in \{ 0 , 1 \} ^ { k }$ .

Suppose there are $_ { T \mathcal { O } }$ -gates in total, and the $i$ -th $\mathcal { O }$ -gate is an $f _ { n _ { i } }$ gate. Then the unitary operator $U$ applied by the circuit $C$ can be decomposed as

$$
U = U _ { T + 1 } ( U _ { f _ { n _ { T } } } \otimes I _ { N - n _ { T } } ) \cdot \cdot \cdot ( U _ { f _ { n _ { 2 } } } \otimes I _ { N - n _ { 2 } } ) U _ { 2 } ( U _ { f _ { n _ { 1 } } } \otimes I _ { N - n _ { 1 } } ) U _ { 1 } ,
$$

where the $U _ { i }$ ’s are the unitary operators corresponding to the sub-circuits which don’t contain an $\mathcal { O }$ -gate.

Again, the algorithm proceeds by replacing each $\mathcal { O }$ -gate by a much simpler gate one by one, withou affecting the resulting quantum state too much, and then simulating the final circuit to get a sample to output.

Replacing the $t$ -th $\mathcal { O }$ -gate. Suppose we have already replaced the first $t - 1 \mathcal { O }$ -gates: that is, for each $i \in [ t - 1 ]$ , we replaced the $f _ { n _ { i } }$ gate (the $i$ -th $\mathcal { O }$ -gate) with a $g _ { i }$ gate. Now we are going to replace the $t$ -th $\mathcal { O }$ -gate.

Let

$$
| v \rangle = U _ { t } ( U _ { g _ { t - 1 } } \otimes I _ { N - n _ { t - 1 } } ) \cdot \cdot \cdot ( U _ { g _ { 2 } } \otimes I _ { N - n _ { 2 } } ) U _ { 2 } ( U _ { g _ { 1 } } \otimes I _ { N - n _ { 1 } } ) U _ { 1 } | 0 \rangle ^ { \otimes N } ,
$$

which is the quantum state right before the $t { \cdot }$ -th $\mathcal { O }$ gate in the circuit after the replacement.

For brevity, we use $f$ to denote the function $f _ { n _ { t } }$ , and we drop the subscript $t$ of $n _ { t }$ when it is clear from context.

Analysis of incurred error. The $t$ -th $\mathcal { O }$ -gate is an $f$ gate. If we replace it by a $g$ gate, then the deviation caused to the quantum states is

$$
\| U _ { f } \otimes I _ { N - n } | v \rangle - U _ { g } \otimes I _ { N - n } | v \rangle \| = \| ( U _ { f } - U _ { g } ) \otimes I _ { N - n } | v \rangle \| .
$$

Let $H$ be the Hilbert space corresponding to the last $N - n$ qubits, and let $\rho = \mathrm { T r } _ { H } [ | \boldsymbol { v } \rangle \langle \boldsymbol { v } | ]$ . Then proceeding exactly as in Lemma 5.3, we have

$$
\| ( ( U _ { f } - U _ { g } ) \otimes I _ { N - n } ) | v \rangle \| ^ { 2 } = 4 \cdot \operatorname * { P r } _ { i \sim Q } [ f ( i ) \neq g ( i ) ] ,
$$

where $Q$ is the probability on $\{ 0 , 1 \} ^ { n }$ defined by $Q ( i ) = \langle i | \rho | i \rangle$ , and $[ f ( i ) \neq g ( i ) ]$ is the indicator function that takes value 1 when $f ( i ) \neq g ( i )$ and 0 otherwise.

Upper bounding the deviation (20) vis PAC learning. Now, we want to replace $f$ by another function $g$ , so that the deviation term (20) is minimized.

By a standard result of PAC learning (cf. the book of Vapnik [Vap98]), for parameters $\varepsilon _ { 1 }$ and $\delta _ { 1 }$ , we can take a p $\mathrm { \ o d y } ( n , \varepsilon _ { 1 } ^ { - 1 } , \ln \delta _ { 1 } ^ { - 1 } )$ number of i.i.d. samples from $Q$ , and then find a function $g$ in ${ \mathsf { S l Z E } } ( q ( n ) )$ which agrees with $f$ on those samples. Then with probability at least $1 - \delta _ { 1 }$ , we will have

$$
\operatorname* { P r } _ { i \sim Q } [ f ( i ) \neq g ( i ) ] \leq \varepsilon _ { 1 } .
$$

The choice of $\varepsilon _ { 1 }$ and $\delta _ { 1 }$ will be made later. In any case, with probability at least $1 - \delta _ { 1 }$ , we have

$$
\| ( U _ { f } - U _ { g } ) \otimes I _ { N - n } | v \rangle \| ^ { 2 } \leq 4 \varepsilon _ { 1 } ,
$$

which in turn implies

$$
\| ( U _ { f } - U _ { g } ) \otimes I _ { N - n } | v \rangle \| \leq 2 \cdot \sqrt { \varepsilon _ { 1 } } .
$$

Analysis of the final circuit $C ^ { \mathrm { f i n a l } }$ . Suppose that at the end, for each $t \in [ T ]$ , our algorithm has replaced the $t$ -th $\mathcal { O }$ -gate with a $g _ { t }$ gate, where $g _ { t }$ is a function from $\{ 0 , 1 \} ^ { n _ { t } }$ to $\{ 0 , 1 \}$ . Let $C ^ { \mathrm { f i n a l } }$ be the circuit after the replacement. Also, let

$$
V = U _ { T + 1 } ( U _ { g _ { T } } \otimes I _ { N - n _ { T } } ) \cdot \cdot \cdot ( U _ { g _ { 2 } } \otimes I _ { N - n _ { 2 } } ) U _ { 2 } ( U _ { g _ { 1 } } \otimes I _ { N - n _ { 1 } } ) U _ { 1 }
$$

be the unitary operator corresponding to $C ^ { \mathrm { f i n a l } }$ .

Now we set δ1 = $\delta _ { 1 } = \frac { \varepsilon } { 2 T }$ 2T , and ε1 = $\varepsilon _ { 1 } = \frac { \varepsilon ^ { 4 } } { 2 5 6 T ^ { 2 } }$ . Then by a union bound over all rounds, and following exactly the same analysis as in Lemma 5.3, with probability at least $1 - T \cdot \delta _ { 1 } = 1 - \varepsilon / 2$ , we have

$$
\| U | 0 \rangle ^ { \otimes N } - V | 0 \rangle ^ { \otimes N } \| \le 2 T \cdot \sqrt { \varepsilon _ { 1 } } = \frac { \varepsilon ^ { 2 } } 8 .
$$

Our classical algorithm $A$ then simulates stages 2 and 3 of the SampBQP algorithm $M$ straightforwardly. It first takes a sample $z$ by measuring $V | 0 \rangle ^ { \otimes N }$ in the computational basis, and then outputs $A ^ { \mathsf { o u t p u t } } ( z )$ as its sample, where $A ^ { \mathsf { o u t p u t } }$ is the classical algorithm used by $M$ in stage 3.

By Corollary 2.5, with probability at least $1 - \varepsilon / 2$ , the final distribution $\mathcal { D }$ on which $A$ takes samples satisfies

$$
\| \mathcal { D } - \mathcal { D } _ { x , \varepsilon } ^ { M } \| \leq \sqrt { 2 \cdot \frac { \varepsilon ^ { 2 } } { 8 } } = \frac { \varepsilon } { 2 } .
$$

Hence, the outputted distribution DAx,ε satisfies

$$
\| \mathcal { D } _ { x , \varepsilon } ^ { A } - \mathcal { D } _ { x , \varepsilon } ^ { M } \| \leq \varepsilon .
$$

Showing that $A$ is a SampBPP algorithm. We still have to show that $A$ is a SampBPP oracle algorithm. From the previous discussion, $A$ needs to do the following non-trivial computations.

• Taking a polynomial number of samples from $Q$ . This task is in SampBQP (no oracle involved) by definition. By our assumption SampBQP $=$ SampBPP, it can be done in SampBPP.   
• Finding a $g \in \mathsf { S l Z E } ( q ( n ) )$ such that $g$ agrees with $f$ on all the samples. This can be done in NP, so by our assumption ${ \mathsf { N P \subseteq B P P } }$ , it can be done in BPP.   
• Taking a sample by measuring $V | 0 \rangle ^ { \otimes N }$ . Again, this task is in SampBQP, and hence can be done in SampBPP by our assumption.

Therefore, $A$ is a SampBPP oracle algorithm.

# 9 Open Problems

There are many exciting open problems left by this paper; here we mention just a few.

(1) Is QUATH (our assumption about the hardness of guessing whether $| \langle 0 | C | 0 \rangle | ^ { 2 }$ is greater or less than the median) true or false?   
(2) Is Conjecture 1 true? That is, does a random quantum circuit on $n$ qubits sample an unbalanced distribution over $n$ -bit strings with $1 - 1 / \exp ( n )$ probability?   
(3) We showed that there exists an oracle relative to which SampBPP $=$ SampBQP but PH is infinite. Can we nevertheless show that SampBPP $=$ SampBQP would collapse PH in the unrelativized world? (An affirmative answer would, of course, follow from Aaronson and Arkhipov’s Permanentof-Gaussians Conjecture [AA13], as mentioned in Section 1.2.)   
(4) Is our classical algorithm to simulate a quantum circuit with $n$ qubits and $m$ gates optimal? Or could we reduce the complexity, say from $m ^ { O ( n ) }$ to $2 ^ { O ( n ) } \cdot m ^ { O ( { \hat { 1 } } ) }$ , while keeping the space usage polynomial? Does it matter if we only want to sample from the output distribution, rather than actually calculating the probabilities? What about if we only want to guess an amplitude with small bias, as would be needed to refute QUATH?   
(5) For random quantum circuit sampling, we proved a conditional hardness result that talks directly about the observed outputs of a sampling process, rather than about the unknown distribution that’s sampled from. Can we get analogous hardness results for the BosonSampling or IQP models, under some plausible hardness conjecture? Note that the argument from Section 3 doesn’t work directly for BosonSampling or IQP, for the simple reason that in those models, the advantage over chance in guessing a given amplitude is at least $1 / \exp ( n )$ , rather than $1 / \exp ( m )$ for some $m \gg n$ as is the case for random circuits.   
(6) We proved a lower bound of $\Omega ( N )$ on the classical query complexity of Fourier Sampling, for a rather small error $\varepsilon = { \frac { 1 } { 4 0 0 0 0 } }$ The error constant does matter for sampling problems, since there is no efficient way to reduce the error in general. So can we discover the exact threshold $\varepsilon$ for an $\Omega ( N )$ lower bound? That is, find the constant $\varepsilon$ such that there is an $o ( N )$ query classical algorithm solving Fourier Sampling with error $\varepsilon$ , but any classical algorithm with error $< \varepsilon$ needs $\Omega ( N )$ queries?   
(7) In Section 7, we showed that there is an oracle $\mathcal { O }$ in P/poly separating BPP from BQP, assuming that one-way functions exist. Is it possible to weaken the assumption to, say, NP $\nless$ BPP?

# Acknowledgments

We thank Shalev Ben-David, Sergio Boixo, Yuzhou Gu, Greg Kuperberg, John Martinis, Ashley Montanaro, John Preskill, Vadim Smelyansky, Ronald de Wolf, and Mark Zhandry for helpful discussions about the subject of this paper.

# References

$[ \mathrm { A } ^ { + } ]$ S. Aaronson et al. The Complexity Zoo. www.complexityzoo.com.   
[AA13] S. Aaronson and A. Arkhipov. The computational complexity of linear optics. Theory of Computing, 9(4):143–252, 2013. Earlier version in Proc. ACM STOC’2011. ECCC TR10- 170, arXiv:1011.3245.   
[AA15] Scott Aaronson and Andris Ambainis. Forrelation: A problem that optimally separates quantum from classical computing. In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing, pages 307–316. ACM, 2015.   
[Aar10] S. Aaronson. BQP and the polynomial hierarchy. In Proc. ACM STOC, 2010. arXiv:0910.4698.   
[Aar14] Scott Aaronson. The equivalence of sampling and searching. Theory of Computing Systems, 55(2):281–298, 2014.   
[Aar15] S. Aaronson. Google, D-wave, and the case of the factor- $1 0 \uparrow 8$ speedup for WHAT?, 2015. http://www.scottaaronson.com/blog/ $\mathrm { ? p } { = } 2 5 5 5$ .   
[AB09] Sanjeev Arora and Boaz Barak. Computational complexity: a modern approach. Cambridge University Press, 2009.   
[ABDK15] Scott Aaronson, Shalev Ben-David, and Robin Kothari. Separations in query complexity using cheat sheets. arXiv preprint arXiv:1511.01937, 2015.   
[ABKM16] Scott Aaronson, Adam Bouland, Greg Kuperberg, and Saeed Mehraban. The computational complexity of ball permutations. arXiv preprint arXiv:1610.06646, 2016.   
[ABO97] D. Aharonov and M. Ben-Or. Fault-tolerant quantum computation with constant error. In Proc. ACM STOC, pages 176–188, 1997. quant-ph/9906129.   
[ABOE08] D. Aharonov, M. Ben-Or, and E. Eban. Interactive proofs for quantum computations. arXiv:0810.5375, 2008.   
[Amb05] Andris Ambainis. Polynomial degree and lower bounds in quantum complexity: Collision and element distinctness with small range. Theory of Computing, 1(1):37–46, 2005.   
[AS04] S. Aaronson and Y. Shi. Quantum lower bounds for the collision and the element distinctness problems. J. of the ACM, 51(4):595–605, 2004.   
[AW09] S. Aaronson and A. Wigderson. Algebrization: a new barrier in complexity theory. ACM Trans. on Computation Theory, 1(1), 2009. Earlier version in Proc. ACM STOC’2008.   
[BBBV97] C. Bennett, E. Bernstein, G. Brassard, and U. Vazirani. Strengths and weaknesses of quantum computing. SIAM J. Comput., 26(5):1510–1523, 1997. quant-ph/9701001.   
[BFK09] A. Broadbent, J. Fitzsimons, and E. Kashefi. Universal blind quantum computation. In Proc. IEEE FOCS, 2009. arXiv:0807.4154.   
[BG16] Sergey Bravyi and David Gosset. Improved classical simulation of quantum circuits dominated by clifford gates. arXiv preprint arXiv:1601.07601, 2016.   
[BGS75] Theodore Baker, John Gill, and Robert Solovay. Relativizations of the ${ \mathrm { P } } { = } \mathrm { ? N P }$ question. SIAM Journal on computing, 4(4):431–442, 1975.   
[BHH16] Fernando GSL Brandao, Aram W Harrow, and Michał Horodecki. Local random quan- ˜ tum circuits are approximate polynomial-designs. Communications in Mathematical Physics, 346(2):397–434, 2016.   
$[ \mathrm { B } \mathrm { I S } ^ { + } 1 6 ]$ Sergio Boixo, Sergei V Isakov, Vadim N Smelyanskiy, Ryan Babbush, Nan Ding, Zhang Jiang, John M Martinis, and Hartmut Neven. Characterizing quantum supremacy in near-term devices. arXiv preprint arXiv:1608.00263, 2016.   
[BJS10] M. Bremner, R. Jozsa, and D. Shepherd. Classical simulation of commuting quantum computations implies collapse of the polynomial hierarchy. Proc. Roy. Soc. London, A467(2126):459–472, 2010. arXiv:1005.1407.   
[BL95] Dan Boneh and Richard J Lipton. Quantum cryptanalysis of hidden linear functions. In Annual International Cryptology Conference, pages 424–437. Springer, 1995.   
[BMS15] Michael J Bremner, Ashley Montanaro, and Dan J Shepherd. Average-case complexity versus approximate simulation of commuting quantum computations. arXiv preprint arXiv:1504.07999, 2015.   
[BMS16] Michael J Bremner, Ashley Montanaro, and Dan J Shepherd. Achieving quantum supremacy with sparse and noisy commuting quantum computations. arXiv preprint arXiv:1610.01808, 2016.   
[BV97] E. Bernstein and U. Vazirani. Quantum complexity theory. SIAM J. Comput., 26(5):1411– 1473, 1997. Earlier version in Proc. ACM STOC’1993.   
[Che16] Lijie Chen. A note on oracle separations for BQP. arXiv preprint arXiv:1605.00619, 2016.   
$[ \mathrm { C H S ^ { + } } 1 5 ]$ Jacques Carolan, Christopher Harrold, Chris Sparrow, Enrique Mart´ın-Lopez, Nicholas J Rus- ´ sell, Joshua W Silverstone, Peter J Shadbolt, Nobuyuki Matsuda, Manabu Oguma, Mikitaka Itoh, Graham D Marshall, Mark G Thompson, Jonathan C F Matthews, Toshikazu Hashimoto, Jeremy L O’Brien, and Anthony Laing. Universal linear optics. Science, 349(6249):711–716, 2015.   
[FFKL03] Stephen Fenner, Lance Fortnow, Stuart A Kurtz, and Lide Li. An oracle builders toolkit. Information and Computation, 182(2):95–136, 2003.   
[FH16] Edward Farhi and Aram W Harrow. Quantum supremacy through the quantum approximate optimization algorithm. arXiv preprint arXiv:1602.07674, 2016.   
[FR99] L. Fortnow and J. Rogers. Complexity limitations on quantum computation. J. Comput. Sys. Sci., 59(2):240–252, 1999. cs.CC/9811023.   
[Fuj16] Keisuke Fujii. Noise threshold of quantum supremacy. arXiv preprint arXiv:1610.03632, 2016.   
[GGM86] O. Goldreich, S. Goldwasser, and S. Micali. How to construct random functions. J. of the ACM, 33(4):792–807, 1986. Earlier version in Proc. IEEE FOCS’1984, pp. 464-479.   
[GL89] Oded Goldreich and Leonid A Levin. A hard-core predicate for all one-way functions. In Proceedings of the twenty-first annual ACM symposium on Theory of computing, pages 25– 32. ACM, 1989.   
[Has86] Johan Hastad. Almost optimal lower bounds for small depth circuits. In Proceedings of the eighteenth annual ACM symposium on Theory of computing, pages 6–20. ACM, 1986.   
[HILL99] J. Hastad, R. Impagliazzo, L. A. Levin, and M. Luby. A pseudorandom generator from any ˚ one-way function. SIAM J. Comput., 28(4):1364–1396, 1999.   
[IW97] R. Impagliazzo and A. Wigderson. $\mathrm { P } =$ BPP unless E has subexponential circuits: derandomizing the XOR Lemma. In Proc. ACM STOC, pages 220–229, 1997.   
[JVdN14] Richard Jozsa and Marrten Van den Nest. Classical simulation complexity of extended clifford circuits. Quantum Information & Computation, 14(7&8):633–648, 2014.   
[Kal11] Gil Kalai. How quantum computers fail: quantum codes, correlations in physical systems, and noise accumulation. arXiv preprint arXiv:1106.0485, 2011.   
$[ \mathrm { K B F ^ { + } } 1 5 ]$ J Kelly, R Barends, AG Fowler, A Megrant, E Jeffrey, TC White, D Sank, JY Mutus, B Campbell, Yu Chen, et al. State preservation by repetitive error detection in a superconducting quantum circuit. Nature, 519(7541):66–69, 2015.   
[Kut05] Samuel Kutin. Quantum lower bound for the collision problem with small range. Theory of Computing, 1(1):29–36, 2005.   
[Lev03] Leonid A Levin. The tale of one-way functions. Problems of Information Transmission, 39(1):92–103, 2003.   
[LR88] Michael Luby and Charles Rackoff. How to construct pseudorandom permutations from pseudorandom functions. SIAM Journal on Computing, 17(2):373–386, 1988.   
[MFF14] Tomoyuki Morimae, Keisuke Fujii, and Joseph F Fitzsimons. Hardness of classically simulating the one-clean-qubit model. Physical review letters, 112(13):130502, 2014.   
[MS08] Igor L Markov and Yaoyun Shi. Simulating quantum computation by contracting tensor networks. SIAM Journal on Computing, 38(3):963–981, 2008.   
[NW94] Noam Nisan and Avi Wigderson. Hardness vs randomness. Journal of computer and System Sciences, 49(2):149–167, 1994.   
[PGHAG15] Borja Peropadre, Gian Giacomo Guerreschi, Joonsuk Huh, and Alan Aspuru-Guzik. Mi- ´ crowave boson sampling. arXiv preprint arXiv:1510.08064, 2015.   
[Pre12] John Preskill. Quantum computing and the entanglement frontier. arXiv preprint arXiv:1203.5813, 2012.   
[RR97] A. A. Razborov and S. Rudich. Natural proofs. J. Comput. Sys. Sci., 55(1):24–35, 1997. Earlier version in Proc. ACM STOC’1994, pp. 204-213. Benjamin Rossman, Rocco A Servedio, and Li-Yang Tan. An average-case depth hierarchy theorem for boolean circuits. In Foundations of Computer Science (FOCS), 2015 IEEE 56th Annual Symposium on, pages 1030–1048. IEEE, 2015.   
Terry Rudolph. Why I am optimistic about the silicon-photonic route to quantum computing. arXiv preprint arXiv:1607.08535, 2016.   
W. J. Savitch. Relationships between nondeterministic and deterministic tape complexities. J. Comput. Sys. Sci., 4(2):177–192, 1970.   
Rocco A Servedio and Steven J Gortler. Equivalences and separations between quantum and classical learnability. SIAM Journal on Computing, 33(5):1067–1092, 2004.   
A. Shamir. IP=PSPACE. J. of the ACM, 39(4):869–877, 1992. Earlier version in Proc. IEEE FOCS’1990, pp. 11-15.   
P. W. Shor. Polynomial-time algorithms for prime factorization and discrete logarithms on a quantum computer. SIAM J. Comput., 26(5):1484–1509, 1997. Earlier version in Proc. IEEE FOCS’1994. quant-ph/9508027.   
Joel Spencer. Asymptopia, volume 71. American Mathematical Soc., 2014.   
Amit Sahai and Salil Vadhan. A complete problem for statistical zero knowledge. Journal of the ACM (JACM), 50(2):196–249, 2003.   
B. M. Terhal and D. P. DiVincenzo. Adaptive quantum computation, constant-depth circuits and Arthur-Merlin games. Quantum Information and Computation, 4(2):134–145, 2004. quant-ph/0205133.   
S. Toda. PP is as hard as the polynomial-time hierarchy. SIAM J. Comput., 20(5):865–877, 1991. Earlier version in Proc. IEEE FOCS’1989, pp. 514-519.   
Vladimir Naumovich Vapnik. Statistical learning theory, volume 1. Wiley New York, 1998. Andrew Chi-Chih Yao. Separating the polynomial-time hierarchy by oracles. In 26th Annual Symposium on Foundations of Computer Science (sfcs 1985), 1985.   
Mark Zhandry. How to construct quantum random functions. In Foundations of Computer Science (FOCS), 2012 IEEE 53rd Annual Symposium on, pages 679–687. IEEE, 2012. Mark Zhandry. A note on quantum-secure prps. arXiv preprint arXiv:1611.05564, 2016.

# A Other Results on Oracle Separations in P/poly

In this section we discuss the rest of our results on complexity theory relative to oracles in P/poly (see Figure 1 for an overview). For the definitions of the involved complexity classes, see for example $[ \mathrm { A } ^ { + } ]$ .

We first discuss $\mathsf { P }$ and NP. We observe that there exists an oracle $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ such that $\bar { \mathsf { P } } ^ { \mathcal { O } } \neq \mathsf { N P } ^ { \mathcal { O } }$ unconditionally, and no oracle $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ can make $\mathsf { P } = \mathsf { N P }$ unless ${ \mathsf { N P } } \subset { \mathsf { P } } / { \mathsf { p o l y } }$ .

Then we discuss $\mathsf { P }$ and BPP. We first prove that the standard derandomization assumption (there exists a function $f \in \mathsf { E } = \mathsf { D T I M E } ( 2 ^ { O ( n ) } )$ that requires a $2 ^ { \Omega ( n ) }$ -size circuit) also implies that $\mathsf { P } ^ { \mathcal { O } } = \mathsf { B } \mathsf { P } \mathsf { P } ^ { \mathcal { O } }$ for all $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ . Then, surprisingly, we show that the converse also holds! I.e., if no such $f$ exists, then there exists an oracle $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ such that $\mathsf { P } ^ { \mathcal { O } } \neq \mathsf { B } \mathsf { P } \mathsf { P } ^ { \mathcal { O } }$ .

Finally, we discuss BQP and SZK. We show that assuming the existence of one-way functions, there exist oracles in P/poly that separate BQP from SZK, and also SZK from BQP.

We will need to use quantum-secure pseudorandom permutations. By a very recent result of Zhandry [Zha16], their existence follows from the existence of quantum one-way functions.

Lemma A.1 ( [Zha16]). Assuming quantum one way functions exist, there exist quantum-secure PRPs.

![](images/c90804084a583244960147896c5d7a4e0cdc68f0f67b037ec017d882ad9d0640.jpg)

Figure $: { \mathcal { C } } _ { 1 } \to { \mathcal { C } } _ { 2 }$ indicates $\mathcal { C } _ { 1 }$ is contained in $\mathcal { C } _ { 2 }$ respect to every oracle in P/poly, and $\mathcal { C } _ { 1 } \ \mathrm { ~ -- \ } \mathcal { C } _ { 2 }$ denotes that there is an oracle $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ such that ${ \mathcal { C } } _ { 1 } ^ { \mathcal { O } } \not \subset { \mathcal { C } } _ { 2 } ^ { \mathcal { O } }$ . Red indicates this statement is based on the existence of classical one-way functions, Blue indicates the statement is based on the existence of quantum one-way functions, and Black indicates the statement holds unconditionally.

# A.1 P, BPP, BQP vs NP

We begin with the relationships of P, BPP, and BQP to NP relative to oracles in P/poly.

The first observation is that using the function OR and standard diagonalization techniques, together with the fact that OR is hard for quantum algorithms [BBBV97], we immediately have:

Observation 1. There is an oracle $\mathcal { O } \in P / p o I y$ such that $N P ^ { \mathcal { O } } \subset B Q P ^ { \mathcal { O } }$ .

On the other side, we also show that unless NP ⊂ P/poly (BQP/poly), there is no oracle $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ such that ${ \mathsf { N P } } ^ { \mathcal { O } } \subseteq { \mathsf { B P P } } ^ { \mathcal { O } } ( { \mathsf { B Q P } } ^ { \mathcal { O } } )$ .

Theorem A.2. Unless $N P \subset P / p o I y$ , there is no oracle $\mathcal { O } \in P / p o l \text{ ‰}$ y such that $N P ^ { \mathcal { O } } \subseteq B P P ^ { \mathcal { O } }$ . Likewise, there is no oracle $\mathcal { O } \in P / p o l \}$ such that $N P ^ { \mathcal { O } } \subseteq B Q P ^ { \mathcal { O } }$ unless $N P \subseteq B Q P / p o I y$ .

Proof. Suppose there is an oracle $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ such that ${ \mathsf { N P } } ^ { \mathcal { O } } \subseteq { \mathsf { B P P } } ^ { \mathcal { O } }$ . Since ${ \mathsf { B P P } } \subset { \mathsf { P } } / { \mathsf { p o l y } }$ , and $\mathsf { P } ^ { \mathcal { O } } / \mathsf { p o l y } \subseteq \mathsf { P } / \mathsf { p o l y }$ (since the relevant parts of the oracle $\mathcal { O }$ can be directly supplied to the P/poly algorithm), we have $\mathsf { N P \subseteq N P ^ { \mathcal { O } } \subset P / p o l y }$ . The second claim can be proved in the same way.

The following corollary is immediate.

Corollary A.3. There is an oracle O ∈ P/poly such that $P ^ { \mathcal { O } } \neq N P ^ { \mathcal { O } }$ , and there is no oracle $\mathcal { O } \in P / p o I y$ such that $P ^ { \mathcal { O } } = N P ^ { \mathcal { O } }$ unless $N P \subset P / p o I y$ .

# A.2 P vs BPP

Next we consider the relationship between $\mathsf { P }$ and BPP. It is not hard to observe that the standard derandomization assumption for ${ \mathsf { P } } = { \mathsf { B } } { \mathsf { P } } { \mathsf { P } }$ is in fact strong enough to make $\mathsf { P } ^ { \mathcal { O } } = \mathsf { B } \mathsf { P } \mathsf { P } ^ { \mathcal { O } }$ for every oracle $\mathcal { O }$ in P/poly.

Given a function $f : \{ 0 , 1 \} ^ { n }  \{ 0 , 1 \}$ , let $H _ { \mathrm { w r s } } ( f )$ be the minimum size of circuits computing $f$ exactly.

Observation 2 (Implicit in [NW94, IW97], see also Theorem 20.7 in [AB09]). If there exists a function $f \in E = D T I M E ( 2 ^ { \bar { O } ( n ) } )$ and $\varepsilon > 0$ such that $H _ { w r s } ( f ) \geq 2 ^ { \varepsilon n }$ for sufficiently large $n$ , then $B P P ^ { \mathcal { O } } = P ^ { \mathcal { O } }$ for every $\mathcal { O } \in P / p o I y .$ .

Proof Sketch. From [NW94] and [IW97], the assumption leads to a strong PRG which is able to fool circuits of a fixed polynomial size with a logarithmic seed length.

An algorithm with an oracle $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ with a certain input can still be represented by a polynomial size circuit, so we can still enumerate all possible seeds to get a deterministic algorithm.

Surprisingly, we show that condition is not only sufficient, but also necessary.

Theorem A.4. If for every $f \in E = D T I M E ( 2 ^ { O ( n ) } )$ and $\varepsilon > 0$ , there are infinitely many n’s with $H _ { w r s } ( f ) <$ $2 ^ { \varepsilon n }$ , then there exists an oracle $\mathcal { O } \in P / p o I y$ such that $B P P ^ { \mathcal { O } } \neq P ^ { \mathcal { O } }$ .

Proof. For simplicity, in the following we will specify an oracle $\mathcal { O }$ by a sequence of functions $\{ f _ { i } \}$ , where each $f _ { i }$ is a function from $\{ 0 , 1 \} ^ { n _ { i } } \to \{ 0 , 1 \}$ and the sequence $\{ n _ { i } \}$ is strictly increasing. That is, ${ \mathcal { O } } _ { n _ { i } }$ is set to $f _ { i }$ , and $\mathcal { O }$ maps all strings with length not in $\{ n _ { i } \}$ to 0.

As there are only countably many $\mathsf { P }$ oracle TM machines, we let $\{ A _ { i } \} _ { i = 1 } ^ { + \infty }$ be an ordering of them.

The GapMaj function. Recall that the gapped-majority function, GapMaj : $\{ 0 , 1 \} ^ { N } \stackrel { \scriptscriptstyle \backslash } {  } \{ 0 , 1 \}$ , which outputs 1 if the input has Hamming weight $\geq 2 N / 3$ , or 0 if the input has Hamming weight $\le N / 3$ , and is undefined otherwise, is the function which separates $\mathsf { P }$ and BPP in the query complexity world. We are going to encode inputs to GapMaj in the oracle bits to achieve our separation.

We call an oracle valid, if for each $n$ , either $| { \mathcal { O } } _ { n } ^ { - 1 } ( 0 ) | \geq { \frac { 2 } { 3 } } \cdot 2 ^ { n }$ or $| { \mathcal { O } } _ { n } ^ { - 1 } ( 1 ) | \geq { \frac { 2 } { 3 } } \cdot 2 ^ { n }$ . That is, if we interpret ${ \mathcal { O } } _ { n }$ as a binary string with length $2 ^ { n }$ , then $\mathsf { G a p M a j } ( { \mathcal { O } } _ { n } )$ is defined.

The language $L ^ { \mathcal { O } }$ . For a valid oracle $\mathcal { O }$ , we define the following language:

$$
L o = \{ 0 ^ { n } : { \mathsf { G a p M a j } } ( { \mathcal { O } } _ { n } ) = 1 \} .
$$

Clearly, this language lies in $\mathsf { B P P } ^ { \mathcal { O } }$ . To prove the theorem, we will construct a valid oracle $\mathcal { O }$ such that $L o \not \in { \mathsf { P } } ^ { \mathcal { O } }$ .

Construction of $\mathcal { O }$ . To construct such an oracle, we resort to the standard diagonalization method: for each integer $i$ , we find an integer $n _ { i }$ and set the function ${ \mathcal { O } } _ { n _ { i } }$ so that the machine $A _ { i }$ can’t decide $0 ^ { n _ { i } }$ correctly. In order to do this, we will make sure that each $A _ { i }$ can only see 0 when querying the function ${ \mathcal { O } } _ { n _ { i } }$ . Since $A _ { i }$ can only see a polynomial number of bits, we can set the remaining bits in ${ \mathcal { O } } _ { n _ { i } }$ adversarially.

Let $\mathcal { O } _ { \mathsf { p a r t } } ^ { i }$ be the oracle specified by $\{ \mathcal { O } _ { n _ { j } } \} _ { j = 1 } ^ { i }$ , and let $T _ { i }$ be the maximum integer such that a bit in $\mathcal { O } _ { T _ { i } }$ is queried by $A _ { i }$ when running on input $0 ^ { n _ { i } }$ . Observe that by setting $n _ { i + 1 } > T _ { i }$ , we can make sure that $A _ { i } ^ { \mathcal { O } } ( 0 ^ { n _ { i } } ) = A _ { i } ^ { \mathcal { O } _ { \mathsf { p a r t } } ^ { i } } ( 0 ^ { n _ { i } } )$ for each $i$ .

Diagonalization against $A _ { i }$ . Suppose we have already constructed $\mathcal { O } _ { n _ { 1 } } , \ldots , \mathcal { O } _ { n _ { i - 1 } }$ , and we are going to deal with $A _ { i }$ . Since $A _ { i }$ is a $\mathsf { P }$ machine, there exists a constant $c$ such that $A _ { i }$ runs in at most $n ^ { c }$ steps for inputs with length $n$ . Thus, $A _ { i }$ can query at most $n ^ { c }$ values in ${ \mathcal { O } } _ { n }$ on input $0 ^ { n }$ .

Construction and Analysis of $f$ . Now consider the following function $f$ , which analyzes the behavior of $A _ { i } ^ { \mathcal { O } _ { \mathsf { p a r t } } ^ { i - 1 } }$

• given an input $x \in \{ 0 , 1 \} ^ { * }$ , let $m = | x |$ ;

• the first $m _ { 1 } = \lfloor m / 5 c \rfloor$ bits of $x$ encode an integer $n \in [ 2 ^ { m _ { 1 } } ]$ ;

• the next $m _ { 2 } = m - m _ { 1 }$ bits of $x$ encode a string $p \in \{ 0 , 1 \} ^ { m _ { 2 } }$ • $f ( x ) = 1$ iff $A _ { i } ^ { \mathcal { O } _ { \mathsf { p a r t } } ^ { i - 1 } } ( 0 ^ { n } )$ has queried $\mathcal { O } _ { n } ( z )$ for an $z \in \{ 0 , 1 \} ^ { n }$ with $p$ as a prefix.14

It is not hard to see that $f \in \mathsf { E }$ : the straightforward algorithm which directly simulates $A _ { i } ^ { \mathcal { O } _ { \mathsf { p a r t } } ^ { i - 1 } } ( 0 ^ { n } )$ runs in $O ( n ^ { c } ) = 2 ^ { O ( m / 5 c \cdot c ) } = 2 ^ { O ( m ) }$ time (note that the input length is $m = | x | )$ . Therefore, by our assumption, there exists an integer $m$ such that $2 ^ { \lfloor m / 5 c \rfloor } > \operatorname* { m a x } ( T _ { i - 1 } , n _ { i - 1 } )$ and $\dot { H } _ { \mathrm { w r s } } ( f _ { m } ) < 2 ^ { m / c }$ . Then we set ni = 2bm/5cc.

Construction and Analysis of ${ \mathcal { O } } _ { n _ { i } }$ . Now, if $A _ { i } ^ { \mathcal { O } _ { \mathsf { p a r t } } ^ { i - 1 } } ( 0 ^ { n _ { i } } ) = 1$ , we set ${ \mathcal { O } } _ { n _ { i } }$ to be the constant function 0, so that $L ^ { \mathcal { O } } ( 0 ^ { n _ { i } } ) = 0$ .

Otherwise, $A _ { i } ^ { \mathcal { O } _ { \mathsf { p a r t } } ^ { i - 1 } } ( 0 ^ { n _ { i } } ) = 0$ . We define a function $g : \{ 0 , 1 \} ^ { n _ { i } } \to \{ 0 , 1 \}$ as follows: $g ( z ) = 1$ iff $A _ { i } ^ { \mathcal { O } _ { \mathsf { p a r t } } ^ { i - 1 } } ( 0 ^ { n _ { i } } )$ has queried $\mathcal { O } _ { n _ { i } } ( z ^ { \prime } )$ for an $z ^ { \prime } \in \{ 0 , 1 \} ^ { n _ { i } }$ such that $z$ and $z ^ { \prime }$ share a prefix of length $m - \lfloor m / 5 c \rfloor$ . Note that $g ( z )$ can be implemented by hardwiring $n _ { i }$ and $z _ { 1 . . . m - \lfloor m / 5 c \rfloor }$ (that is, the first $m - \lfloor m / 5 c \rfloor$ bits of $z$ ) into the circuit for $f _ { m }$ , which means that there is a circuit of size $2 ^ { \bar { m } / c } = n _ { i } ^ { O ( 1 ) }$ ) for g. We set Oni := ¬g.

From the definition of $g$ and the fact that $A _ { i } ^ { \mathcal { O } _ { \mathsf { p a r t } } ^ { i - 1 } } ( 0 ^ { n _ { i } } )$ makes at most $n _ { i } ^ { c }$ queries, there is at most a

$$
\frac { n _ { i } ^ { c } } { 2 ^ { m - \lfloor m / 5 c \rfloor } } < \frac { n _ { i } ^ { c } } { 2 ^ { 4 c \lfloor m / 5 c \rfloor } } = n _ { i } ^ { - 3 c }
$$

fraction of inputs that are 0 in $\neg g$ . Hence, $\mathsf { G a p M a j } ( \lnot g ) = 1$ and $L ^ { \mathcal { O } } ( 0 ^ { n _ { i } } ) = 1$ .

We claim that in both cases, we have $A _ { i } ^ { { \mathcal { O } } _ { \mathsf { p a r t } } ^ { i - 1 } } ( 0 ^ { n _ { i } } ) = A _ { i } ^ { { \mathcal { O } } _ { \mathsf { p a r t } } ^ { i } } ( 0 ^ { n _ { i } } )$ . This holds trivially in the first case since we set $\mathcal { O } _ { n _ { i } } : = \mathbf { 0 }$ . For the second case, note from the definition of $g$ that all queries by $A _ { i } ^ { \mathcal { O } _ { \mathsf { p a r t } } ^ { i } } ( 0 ^ { n _ { i } } )$ to ${ \mathcal { O } } _ { n _ { i } }$ return 0, and hence $A _ { i }$ will behave exactly the same.

Finally, since we set $n _ { i } > T _ { i - 1 }$ for each $i$ , we have $A _ { i } ^ { \mathcal { O } } ( 0 ^ { n _ { i } } ) = A _ { i } ^ { \mathcal { O } _ { \mathsf { p a r t } } ^ { i } } ( 0 ^ { n _ { i } } ) \neq L ^ { \mathcal { O } } ( 0 ^ { n _ { i } } )$ , which means that no $A _ { i }$ can decide $L ^ { \mathcal { O } }$ .

# A.3 BQP vs SZK

Next we investigate the relationship between BQP and SZK relative to oracles in P/poly. We first show that, by using quantumly-secure pseudorandom permutations, as well as the quantum lower bound for distinguishing permutations from 2-to-1 functions [AS04], we can construct an oracle in P/poly which separates SZK from BQP.

Theorem A.5. Assuming quantum-secure one way functions exist, there exists an oracle $\mathcal { O } \in P ,$ /poly such that $S Z K ^ { \mathcal { O } } \subset B Q P ^ { \mathcal { O } }$ .

Proof. Let PRP be a quantum-secure pseudorandom permutation from ${ \boldsymbol { \mathcal { K } } } \times { \boldsymbol { \mathcal { X } } } \to { \boldsymbol { \mathcal { X } } }$ , whose existence is guaranteed by Lemma A.1.

We first build a pseudorandom 2-to-1 function from PRP. We interpret $\mathcal { X }$ as $[ N ]$ where $N = | { \mathcal { X } } |$ , and assume that $N$ is even. We construct $\mathsf { P R F ^ { 2 \to 1 } }$ : $( \mathcal { K } \times \mathcal { K } ) \times \mathcal { X } \to \mathcal { X }$ as follows:

• The key space $\kappa ^ { 2 \to 1 }$ is $\kappa \times \kappa$ . That is, a key $k \in \mathcal { K } ^ { 2  1 }$ is a pair of keys $( k _ { 1 } , k _ { 2 } )$

Note that $\mathsf { P R F ^ { 2 \to 1 } }$ would be a uniformly random 2-to-1 function from $[ N ]  [ N ]$ , if $\mathsf { P R P } _ { k _ { 1 } }$ and $\mathsf { P R P } _ { k _ { 2 } }$ were replaced by two uniformly random permutations on $[ N ]$ . Hence, by a standard reduction argument, $\mathsf { P R F ^ { 2  \bar { 1 } } }$ is a quantumly-secure pseudorandom 2-to-1 function. That is, for any polynomial-time quantum algorithm $A$ , we have

$$
| \operatorname* { P r } _ { k  K ^ { 2  1 } } [ A ^ { \mathrm { P R F } _ { k } ^ { 2  1 } } ( ) = 1 ] - \operatorname* { P r } _ { f  \mathsf { F } _ { \mathcal { X } } ^ { 2  1 } } [ A ^ { f } ( ) = 1 ] | < \varepsilon ,
$$

where $\varepsilon$ is a negligible function and $\mathsf { F } _ { \mathcal { X } } ^ { 2  1 }$ is the set of 2-to-1 functions from $\mathcal { X }  \mathcal { X }$

Also, from the definition of PRP, we have

$$
| \operatorname* { P r } _ { k  K ^ { \mathsf { P R P } } } [ A ^ { \mathsf { P R P } _ { k } } ( ) = 1 ] - \operatorname* { P r } _ { f  \mathsf { P e r m } _ { \mathcal { X } } } [ A ^ { f } ( ) = 1 ] | < \varepsilon ,
$$

where $\mathsf { P e r m } _ { \mathcal { X } }$ is the set of permutations on $\mathcal { X }$ .

From the results of Aaronson and Shi [AS04], Ambainis [Amb05] and Kutin [Kut05], no $o ( N ^ { 1 / 3 } )$ -query quantum algorithm can distinguish a random permutation from a random 2-to-1 function. Therefore, we have

$$
| \operatorname* { P r } _ { f  \mathsf { F } _ { \mathcal { X } } ^ { 2 } } [ A ^ { f } ( ) = 1 ] - \operatorname* { P r } _ { f  \mathsf { P e r m } _ { \mathcal { X } } } [ A ^ { f } ( ) = 1 ] | < o ( 1 ) .
$$

Putting the above three inequalities together, we have

$$
\left| \operatorname* { P r } _ { k \left. K ^ { 2 } \right. 1 } [ A ^ { \mathsf { P R F } _ { k } ^ { 2 \right. 1 } } ( ) = 1 ] - \operatorname* { P r } _ { k \left. K ^ { \mathsf { P R P } } \right|} [ A ^ { \mathsf { P R P } _ { k } } ( ) = 1 ]  < o ( 1 ) ,
$$

which means $A$ cannot distinguish $\mathsf { P R F } _ { \mathcal { K } ^ { 2  1 } } ^ { 2  1 }$ and $\mathsf { P R P } _ { K ^ { \mathsf { P R P } } }$

On the other side, an SZK algorithm can easily distinguish a permutation from a two-to-one function. Therefore, we can proceed exactly as in Theorem 7.6 to construct an oracle $\mathcal { O } \in \mathsf { P } /$ poly such that $\mathsf { s z K } ^ { \mathcal { O } } \notin$ ${ \tt B Q P } ^ { \mathcal { O } }$ . □

Very recently, Chen [Che16] showed that, based on a construction similar to the “cheat-sheet” function by Aaronson, Ben-David and Kothari [ABDK15], we can take any function which is hard for BPP algorithms, and turn it into a function which is hard for SZK algorithms in a black-box fashion. We are going to adapt this construction, together with a PRF, to build an oracle in P/poly which separates BQP from SZK.

Theorem A.6. Assuming one-way functions exist, there exists an oracle O ∈ P/poly such that $B Q P ^ { \mathcal { O } } \ \mathcal { L }$ $s Z K ^ { \mathcal { O } }$ .

Proof. We will use the P $3 \mathsf { F } ^ { \mathsf { m o d } } : { \mathsf { K } } ^ { \mathsf { m o d } } \times { \mathcal { X } } ^ { \mathsf { m o d } } \to { \mathcal { X } } ^ { \mathsf { m o d } }$ defined in Section 7.2 here. For simplicity, we will use $\mathcal { X }$ to denote $\chi ^ { \mathrm { { m o d } } }$ in this proof. Recall that $\mathcal { X }$ is interpreted as $[ N ]$ for $N = N ( n ) = | { \mathcal { X } } |$ .

Construction of distributions $\mathcal { D } _ { n } ^ { i }$ . For each $n$ , we define distributions $\mathcal { D } _ { n } ^ { 0 }$ and $\mathcal { D } _ { n } ^ { 1 }$ on $( { \mathcal X } _ { n } \to { \mathcal X } _ { n } ) \times$ $\{ 0 , 1 \} ^ { \sqrt { N } / 2 }$ as follows. We draw a function $f _ { n } : \mathcal { X } \to \mathcal { X }$ from $\mathsf { P R F } _ { K ^ { \mathsf { m o d } } } ^ { \mathsf { m o d } }$ , that is, we draw $( k , a ) \gets K ^ { \mathsf { m o d } } =$ ${ \mathcal { K } } ^ { \mathsf { r a w } } \times A$ , and set $f _ { n } : = \mathsf { P R F } _ { ( k , a ) } ^ { \mathsf { m o d } }$ ; then we let $z = 0 ^ { \sqrt { N } / 2 }$ first, and set $z _ { a } = i$ in $\mathcal { D } _ { n } ^ { i }$ ; finally we output the pair $( f , z )$ as a sample.

Distinguishing $\mathcal { D } _ { n } ^ { 0 }$ and $\mathcal { D } _ { n } ^ { 1 }$ is hard for SZK. Recall that SZK is a semantic class. That is, a given protocol $\Pi$ might be invalid with different oracles or different inputs (i.e., the protocol might not satisfy the zero-knowledge constraint, or the verifier might accept with a probability that is neither $\geq 2 / 3 \mathrm { n o r } \leq 1 / 3 )$ We write $\Pi ^ { ( f , \bar { z } ) } ( ) = \bot$ when $\Pi$ is invalid given oracle access to $( f , z )$ .

We claim that for any protocol $\Pi$ , one of the following two claims must hold for sufficiently large $n$ :

$$
\begin{array} { r l } & { \underset { ( f , z )  \mathcal { D } _ { n } ^ { 0 } } { \mathrm { P r } } [ \Pi ^ { ( f , z ) } ( ) = \perp ] > 0 . 1 \mathrm { ~ o r ~ } \underset { ( f , z )  \mathcal { D } _ { n } ^ { 1 } } { \mathrm { P r } } [ \Pi ^ { ( f , z ) } ( ) = \perp ] > 0 . 1 . } \\ & { | \underset { ( f , z )  \mathcal { D } _ { n } ^ { 0 } } { \mathrm { P r } } [ \Pi ^ { ( f , z ) } ( ) = 1 ] - \underset { ( f , z )  \mathcal { D } _ { n } ^ { 1 } } { \mathrm { P r } } [ \Pi ^ { ( f , z ) } ( ) = 1 ] | < 0 . 2 . } \end{array}
$$

That is, either $\Pi$ is invalid on a large fraction of oracles, or else $\Pi$ cannot distinguish $\mathcal { D } _ { n } ^ { 0 }$ from $\mathcal { D } _ { n } ^ { 1 }$ with a very good probability.

Building a BPP algorithm to break PRFmod. Suppose for a contradiction that there are infinitely many $n$ such that none of (A) and (B) hold. Without loss of generality, we can assume that

$$
\operatorname* { P r } _ { ( f , z ) \gets \mathcal { D } _ { n } ^ { 1 } } \left[ \Pi ^ { ( f , z ) } ( \big ) = 1 \right] - \operatorname* { P r } _ { ( f , z ) \gets \mathcal { D } _ { n } ^ { 0 } } \left[ \Pi ^ { ( f , z ) } ( \big ) = 1 \right] \geq 0 . 2 .
$$

We are going to build a BPP algorithm which is able to break PRFmod on those $n$ , thereby contradicting Lemma 7.5.

From (A), we have

$$
\operatorname* { P r } _ { ( f , z ) \in { \cal { D } } _ { n } ^ { 1 } } [ \Pi ^ { ( f , z ) } ( \ l ) = 1 ] - ( 1 - \operatorname* { P r } _ { ( f , z )  { \cal { D } } _ { n } ^ { 0 } } [ \Pi ^ { ( f , z ) } ( \ l ) = 0 ] ) \ge 0 . 1 ,
$$

which simplifies to

$$
\operatorname* { P r } _ { ( f , z ) \gets \mathcal { D } _ { n } ^ { 1 } } \left[ \Pi ^ { ( f , z ) } ( \bigl ) = 1 \right] + \operatorname* { P r } _ { ( f , z ) \gets \mathcal { D } _ { n } ^ { 0 } } \left[ \Pi ^ { ( f , z ) } ( \bigl ) = 0 \right] \geq 1 . 1 .
$$

From the definition of $\mathcal { D } _ { n } ^ { 0 }$ and $\mathcal { D } _ { n } ^ { 1 }$ , the above implies that

$$
\operatorname* { P r } _ { ( k , a ) \in - K ^ { \mathrm { m o d } } } \left[ \Pi ^ { ( f , z _ { 1 } ) } ( \big ) = 1 \mathrm { ~ a n d ~ } \Pi ^ { ( f , z _ { 0 } ) } ( \big ) = 0 , f = \mathsf { P R F } _ { ( k , a ) } ^ { \mathsf { m o d } } , z _ { 0 } = 0 ^ { \sqrt { N } / 2 } , z _ { 1 } = e _ { a } \right] \ge 0 . 1 ,
$$

where $e _ { a }$ denotes the string of length $\sqrt { N } / 2$ that is all zero except for the $a$ -th bit.

Analysis of distributions $A _ { i } ^ { ( f , z ) }$ . By a result of Sahai and Vadhan [SV03], there are two polynomialtime samplable distributions $A _ { 0 } ^ { ( f , z ) }$ and $A _ { 1 } ^ { ( f , z ) }$ such that $\| A _ { 0 } ^ { ( f , z ) } - A _ { 1 } ^ { ( f , z ) } \| \geq 1 - 2 ^ { - n }$ when $\Pi ^ { ( f , z ) } ( \bigr ) = 1$ and $\| A _ { 0 } ^ { ( f , z ) } - A _ { 1 } ^ { ( f , z ) } \| \leq 2 ^ { - n }$ when $\Pi ^ { ( f , z ) } ( \bigr ) = 0$ .

Hence, with probability 0.1 over $( k , a )  K ^ { \mathrm { m o d } }$ , we have

$$
\begin{array} { r } { \| A _ { 0 } ^ { ( f , z _ { 1 } ) } - A _ { 1 } ^ { ( f , z _ { 1 } ) } \| \ge 1 - 2 ^ { - n } \operatorname { a n d } \| A _ { 0 } ^ { ( f , z _ { 0 } ) } - A _ { 1 } ^ { ( f , z _ { 0 } ) } \| \le 2 ^ { - n } . } \end{array}
$$

This means that either $\| A _ { 0 } ^ { ( f , z _ { 0 } ) } - A _ { 0 } ^ { ( f , z _ { 1 } ) } \| \ge 1 / 3$ or $\| A _ { 1 } ^ { ( f , z _ { 0 } ) } - A _ { 1 } ^ { ( f , z _ { 1 } ) } \| \geq 1 / 3$

Now we show that the above implies an algorithm that breaks PRFmod, and therefore contradicts Lemma 7.5.

The algorithm and its analysis. Given oracle access to a function $f \gets \mathsf { P R F } _ { \mathcal { K } ^ { \mathrm { m o d } } } ^ { \mathsf { m o d } }$ , our algorithm first picks a random index $i \in \{ 0 , 1 \}$ . It then simulates $A _ { i }$ with oracle access to $( f , z )$ to take a sample from $\bar { \mathbf { \Lambda } } _ { A _ { i } } ( f , z )$ , where $z = z _ { 0 } = 0 ^ { \sqrt { N } / 2 }$ ; it records all the indices in $z$ that are queried by $A _ { i }$ . Now, with probability at least index o $0 . 1 / 2 = 0 . 0 5$ , we e that $\| A _ { i } ^ { ( f , z _ { 0 } ) } - A _ { i } ^ { ( f , z _ { 1 } ) } \| \ge 1 / 3$ Since -th inde $( f , z _ { 0 } )$ and with $( f , z _ { 1 } )$ only differility at least e . $a$ -th $z$ $A _ { i } ^ { ( f , z _ { 0 } ) }$ $a$ $z$ $1 / 3$

Hence, with probability at least $0 . 0 5 / 3 = \Omega ( 1 )$ , one of the values recorded by our algorithm is $a$ , and in that case our algorithm can find a collision in $f$ easily. However, when $f$ is a truly random function, no algorithm can find a collision with a non-negligible probability. Therefore, this algorithm is a distinguisher between PRFmod and a truly random function, contradicting the fact that PRFmod is secure by Lemma 7.5.

Construction of the oracle $\mathcal { O }$ . Finally, we are ready to construct our oracle $\mathcal { O }$ . We will let $\mathcal { O }$ encode pairs (f1, z1), (f2, z2), . . . , where fn is a function from Xn to Xn and zn ∈ {0, 1} N /2.

For each $n$ , we draw a random index $i  \{ 0 , 1 \}$ , and then draw $( f _ { n } , z _ { n } ) \gets \mathcal { D } _ { n } ^ { i }$ . We set $L$ to be the unary language consisting of all $0 ^ { n }$ for which $\left( f _ { n } , z _ { n } \right)$ is drawn from $\mathcal { D } _ { n } ^ { 1 }$ .

From Lemma 7.5, a quantum algorithm can distinguish $\mathcal { D } _ { n } ^ { 0 }$ from $\mathcal { D } _ { n } ^ { 1 }$ , except with negligible probability, by recovering $a$ . Therefore, by a similar argument as in the proof of Theorem 7.6, we have $L \in \mathsf { B Q P } ^ { \mathcal { O } }$ with probability 1.

On the other hand, for a protocol $\Pi$ and a sufficiently large $n$ , either (A) happens, which means that $\Pi ^ { ( f _ { n } , z _ { n } ) }$ is invalid with probability 0.05 on input $0 ^ { n }$ , or (B) happens, which means that $\Pi$ cannot distinguish $\mathcal { D } _ { n } ^ { 0 }$ and $\mathcal { D } _ { n } ^ { 1 }$ with a constant probability.

In both cases $\Pi$ cannot decide whether $0 ^ { n }$ belongs to $L$ correctly with bounded error. Hence, again by a similar argument as in the proof of Theorem 7.6, the probability that $\Pi$ decides $L$ is 0. And since there are only countably many protocols, we have $L \not \in { \mathsf { S } } { \mathsf { Z } } { \mathsf { K } } ^ { \mathcal { O } }$ with probability 1, which means that ${ \mathsf { B Q P } } ^ { \mathcal { O } } \subset { \mathsf { S Z K } } ^ { \mathcal { O } }$ with probability 1.

Finally, it is easy to see that $\mathcal { O } \in \mathsf { P } / \mathsf { p o l y }$ , which completes the proof.

# B Missing Proofs in Section 3

We first prove Lemma 3.6.

Proof of Lemma 3.6. Let $N = 2 ^ { n }$ for simplicity and $L$ be a list consisting of $N$ reals: $| \langle u | w \rangle | ^ { 2 } - 2 ^ { - n }$ for each $w \in \{ 0 , 1 \} ^ { n }$ . We sort all reals in $L$ in increasing order, and denote them by $a _ { 1 } , a _ { 2 } , \dotsc , a _ { N }$ . We also let $\Delta = \mathsf { d e v } ( | u \rangle )$ for brevity.

Then from the definitions of $\mathsf { a d v } ( | u \rangle )$ and $\mathsf { d e v } ( | u \rangle )$ , we have

$$
\sum _ { i = 1 } ^ { N } a _ { i } = 0 ,
$$

$$
\sum _ { i = 1 } ^ { N } \left| a _ { i } \right| = \Delta ,
$$

and

$$
\mathsf { a d v } ( | u \rangle ) = \frac { 1 } { 2 } + \sum _ { i = N / 2 + 1 } ^ { N } a _ { i } .
$$

Now, let $t$ be the first index such that $a _ { t } \geq 0$ . Then we have

$$
\sum _ { i = t } ^ { N } a _ { i } = \sum _ { i = t } ^ { N } | a _ { i } | = { \frac { \Delta } { 2 } } \qquad { \mathrm { a n d } } \qquad \sum _ { i = 1 } ^ { t - 1 } a _ { i } = - \sum _ { i = 1 } ^ { t - 1 } | a _ { i } | = - { \frac { \Delta } { 2 } } .
$$

We are going to consider the following two cases.

• (i): $t \ge N / 2 + 1$ . Note that $a _ { i }$ ’s are increasing and for all $i < t$ , $a _ { i } < 0$ , we have

$$
\sum _ { i = 1 } ^ { N / 2 } | a _ { i } | \geq \sum _ { i = N / 2 + 1 } ^ { t - 1 } | a _ { i } | ,
$$

which means

$$
\sum _ { i = N / 2 + 1 } ^ { t - 1 } \left| a _ { i } \right| \leq \frac { 1 } { 2 } \cdot \sum _ { i = 1 } ^ { t - 1 } \left| a _ { i } \right| \leq \frac { \Delta } { 4 } .
$$

Therefore,

$$
\sum _ { i = N / 2 + 1 } ^ { N } a _ { i } \ge \sum _ { i = t } ^ { N } a _ { i } + \sum _ { i = N / 2 + 1 } ^ { t - 1 } a _ { i } \ge \frac { 1 } { 2 } + \frac { \Delta } { 2 } - \frac { \Delta } { 4 } \ge \frac { 1 } { 2 } + \frac { \Delta } { 4 } .
$$

• (ii): $t \leq N / 2$ . In this case, note that we have

$$
\sum _ { i = N / 2 + 1 } ^ { N } a _ { i } \geq \sum _ { i = t } ^ { N / 2 } a _ { i } .
$$

Therefore,

$$
\sum _ { i = N / 2 + 1 } ^ { N } a _ { i } \geq \frac { 1 } { 2 } \cdot \sum _ { i = t } ^ { N } a _ { i } \geq \frac { \Delta } { 4 } .
$$

Since in both cases we have $\sum _ { = N / 2 + 1 } ^ { N } a _ { i } \geq \frac \Delta 4$ , it follows that i

$$
\mathsf { a d v } ( | u \rangle ) = \frac { 1 } { 2 } + \sum _ { i = N / 2 + 1 } ^ { N } a _ { i } \geq \frac { 1 } { 2 } + \frac { \Delta } { 4 } ,
$$

which completes the proof.

Now we prove Lemma 3.7.

Proof of Lemma 3.7. The random pure state $| u \rangle$ can be generated as follows: draw four i.i.d. reals $x _ { 1 } , x _ { 2 } , x _ { 3 } , x _ { 4 } \sim$ $\mathcal { N } ( 0 , 1 )$ , and set

$$
| u \rangle = \frac { ( x _ { 1 } + x _ { 2 } i ) | 0 \rangle + ( x _ { 3 } + x _ { 4 } i ) | 1 \rangle } { \sqrt { x _ { 1 } ^ { 2 } + x _ { 2 } ^ { 2 } + x _ { 3 } ^ { 2 } + x _ { 4 } ^ { 2 } } } .
$$

Hence, we have

$$
\begin{array} { r l } {  { \big \rangle \big | ^ { 2 } - | \langle u | 1 \rangle | ^ { 2 } \big | \Big | = \int _ { - \infty } ^ { \infty } \int _ { - \infty } ^ { \infty } \int _ { - \infty } ^ { \infty } \int _ { - \infty } ^ { \infty } \frac { 1 } { ( 2 \pi ) ^ { 2 } } \frac { | x _ { 1 } ^ { 2 } + x _ { 2 } ^ { 2 } - x _ { 3 } ^ { 2 } - x _ { 4 } ^ { 2 } | } { x _ { 1 } ^ { 2 } + x _ { 2 } ^ { 2 } + x _ { 3 } ^ { 2 } + x _ { 4 } ^ { 2 } } \cdot e ^ { - ( x _ { 1 } ^ { 2 } + x _ { 2 } ^ { 2 } + x _ { 3 } ^ { 2 } + x _ { 4 } ^ { 2 } ) / 2 } d x _ { 1 } } } \\ & { = \int _ { 0 } ^ { 2 \pi } \int _ { 0 } ^ { 2 \pi } \int _ { 0 } ^ { + \infty } \int _ { 0 } ^ { + \infty } \frac { 1 } { \big ( 2 \pi ) ^ { 2 } } \cdot \frac { | \rho _ { 1 } ^ { 2 } - \rho _ { 2 } ^ { 2 } | } { \rho _ { 1 } ^ { 2 } + \rho _ { 2 } ^ { 2 } } \cdot \rho _ { 1 } \rho _ { 2 } \cdot e ^ { - ( \rho _ { 1 } ^ { 2 } + \rho _ { 2 } ^ { 2 } ) / 2 } d \rho _ { 1 } d \rho _ { 2 } d \theta _ { 1 } d } \\ & { = \int _ { 0 } ^ { + \infty } \int _ { 0 } ^ { + \infty } \frac { | \rho _ { 1 } ^ { 2 } - \rho _ { 2 } ^ { 2 } | } { \rho _ { 1 } ^ { 2 } + \rho _ { 2 } ^ { 2 } } \cdot \rho _ { 1 } \rho _ { 2 } \cdot e ^ { - ( \rho _ { 1 } ^ { 2 } + \rho _ { 2 } ^ { 2 } ) / 2 } d \rho _ { 1 } d \rho _ { 2 } } \\ & { = \frac { 1 } { 2 } } \end{array}
$$

# C Missing Proofs in Section 6

We prove Lemma 6.5 here.

Proof of Lemma 6.5. We prove the concentration inequality by bounding the variance,

$$
\operatorname { V a r } [ \mathsf { a d v } ( f ) ] = \mathbb { E } [ \mathsf { a d v } ( f ) ^ { 2 } ] - \mathbb { E } [ \mathsf { a d v } ( f ) ] ^ { 2 } .
$$

Note that

$$
\mathbb { E } [ \mathsf { a d v } ( f ) ] ^ { 2 } = \left( \frac { 2 } { \sqrt { 2 \pi } } \int _ { 1 } ^ { + \infty } x ^ { 2 } e ^ { - x ^ { 2 } / 2 } d x \right) ^ { 2 } = \mathsf { S u c c } _ { Q } ^ { 2 } .
$$

We now calculate $\mathbb { E } [ \mathsf { a d v } ( f ) ^ { 2 } ]$ . We have

$$
\begin{array} { r l } & { \frac { \mathbb { E } } { f } [ \mathsf { a d v } ( f ) ^ { 2 } ] = \frac { \mathbb { E } } { f } \left[ \left( \underset { z \in \{ 0 , 1 \} ^ { n } } { \mathbb { E } } [ \widehat { f } ^ { 2 } ( z ) \cdot \mathbf { 1 } _ { | \widehat { f } ( z ) | \geq 1 } ] \right) ^ { 2 } \right] } \\ & { \quad \quad \quad = \frac { \mathbb { E } } { f } \left[ \underset { z _ { 1 } , z _ { 2 } \in \{ 0 , 1 \} ^ { n } } { \mathbb { E } } \left[ \widehat { f } ^ { 2 } ( z _ { 1 } ) \widehat { f } ^ { 2 } ( z _ { 2 } ) \cdot \mathbf { 1 } _ { | \widehat { f } ( z _ { 1 } ) | \geq 1 \land | \widehat { f } ( z _ { 2 } ) | \geq 1 } \right] \right] . } \\ & { \quad \quad \quad = \underset { z _ { 1 } , z _ { 2 } \in \{ 0 , 1 \} ^ { n } } { \mathbb { E } } \left[ \mathbb { E } \left[ \widehat { f } ^ { 2 } ( z _ { 1 } ) \widehat { f } ^ { 2 } ( z _ { 2 } ) \cdot \mathbf { 1 } _ { | \widehat { f } ( z _ { 1 } ) | \geq 1 \land | \widehat { f } ( z _ { 2 } ) | \geq 1 } \right] \right] . } \end{array}
$$

Now there are two cases: $z _ { 1 } = z _ { 2 }$ and $z _ { 1 } \neq z _ { 2 }$ . When $z _ { 1 } = z _ { 2 }$ , let $z = z _ { 1 } = z _ { 2 }$ ; then we have

$$
\begin{array} { l } { { E x _ { f } \left[ \widehat f ^ { 2 } ( z _ { 1 } ) \widehat f ^ { 2 } ( z _ { 2 } ) \cdot { \mathbf { 1 } } _ { | \widehat f ( z _ { 1 } ) | \geq 1 \wedge | \widehat f ( z _ { 2 } ) | \geq 1 } \right] = \mathbb { E } \left[ \widehat f ^ { 4 } ( z ) \cdot { \mathbf { 1 } } _ { | \widehat f ( z ) | \geq 1 } \right] } } \\ { { \displaystyle = \frac { 2 } { \sqrt { 2 \pi } } \int _ { 1 } ^ { + \infty } x ^ { 4 } e ^ { - x ^ { 2 } / 2 } d x } } \\ { { \displaystyle = O ( 1 ) } . } \end{array}
$$

Next, if $z _ { 1 } \neq z _ { 2 }$ , then without loss of generality, we can assume $z _ { 1 } = 0 ^ { N }$ . Now we define two sets $A$ and $B$ ,

We also define

$$
\widehat { f } _ { A } : = \frac { 1 } { \sqrt { N / 2 } } \cdot \sum _ { z \in A } f ( z ) \ \mathrm { a n d } \ \widehat { f } _ { B } : = \frac { 1 } { \sqrt { N / 2 } } \cdot \sum _ { z \in B } f ( z ) .
$$

Then from the definitions of $\widehat { f } ( z _ { 1 } )$ and $\widehat { f } ( z _ { 2 } )$ , we have

$$
{ \widehat { f } } ( z _ { 1 } ) = { \frac { 1 } { \sqrt { 2 } } } \cdot ( { \widehat { f } } _ { A } + { \widehat { f } } _ { B } ) { \mathrm { ~ a n d ~ } } { \widehat { f } } ( z _ { 1 } ) = { \frac { 1 } { \sqrt { 2 } } } \cdot ( { \widehat { f } } _ { A } - { \widehat { f } } _ { B } ) .
$$

Therefore,

$$
) \widehat f ^ { 2 } ( z _ { 2 } ) \cdot \mathbf { 1 } _ { | \widehat f ( z _ { 1 } ) | \geq 1 \wedge | \widehat f ( z _ { 2 } ) | \geq 1 } \Big ] = \left( \frac { 1 } { \sqrt { 2 \pi } } \right) ^ { 2 } \cdot \int _ { | a + b | \geq \sqrt { 2 } } \frac { 1 } { 4 } \cdot ( a + b ) ^ { 2 } \cdot ( a - b ) ^ { 2 } \cdot e ^ { - ( a ^ { 2 } + b ^ { 2 } ) / 2 } .
$$

Let $x = a + b$ and $y = a - b$ . Then

$$
a = { \frac { x + y } { 2 } } , b = { \frac { x - y } { 2 } } , d a = { \frac { d x + d y } { 2 } } , { \mathrm { a n d } } d b = { \frac { d x - d y } { 2 } } .
$$

Also note that $x ^ { 2 } + y ^ { 2 } = 2 ( a ^ { 2 } + b ^ { 2 } )$ . Plugging in $x$ and $y$ , the above can be simplified to

$$
\begin{array} { r l } { \frac { 1 } { 2 \pi } \displaystyle \int _ { | v | \geq \sqrt { 2 } } \frac { 1 } { 4 } x ^ { 2 } y ^ { 2 } e ^ { - ( x ^ { 2 } + y ^ { 2 } ) / 4 } \cdot \frac { 1 } { 2 } d x d y = \frac { 1 } { 2 \pi } \left( \displaystyle \int _ { | x | \geq \sqrt { 2 } } \frac { 1 } { 2 \sqrt { 2 } } \cdot x ^ { 2 } e ^ { - x ^ { 2 } / 4 } d x \right) ^ { 2 } } & { } \\ { \displaystyle } & { = \frac { 1 } { 2 \pi } \left( \displaystyle \int _ { \sqrt { 2 } } ^ { + \infty } \frac { 1 } { \sqrt { 2 } } \cdot x ^ { 2 } e ^ { - x ^ { 2 } / 4 } d x \right) ^ { 2 } } \\ & { = \frac { 1 } { 2 \pi } \left( \displaystyle \int _ { 1 } ^ { + \infty } 2 t ^ { 2 } e ^ { - t ^ { 2 } / 2 } d t \right) ^ { 2 } } \\ & { = \left( \frac { 2 } { \sqrt { 2 \pi } } \displaystyle \int _ { 1 } ^ { + \infty } t ^ { 2 } e ^ { - t ^ { 2 } / 2 } d t \right) ^ { 2 } = } \end{array}
$$

$$
( t = x / \sqrt { 2 } )
$$

Putting two cases together, we have

$$
\underline { { \mathbb { E } } } [ \mathsf { a d v } ( f ) ^ { 2 } ] = \frac { 1 } { N } \cdot O ( 1 ) + \frac { N - 1 } { N } \cdot \mathsf { S u c c } _ { Q } ^ { 2 } ,
$$

which in turn implies

$$
\operatorname { V a r } [ \mathsf { a d v } ( f ) ] = O ( 1 / N ) .
$$

# D Missing Proofs in Section 7

For completeness, we prove Lemma 7.5 here.

Proof of Lemma 7.5. In the following, we will always use $\varepsilon = \varepsilon ( n )$ to denote a negligible function. And we will denote $\mathcal { X } ^ { \mathsf { r a w } }$ as $\mathcal { X }$ for brevity. Recall that we interpret $\mathcal { X }$ as $[ N ]$ for $N = N ( n ) = \mathcal { X }$ .

Both PRPraw and PRFmod are classically-secure PRFs. It is well-known that a secure PRP is also a secure PRF; therefore ${ \mathsf { P R P } } ^ { \mathsf { r a w } }$ is a classically-secure PRF. So we only need to prove this for PRFmod.

Recall that $\mathsf { P R F } _ { ( k , a ) } ^ { \mathsf { m o d } } ( x ) = \mathsf { P R P } _ { k } ^ { \mathsf { r a w } } ( ( x - 1 )$ mod $a { + 1 }$ ). We first show that if the ${ \mathsf { P R P } } ^ { \mathsf { r a w } }$ in the definition of PRFmod were replaced by a truly random function, then no classical polynomial-time algorithm $A$ could distinguish it from a truly random function. That is,

$$
\left| \operatorname* { P r } _ { f \gets \mathcal { X } ^ { \mathcal { X } } , a \gets \mathcal { A } } [ A ^ { f _ { \mathrm { m o d } } } { } ( \cdot ) = 1 ] - \operatorname* { P r } _ { f \gets \mathcal { X } ^ { \mathcal { X } } } [ A ^ { f } ( \cdot ) = 1 ] \right| < \varepsilon ,
$$

where $f _ { \mathrm { m o d } a } ( x ) : = f ( ( x - 1 ) { \bmod { a } } + 1 )$ ).

Clearly, as long as $A$ never queries its oracle on two points $x$ and $x ^ { \prime }$ such that $x \equiv x ^ { \prime }$ (mod $a$ ), the oracle will look random. Suppose $A$ makes $q$ queries in total. There are $\binom { q } { 2 }$ possible differences between query points, and each difference is at most $N$ . So for large enough $N$ , each difference can be divisible√ √ by at most two different moduli from √ $\mathcal { A }$ (recall that each number in $\mathcal { A }$ lies in $[ \sqrt { N } / 4 , \sqrt { N } / 2 ] )$ . And since $| \dot { \boldsymbol { \mathcal { A } } } | \geq \Omega ( \sqrt { N } / \log N )$ , the total probability of querying two $x$ and $x ^ { \prime }$ such that $x \equiv x ^ { \prime }$ (mod $a$ ) is at most

$$
O \left( { \frac { q ^ { 2 } \log N } { \sqrt { N } } } \right) ,
$$

which is negligible as $N$ is exponential in $n$ . This implies (21).

Now, since PRPraw is a classically-secure PRF, for any polynomial-time algorithm $A$ , we have

$$
\left| \operatorname* { P r } _ { f \gets \mathcal { X } ^ { \mathcal { X } } , a \gets \mathcal { A } } [ A ^ { f _ { \bmod { a } } } ( \cdot ) = 1 ] - \operatorname* { P r } _ { f \gets \mathsf { P R P } _ { K ^ { \alpha \times } , a \gets \mathcal { A } } ^ { r _ { \alpha \times } } } [ A ^ { f _ { \bmod { a } } } ( \cdot ) = 1 ] \right| < \varepsilon ,
$$

since otherwise we can directly construct a distinguisher between $\mathsf { P R P } _ { K ^ { \mathsf { r a w } } } ^ { \mathsf { r a w } }$ and $\chi ^ { \chi }$

Note that

$$
\operatorname* { P r } _ { f \longleftrightarrow \mathsf { P R P } _ { K ^ { \mathrm { r a w } } } ^ { \mathrm { r a w } } , a \gets \mathcal { A } } [ A ^ { f _ { \mathrm { m o d } } } { a } ( \ v u ) = 1 ] = \operatorname* { P r } _ { f \gets \mathsf { P R F } _ { K ^ { \mathrm { r o o d } } } ^ { \mathrm { m o d } } } [ A ^ { f } ( \ v u ) = 1 ]
$$

by their definitions. Hence, (21) and (22) together imply that

$$
| \operatorname* { P r } _ { f  \mathrm { P R F } _ { \mathit { K } ^ { \mathrm { m o d } } } ^ { \mathrm { m o d } } } [ A ^ { f } ( \ l ) = 1 ] - \operatorname* { P r } _ { f  \mathit { K } ^ { \mathit { x } } } [ A ^ { f } ( \ l ) = 1 ] | < \varepsilon
$$

for any polynomial-time algorithm $A$ . This completes the proof for the first statement.

Quantum algorithm for recovering $a$ given oracle access to $\mathsf { P R F } _ { K ^ { \mathsf { m o d } } } ^ { \mathsf { m o d } }$ . Let $( k , a )  K ^ { \mathrm { m o d } }$ , $f =$ $\mathsf { P R F } _ { ( k , a ) } ^ { \mathsf { m o d } }$ and $g = \mathsf { P R P } _ { k } ^ { \mathsf { r a w } }$ . From the definitions, we have $f = g _ { \mathrm { m o d } a }$ .

Since $g$ is a permutation, there is no collision $( x , x ^ { \prime } )$ such that $g ( x ) = g ( x ^ { \prime } )$ . Moreover, in this case, $f = g _ { \mathrm { m o d } a }$ has a unique period $a$ . Therefore, we can apply Boneh and Lipton’s quantum period-finding algorithm [BL95] to recover $a$ . Using a polynomial number of repetitions, we can make the failure probability negligible, which completes the proof for the second statement.

Quantum algorithm for distinguishing ${ \mathsf { P R P } } ^ { \mathsf { r a w } }$ and PRFmod. Finally, we show the above algorithm implies a good quantum distinguisher between ${ \mathsf { P R P } } ^ { \mathsf { r a w } }$ and PRFmod. Given oracle access to a function $f$ our distinguisher $A$ tries to recover a period $a$ using the previously discussed algorithm, and accepts only if $f ( 1 ) = f ( 1 + a )$ .

When $f \gets \mathsf { P R P } _ { \mathcal { K } ^ { \mathsf { r a w } } } ^ { \mathsf { r a w } }$ , note that $f$ is a permutation, which means $A$ accepts with probability 0 in this case.

On the other side, when $f \gets \mathsf { P R F } _ { \mathcal { K } ^ { \mathrm { m o d } } } ^ { \mathsf { m o d } }$ , from the second statement, $A$ can recover the period $a$ with probability at least $1 - \varepsilon$ . Therefore $A$ accepts with probability at least $1 - \varepsilon$ .

Combining, we find that $A$ is a distinguisher with advantage $1 - \varepsilon$ , and this completes the proof for the last statement.

# E Numerical Simulation For Conjecture 1

Recall Conjecture 1, which said that a random quantum circuit $C$ on $n$ qubits satisfies $\mathsf { a d v } ( C ) \geq C _ { \mathsf { t h r } } - \varepsilon$ with probability $1 - 1 / \exp ( n )$ , where

$$
C _ { \sf t h r } : = \frac { 1 + \ln 2 } { 2 } .
$$

We first explain where the magic number $C _ { \mathrm { t h r } }$ comes from. Suppose $C$ is drawn from $\mu _ { \mathsf { H a a r } } ^ { 2 ^ { n } }$ instead of $\mu _ { \mathrm { g r i d } }$ . Then $C | 0 ^ { n } \rangle$ is a random quantum state, and therefore the values $2 ^ { n } \cdot | \langle x | C | 0 \rangle |$ ’s, for each $x \in \{ 0 , 1 \} ^ { n }$ are distributed very closely to $2 ^ { n }$ i.i.d. exponential distributions with $\lambda = 1$ .

So, assuming that, we can see that the median of probList $\left( C | 0 \rangle \right)$ concentrates around $\ln 2$ , as

$$
\int _ { 0 } ^ { \ln 2 } d x e ^ { - x } = { \frac { 1 } { 2 } } ,
$$

![](images/37b0420757c130d8e3cdf9317aaed5a7e17c574581bdef31fc3dd943a2383b41.jpg)  
Figure 2: A histogram of (normalized) probList(C|0i), where C ← µ16,25grid . The $\mathbf { X }$ -axis represents the probability, and the y-axis represents the estimated density, and the red line indicates the PDF of the exponential distribution with $\lambda = 1$ .

which also implies that adv $( C )$ concentrates around

$$
\int _ { \ln 2 } ^ { + \infty } x e ^ { - x } d x = C _ { \mathrm { t h r } } = { \frac { 1 + \ln 2 } { 2 } } \approx 0 . 8 4 6 5 7 4 .
$$

In the following, we first provide some numerical evidence that the values in probList $\left( C | 0 \rangle \right)$ also behave like exponentially distributed random variables, which explains why the constant should indeed be $C _ { \mathrm { t h r } }$ . Then we provide a direct numerical simulation for the distribution of $\mathsf { a d v } ( C )$ to argue that adv $( C )$ approximately follows a nice normal distribution. Finally we examine the decreasing rate of the standard variance of $\mathsf { a d v } ( C )$ to support our conjecture.

# E.1 Numerical Simulation Setting

In the following we usually set $n = 9$ or $n = 1 6$ (so that $\sqrt { n }$ is an integer); and we always set $m = n ^ { 2 }$ as in Conjecture 1.

# E.2 Distribution of probList $\left( C | 0 \rangle \right)$ : Approximate Exponential Distribution

In Figure 2 we plot the histogram of the distribution of the normalized probabilities in probList $\left( C | 0 \rangle \right)$ where $C \gets \mu _ { \mathtt { g r i d } } ^ { 1 6 , 2 5 6 }$ µ16,256grid , that is,

$$
\{ 2 ^ { n } \cdot p : p \in { \mathsf { p r o b l i s t } } ( C | 0 \rangle ) \} .
$$

And we compare it with the exponential distribution with $\lambda = 1$ . From Figure 2, it is easy to observe that these two distributions are quite similar.

# E.3 Distribution of $\mathsf { a d v } ( C )$ : Approximate Normal Distribution

Next we perform direct numerical simulation to see how $\mathsf { a d v } ( C )$ is distributed when $C \gets \mu _ { \mathtt { g r i d } } ^ { n , m }$ . Our results suggest that $\mathsf { a d v } ( C )$ approximately follows a normal distribution with mean close to $C _ { \mathrm { t h r } }$ .

![](images/9f006f91c173070df7e555f3bc36394c331921d8177876804efc2519374e9a00.jpg)  
Figure 3: A histogram of the $\mathsf { a d v } ( C )$ ’s of the $1 0 ^ { 5 }$ i.i.d. samples from $\mu _ { \mathtt { g r i d } } ^ { 9 , 8 1 }$ . The $\mathbf { X }$ -axis represents the value of $\mathsf { a d v } ( C )$ , and the y-axis represents the estimated density, and the red line indicates the PDF of the normal distribution $\mathcal { N } ( 0 . 8 4 6 8 8 4 , 0 . 0 0 8 1 3 9 1 1 ^ { 2 } )$ .

# E.3.1 µ grid , $1 0 ^ { 5 }$ samples

We first draw 105 i.i.d. samples from µ9,81grid and plot the distribution of the corresponding $\mathsf { a d v } ( C )$ ’s in Figure 3. From Figure 3, we can see that the distribution of $\mathsf { a d v } ( C )$ follows a nice normal distribution, with mean very close to $C _ { \mathrm { t h r } }$ .

# E.3.2 $\mu _ { \mathrm { g r i d } } ^ { 1 6 , 2 5 6 }$ , $1 0 ^ { 5 }$

Next, we draw 105 i.i.d. samples from µ16,25grid and plot the distribution of the corresponding $\mathsf { a d v } ( C )$ ’s in Figure 4. From Figure 4, we can observe that the distribution of $\mathsf { a d v } ( C )$ in this case also mimics a nice normal distribution, with mean even closer to $C _ { \mathrm { t h r } }$ than in the previous case.

# E.4 The Empirical Decay of Variance

The previous subsection suggests that $\mathsf { a d v } ( C )$ follows a normal distribution with mean approaching $C _ { \mathrm { t h r } }$ . If that’s indeed the case, then informally, Conjecture 1 becomes equivalent to the conjecture that the variance $\sigma$ of $C _ { \mathrm { t h r } }$ becomes $O ( 1 / n )$ as $n  + \infty$ . So we wish to verify the latter conjecture for $\mu _ { \mathbf { g r i d } } ^ { n , n ^ { 2 } }$ with some numerical simulation.

# The circuit distribution $\mu _ { \mathbf { g e n e } } ^ { n , m }$ ral

Unfortunately, the definition of $\mu _ { \mathbf { g r i d } } ^ { n , m }$ requires $n$ to be a perfect square, and there are only five perfect squares for which we can perform quick simulations $( n \in \{ 1 , 4 , 9 , 1 6 , 2 5 \} )$   
tion µn,mgenera on $n$ qubits and $m$ circuits instead: each of $m$ gates is a Haar random two-qubit gate acting on two qubits chosen uniformly at random. In this case, since we don’t need to arrange the qubits in a square grid, $n$ can be any positive integer.

![](images/17da7ab563f0237c93638454148b3baf84b9d86637c6175f1745cea0254257cf.jpg)  
Figure 4: A histogram of the adv $( C )$ ’s of the $1 0 ^ { 5 }$ i.i.d. samples from $\mu _ { \mathrm { g r i d } } ^ { 1 6 , 2 5 6 }$ . The $\mathbf { X }$ -axis represents the value of $\mathsf { a d v } ( C )$ , the y-axis represents the estimated density, and the red line indicates the PDF of the normal distribution $\mathcal { N } ( 0 . 8 4 6 5 7 9 , 0 . 0 0 0 7 1 2 5 7 1 ^ { 2 } )$ .

Numerical simulation shows that adv(C) is distributed nearly the same when C is drawn from µn,n2general or µgrid for $n = 3$ or $n = 4$ , so it is reasonable to consider $\mu _ { \tt g e n e r a l }$ instead of $\mu _ { \mathrm { g r i d } }$ .

For each n = 2, 3, . . . , 16, we draw 1000 i.i.d. samples from µng ,n2eneral, and calculate the variance of the corresponding $\mathsf { a d v } ( C )$ ’s. The results are summarized in Figure 5.

From Figure 5, we can observe that the variance decreases faster than the inverse function $1 / x$ ; hence it supports Conjecture 1.

![](images/51994ff71358aa7ec605394e5522eefb9f4b7d2333238d2851829e0442e6758d.jpg)  
Figure 5: The empirical decay of the variance of $\mathsf { a d v } ( C )$ . Here a point $( x , y )$ means that the standard variance of the corresponding adv(C)’s for the 1000 i.i.d. samples from µx,x2general i s $y$ . Also, the red line represents the function $y = 0 . 1 / x$ .